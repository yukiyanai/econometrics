# 多重比較法

**今回の目標**

- 多重比較の何が問題であるかを理解する
- 多重比較であることを考慮にいれて検定を行う方法を身につける


## 準備

必要なパッケージを読み込む。
```{r packs, message = FALSE}
pacman::p_load(tidyverse,
               broom)
```

<br>

## 多重比較の問題

多重検定の問題を確認するために、シミュレーションを実施しよう。

まず、標本サイズ$N$で、$K$個の互いに独立な説明変数$x_1, x_2, \dots, x_{K}$ を作る。$N=100$、$K=20$で試してみる。
```{r}
set.seed(2021-11-12)
N <- 100  # 標本サイズ
K <- 20   # 説明変数の数
X <- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)
colnames(X) <- paste0("x", 1:K)
myd <- as_tibble(X)
```

これらの説明変数 $x_k$ ($k = 1, 2, \dots, K$) とは**無関係に** $y$を作り、データフレームに加える。
```{r}
myd$y <- rnorm(N)
```

このデータを使い、以下の回帰モデルを推定する。
$$
\begin{aligned}
  Y_i &\sim \mbox{Normal}(\mu_i, \sigma) \\
  \mu_i &= \beta_0 + \beta_1 x_{i1} + \cdots + \beta_K x_{iK}
\end{aligned}
$$

ここで、$\beta_k = 0$ という帰無仮説を、すべての$k$ ($k = 1, 2, \dots, K$) について個別に検定するとする。そうすると、検定の対象となるファミリーは、
$$
\mathcal{F} = \{\beta_1 = 0, \dots, \beta_K = 0\}
$$
となる。

このシミュレーションでは、$y$をどの$x_k$とも無関係に作っているので、すべての帰無仮説が正しい。よって、このファミリーに含まれる帰無仮説は1つも棄却したくない。

実際に回帰分析を行い、有意水準0.05で1つひとつの仮説を検定しよう。`y ~ .` とすると、`y` をそのデータに含まれる`y`以外のすべての変数に回帰する。
```{r}
fit <- lm(y ~ ., data = myd)
tidy(fit) |> 
  knitr::kable()
```

x8の$p$値 (`p.value`) が 0.05未満なので、$\beta_8 = 0$という帰無仮説が**誤って棄却**されてしまう。

少なくとも1つの帰無仮説を誤って棄却するかどうかは、次のようにして調べることができる。$p$値（`p.value`）が有意水準を下回っていれば、帰無仮説が棄却される。
```{r}
pv <- tidy(fit) |> 
  filter(term != "(Intercept)") |> 
  pull(p.value) 
ifelse(sum(pv < 0.05) > 0, TRUE, FALSE)
```
この `TRUE` が、少なくとも1つの帰無仮説を誤って棄却してしまっていることを示す。`FALSE` ならすべての帰無仮説が「正しく」保留されているということを意味する。


このシミュレーションを繰り返し実施するために、関数を作ろう。
`N`は標本サイズ、`K`は説明変数の数（つまり、ファミリーに含まれる帰無仮説の数）、`alpha` は個々の帰無仮説の検証に使う有意水準である。`alpha`の既定値は0.05にしておく。
```{r}
sim_mc <- function(N = 100, K = 1, alpha = 0.05) {
  X <- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)
  y <- rnorm(N)
  fit <- lm(y ~ X)
  pv <- tidy(fit) |> 
    filter(term != "(Intercept)") |> 
    pull(p.value) 
  ifelse(sum(pv < alpha) > 0, TRUE, FALSE)
}
```

この関数を1回だけ使ってみよう。
```{r}
sim_mc(N = 100, K = 20)
```
`TRUE` という答えが返ってきたので、少なくとも1つの帰無仮説が誤って棄却されたことがわかる。

この関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。
まずは、$K=1$の場合（つまり、多重比較ではない場合）について確認する。
```{r}
res_k1 <- replicate(10000, 
                    sim_mc(N = 100, 
                           K = 1, 
                           alpha = 0.05))
```

少なくとも1つの帰無仮説が誤って棄却される割合を計算する。
```{r}
mean(res_k1)
```
有意水準に設定した0.05に近い値が得られた。「帰無仮説が正しいのに誤って帰無仮説を棄却する確率（危険率）」が有意水準なので、この結果は当然である。

次に、$K=20$の場合について確認する。
```{r}
res_k20 <- replicate(10000, 
                     sim_mc(N = 100, 
                            K = 20, 
                            alpha = 0.05))
```

少なくとも1つの帰無仮説が誤って棄却される割合を計算する。
```{r}
mean(res_k20)
```
ファミリーの有意水準が0.59になった。1つひとつの検定で利用する`alpha`の値を「めったにない」と言えそうな5%にしても、全体ではめったにないとは決して言えない59%に
なってしまっており、多重比較の調整が必要であることがわかる。

ボンフェローニの方法で有意水準を補正するとどうなるだろうか。
$K=20$ のときにファミリーの有意水準を0.05にするには、`alpha = 0.05 / 20` にすればよいはずだ。やってみよう。
```{r}
bonferroni_k20 <- replicate(10000, 
                            sim_mc(N = 100, 
                                   K = 20, 
                                   alpha = 0.05 / 20))
```

少なくとも1つの帰無仮説が誤って棄却される割合を計算する。
```{r}
mean(bonferroni_k20)
```
約5%になっており、多重比較の問題は解消されていることがわかる。

<br>

## ボンフェローニの方法の問題

上では、すべての帰無仮説が正しい場合について考えた。
では、いくつかの帰無仮説が正しくない場合にはどうなるだろうか。

20個の説明変数のうち、3つは$y$に関係があるという状況でシミュレーションを行う。
そのための関数を作る。
```{r}
sim_mc2 <- function(N = 100, K = 4, alpha = 0.05, type = 1) {
  X <- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)
  y <- 0.8 * X[, 1] - 0.7 * X[, 2] + 0.4 * X[, 3] + rnorm(N)
  fit <- lm(y ~ X)
  pv <- tidy(fit) |> 
    filter(term != "(Intercept)") |> 
    pull(p.value) 
  if (type == 1) ifelse(sum(pv[4:K] < alpha) > 0, TRUE, FALSE)
  else if (type == 2) ifelse(sum(pv[1:3] < alpha) == 3, FALSE, TRUE)
  else stop("type must be either 1 or 2.")
}
```

この関数を1回だけ使ってみよう。
```{r}
set.seed(2021-11-12)
sim_mc2(N = 50, K = 20)
```
FALSEという答えが返ってきた。正しい帰無仮説はすべて保留された。

この関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。$K=20$の場合について確認する。
```{r}
res_k20b <- replicate(10000, 
                      sim_mc2(N = 50, 
                              K = 20, 
                              alpha = 0.05))
```

正しい帰無仮説のうち少なくとも1つが誤って棄却される割合を計算する。
```{r}
mean(res_k20b)
```
ファミリーの有意水準が0.49になった。1つひとつの検定で利用する`alpha`の値を「めったにない」と言えそうな5%にしても、全体では「めったにない」とは決して言えない52%に
なってしまっており、多重比較の調整が必要であることがわかる。

そこで、ボンフェローニの方法で有意水準を補正する。
$K=20$ なので`alpha = 0.05 / 20` にすればよいはずだ。
```{r}
bonferroni_k20b <- replicate(10000, 
                            sim_mc2(N = 50, 
                                    K = 20, 
                                    alpha = 0.05 / 20))
```

正しい帰無仮説のうち少なくとも1つが誤って棄却される割合を計算する。
```{r}
mean(bonferroni_k20b)
```
約3.7%になっており、正しい帰無仮説を誤って棄却するという問題は解消されていることがわかる。

では、正しくない帰無仮説は棄却できているだろうか。
第2種の誤りの割合を計算したいので、`type = 2` を指定する。
```{r}
bonferroni_k20c <- replicate(10000, 
                            sim_mc2(N = 50, 
                                    K = 20, 
                                    alpha = 0.05 / 20,
                                    type = 2))
mean(bonferroni_k20c)
```
約19%について、正しくない帰無仮説を少なくとも1つは棄却し損ねていることがわかる。

ボンフェローニの補正を行う前についても同じ割合を計算してみよう。
```{r}
res_k20c <- replicate(10000, 
                      sim_mc2(N = 50, 
                              K = 20, 
                              alpha = 0.05,
                              type = 2))
mean(res_k20c)
```

補正前には、この種の誤りは2%ほどしかなかったことがわかる。ボンフェローニの方法を用いると、正しい帰無仮説を誤って棄却するという間違い（第1種のエラー）が減る代わりに、正しくない帰無仮説を棄却することに失敗する（第2種のエラー）が増えるということだ。

<br>

## ホルムの方法

ボンフェローニの方法は、帰無仮説を棄却する基準を厳しくし過ぎる結果、正しくない帰無仮説を棄却することにも失敗している。この点を改良した、ホルムの方法を試してみよう。

ボンフェローニの方法とホルムの方法比較するために、データを生成して回帰分析の結果を保存する関数を作る。
```{r}
sim_mc3 <- function(N = 50, K = 4) {
  X <- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)
  y <- 0.8 * X[, 1] - 0.7 * X[, 2] + 0.3 * X[, 3] + rnorm(N)
  fit <- lm(y ~ X)
  tidy(fit) |> 
    filter(term != "(Intercept)") |> 
    select(term, estimate, p.value)
}
```

この関数を1回だけ使ってみよう。
```{r}
set.seed(2021-11-14)
res1 <- sim_mc3(N = 50, K = 20)
res1
```
有意水準0.05 で個々の帰無仮説が棄却されるかどうか確かめる。
```{r}
res1$p.value < 0.05
```
最初の3つ（正しくない帰無仮説）は棄却されている。残りの17個の帰無仮説は正しいが、そのうち2つが誤って棄却されている（X15とX16の検定結果が`TRUE`すなわち棄却になっている）。

ボンフェローニの方法で補正するとどうなるだろうか。
`p.adjust()` 関数を使うと、多重比較の補正を行うことができる。
```{r}
p.adjust(res1$p.value, method = "bonferroni")
```
これらの値が、ボンフェローニの方法で検定に使うべき$p$値である。これを使って検定を行う。
```{r}
p.adjust(res1$p.value, method = "bonferroni") < 0.05
```
補正なしだと誤って棄却してしまった正しい帰無仮説は保留されている。代わりに、補正無しでは棄却できていた正しくない帰無仮説 ($\beta_3 = 0$) が保留されている。

`p.adjust()` でホルムの方法も利用できる。
```{r}
p.adjust(res1$p.value, method = "holm")
```
これらの値が、ホルムの方法で検定に使うべき$p$値である。これを使って検定を行う。
```{r}
p.adjust(res1$p.value, method = "holm") < 0.05
```
補正なしだと誤って棄却してしまった正しい帰無仮説は保留されている。ボンフェローニの方法と同様に、補正無しでは棄却できていた正しくない帰無仮説 ($\beta_3 = 0$) が保留されている。

2つの方法の$p$値を比較してみよう。
```{r}
cbind(p.adjust(res1$p.value, method = "bonferroni"),
      p.adjust(res1$p.value, method = "holm"))
```
第1列がボンフェローニの方法による$p$値、第2列がホルムの方法による$p$値である。
2つの方法を比較すると、ホルムの方法の$p$値のほうが小さいことがわかる。
つまり、ホルムの方法のほうが、帰無仮説を棄却しやすい。
帰無仮説を棄却しにくくなるというボンフェローニの方法の欠点が改良されていることがわかる。

このシミュレーションを繰り返し実行するための関数を作る。
帰無仮説が3つ未満しか棄却されなかったときに`TRUE` を返すことにする。（厳密には、これは知りたいこととは異なる。たとえば、正しくない帰無仮説がすべて保留され、正しい帰無仮説が誤って3つ棄却されるという場合も考えられる。）
```{r}
sim_b_h <- function(N = 50, K = 20, alpha = 0.05, method) {
  res <- sim_mc3(N = N, K = K)
  sum(p.adjust(res$p.value, method = method) < alpha) < 3
}
```

この関数を1回だけ使ってみよう。
```{r}
sim_b_h(N = 100, K = 20, method = "holm")
```
`FALSE` が返されたので、正しくない帰無仮説はすべて棄却されたことがわかる。

この関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。まず、ボンフェローニの方法を試す。
```{r}
res_b <- replicate(10000, 
                   sim_b_h(N = 50, 
                           K = 20, 
                           method = "bonferroni"))
```

正しくない帰無仮説のうち、少なくとも1つが保留されてしまう割合を計算する。
```{r}
mean(res_b)
```
49.8%について、正しくない帰無仮説を棄却することに失敗している。


次に、ホルムの方法を試す。
```{r}
res_h <- replicate(10000, 
                   sim_b_h(N = 50, 
                           K = 20, 
                           method = "holm"))
```

少なくとも1つの帰無仮説が誤って棄却される割合を計算する。
```{r}
mean(res_h)
```
48.2%について、正しくない帰無仮説を棄却することに失敗している。
ボンフェローニの方法よりも少しだけマシなようだ。

<br>

## 多重比較補正の計算法

上で説明したとおり、分析結果に対して多重比較の補正を行う際は、`p.adjust()` を使う。
ランダムに生成したデータで実行してみよう。

まず、データを作る。
```{r}
set.seed(2021-11-13)
N <- 50  # 標本サイズ
K <- 8   # 説明変数の数
X <- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)
colnames(X) <- paste0("x", 1:K)
myd <- as_tibble(X) |> 
  mutate(y = 0.5 * x1 + 0.4 * x2 + rnorm(n()))
```

回帰分析を実行する。
```{r}
ols <- lm(y ~ ., 
          data = myd)
```

係数の推定値、補正前の$p$値、ボンフェローニの方法による$p$値、ホルムの方法による$p$値を並べて表示する。
```{r}
ols |> 
  tidy() |> 
  filter(term != "(Intercept)") |> 
  select(term, estimate, p.value) |> 
  mutate(Bonferroni = p.adjust(p.value, method = "bonferroni"),
         Holm = p.adjust(p.value, method = "holm")) |> 
  rename(`説明変数` = term,
         `推定値` = estimate,
         `p値` = p.value)
```

それぞれの$p$値が有意水準を下回る場合について帰無仮説を棄却する。
この例では、補正の有無によって検定結果は変わらない。


