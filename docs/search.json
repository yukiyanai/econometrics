[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KUT 計量経済学",
    "section": "",
    "text": "1 はじめに\nこれは、高知工科大学 経済・マネジメント学群で開講されている「計量経済学」（担当：矢内勇生）の講義用資料である。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "index.html#sec-basicinfo",
    "href": "index.html#sec-basicinfo",
    "title": "KUT 計量経済学",
    "section": "1.1 基本情報",
    "text": "1.1 基本情報\n\nシラバス（講義要項）：PDF\n講義スライドは KUTLMS で配布する\nKUTLMS\n\n登録キーはポータルで通知する\n\n授業用のSlackグループ\n\n登録 には大学ドメイン のメールアドレスが必要",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "index.html#sec-refs",
    "href": "index.html#sec-refs",
    "title": "KUT 計量経済学",
    "section": "1.2 教科書・副読本",
    "text": "1.2 教科書・副読本\n\n1.2.1 教科書\n\n浅野正彦, 矢内勇生. 2018.『Rによる計量政治学』オーム社（サポートページ）\n\n\n\n\n1.2.2 副読本\n\n宋財泫, 矢内勇生 （執筆中）『私たちのR：ベストプラクティスの探求』(web book、無料)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "index.html#sec-topics",
    "href": "index.html#sec-topics",
    "title": "KUT 計量経済学",
    "section": "1.3 講義トピックとウェブ資料の対応",
    "text": "1.3 講義トピックとウェブ資料の対応\n授業の内容は、10のトピックに分かれている。シラバス (PDF) にはトピックごとの予習課題と参考文献が記載されている。 各トピックとこのウェブ資料の対応は以下の通りである。\n\n\n\nトピック\nウェブ資料\n\n\n\n\n1. イントロダクション\n実習の準備\n\n\n2. 回帰分析の基礎　　　　　　　　\n回帰分析の基礎\n\n\n3. データの収集・クリーニング\nRによるデータ操作\n\n\n4. 回帰分析による統計的推測 I\nなし\n\n\n5. 回帰分析による統計的推測 II\n統計的推定\n\n\n\n統計的検定と推論\n\n\n6. 因果推論入門　\nなし\n\n\n7. 回帰分析の応用\n重回帰分析\n\n\n\n回帰分析の応用\n\n\n8. 分布結果を効果的に伝える方法\n分析結果の提示法\n\n\n9. 交差項の利用\n交差項の利用\n\n\n10. 多重比較\n多重比較\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n一部の例外を除いて、各ページ（各章）の内容を実行するために必要なパッケージはページの冒頭で読み込むことにする。ページの途中から実行しても動かないことがあると思われるので、その際はページの最初から実行してほしい。\n各ページは（パッケージのインストールとデータファイルの入手を除き）独立なので、ページ単位で実行することができる。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "econometrics-prep.html",
    "href": "econometrics-prep.html",
    "title": "\n2  実習の準備\n",
    "section": "",
    "text": "2.1 プロジェクトの作成\nまずは、授業用のプロジェクトを作ろう。\nプロジェクトができたら、データを保存するための data ディレクトリをプロジェクト内に作ろう。 プロジェクトを開いた状態で、Console に以下のコマンドを入力して実行する。\ndir.create(\"data\")\nスペルミスに注意 (“date” ではない！)。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>実習の準備</span>"
    ]
  },
  {
    "objectID": "econometrics-prep.html#プロジェクトの作成",
    "href": "econometrics-prep.html#プロジェクトの作成",
    "title": "\n2  実習の準備\n",
    "section": "",
    "text": "RStudio を起動する。\n上部のメニューから、File -&gt; New Project... を選択する\n\nNew Directory を選ぶ\n\nNew Project を選ぶ\n\nDirectory Name: にプロジェクト名を英数字で入力する（例：econometrics）\n\nプロジェクトを保存する場所を変えたい場合は、Create project as subdirectory of: の内容を変える（変える必要はない）\n\n\n入力内容に誤りがないことを確認して、Cretea Project をクリックする",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>実習の準備</span>"
    ]
  },
  {
    "objectID": "econometrics-prep.html#必要なパッケージのインストール",
    "href": "econometrics-prep.html#必要なパッケージのインストール",
    "title": "\n2  実習の準備\n",
    "section": "\n2.2 必要なパッケージのインストール",
    "text": "2.2 必要なパッケージのインストール\n\n2.2.1 大学のPCを使う場合\nすべてインストール済みのはずなので、新たにインストールする必要ない。\nインストールが必要な場合は、\n\n\ninstall.packages()（CRANからインストールする場合）\n\nremotes::install_github()（GitHub からインストールする場合）\n\nなどを使ってインストールする。\nProxy の設定を行わないとインストールできない可能性があるが、その場合は授業中に手順を説明する。\n\n2.2.2 自分のパソコンを使う場合\nあらかじめ（自宅等で）必要なパッケージをインストールしておくと、実習の際に時間を節約できる。 以下のコマンドを実行してパッケージをインストールすれば、この実習資料で扱う内容には対応できる。\n\npkgs &lt;- c(\"tidyverse\",\n          \"remotes\",\n          \"pacman\",\n          \"texreg\",\n          \"haven\",\n          \"readxl\",\n          \"broom\",\n          \"shiny\",\n          \"coefplot\",\n          \"interplot\")\n\ninstall.packages(pkgs, dependencies = TRUE)\nremotes::install_github(\"Gedevan-Aleksizde/fontregisterer\", upgrade = \"never\")\n\n授業で追加のパッケージが必要になったときは、授業中にインストール法を説明する。 各自のレポート執筆のためにここに挙げられているものの他にパッケージが必要になったら、\n\n\ninstall.packages()（CRANからインストールする場合）\n\nremotes::install_github()（GitHub からインストールする場合）\n\nなどを使ってインストールする。ただし、大学のネットワークを利用すると、proxy の設定が必要になる可能性がある（自宅等でインストールするほうが簡単である）。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>実習の準備</span>"
    ]
  },
  {
    "objectID": "regression-intro.html",
    "href": "regression-intro.html",
    "title": "\n3  回帰分析の基礎\n",
    "section": "",
    "text": "3.1 準備\nまず、必要なパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom, \n               texreg)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))\n説明のために『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\nまず、このデータをダウンロードして読み込む（データへのパスは各自の状況に応じて変えること。ここでは、RStudioのプロジェクトを利用していて、プロジェクトが存在するフォルダ内にdata という名前のフォルダがあり、その中にデータセットが保存されていると仮定している）。download.file() でダウンロードしたデータが読み込めない（「データが破損している」などの警告がでる）場合は、Webブラウザを使ってデータをダウンロードすること。\ndownload.file(\n  url = \"https://raw.githubusercontent.com/yukiyanai/quant-methods-R/master/data/hr-data.csv\",\n  destfile = \"data/hr-data.csv\")\nデータが入手できたら、データを読み込み、中身を確認する。\nHR &lt;- read_csv(\"data/hr-data.csv\")\n\nRows: 8803 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): ku, status, name, party, wl, smd, party_jpn\ndbl (15): year, kun, party_code, previous, voteshare, age, nocand, rank, vot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(HR)\n\nRows: 8,803\nColumns: 22\n$ year       &lt;dbl&gt; 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996,…\n$ ku         &lt;chr&gt; \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aich…\n$ kun        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,…\n$ status     &lt;chr&gt; \"現職\", \"元職\", \"現職\", \"新人\", \"新人\", \"新人\", \"新人\", \"現…\n$ name       &lt;chr&gt; \"KAWAMURA, TAKASHI\", \"IMAEDA, NORIO\", \"SATO, TAISUKE\", \"IWA…\n$ party      &lt;chr&gt; \"NFP\", \"LDP\", \"DPJ\", \"JCP\", \"others\", \"kokuminto\", \"indepen…\n$ party_code &lt;dbl&gt; 8, 1, 3, 2, 100, 22, 99, 8, 1, 3, 2, 10, 100, 99, 22, 8, 1,…\n$ previous   &lt;dbl&gt; 2, 3, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0,…\n$ wl         &lt;chr&gt; \"当選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"当…\n$ voteshare  &lt;dbl&gt; 40.0, 25.7, 20.1, 13.3, 0.4, 0.3, 0.2, 32.9, 26.4, 25.7, 12…\n$ age        &lt;dbl&gt; 47, 72, 53, 43, 51, 51, 45, 51, 71, 30, 31, 44, 61, 47, 43,…\n$ nocand     &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7,…\n$ rank       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5,…\n$ vote       &lt;dbl&gt; 66876, 42969, 33503, 22209, 616, 566, 312, 56101, 44938, 43…\n$ eligible   &lt;dbl&gt; 346774, 346774, 346774, 346774, 346774, 346774, 346774, 338…\n$ turnout    &lt;dbl&gt; 49.2, 49.2, 49.2, 49.2, 49.2, 49.2, 49.2, 51.8, 51.8, 51.8,…\n$ exp        &lt;dbl&gt; 9828097, 9311555, 9231284, 2177203, NA, NA, NA, 12940178, 1…\n$ expm       &lt;dbl&gt; 9.828097, 9.311555, 9.231284, 2.177203, NA, NA, NA, 12.9401…\n$ vs         &lt;dbl&gt; 0.400, 0.257, 0.201, 0.133, 0.004, 0.003, 0.002, 0.329, 0.2…\n$ exppv      &lt;dbl&gt; 28.341505, 26.851941, 26.620462, 6.278449, NA, NA, NA, 38.2…\n$ smd        &lt;chr&gt; \"当選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"当…\n$ party_jpn  &lt;chr&gt; \"新進党\", \"自民党\", \"民主党\", \"共産党\", \"その他\", \"国民党\",…\n衆議院議員経験があることを表す変数（ダミー変数）と選挙費用を100万 (1e6 \\(=10^6\\)) 円単位で測定する変数を作る。 新しい変数は dplyr::mutate() で作る。\nHR &lt;- HR |&gt;\n    mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"),\n           expm = exp / 1e6)\n次に、データから2009年の結果だけ抜き出し、HR09として保存する。特定の条件に合致するデータを抜き出したいときは、dplyr::filter() を使う。\nHR09 &lt;- HR |&gt; \n  filter(year == 2009)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>回帰分析の基礎</span>"
    ]
  },
  {
    "objectID": "regression-intro.html#rで線形回帰分析を行う",
    "href": "regression-intro.html#rで線形回帰分析を行う",
    "title": "\n3  回帰分析の基礎\n",
    "section": "\n3.2 Rで線形回帰分析を行う",
    "text": "3.2 Rで線形回帰分析を行う\n\n3.2.1 説明変数が二値しかとらないとき（モデル1）\n得票率（結果変数）を議員経験（説明変数）で説明するモデルを考えよう。 議員経験は、現職または元職の候補者なら1、そうでなければ0をとる二値 (binary) 変数（ダミー変数）である。 このモデルを式で表すと、 \\[\n得票率_i = \\beta_1 + \\beta_2 \\cdot 議員経験_i + e_i\n\\] と、なる。\nRでは、lm() で回帰式を推定することができる。\n\nfit_1 &lt;- lm(voteshare ~ experience, data = HR09)\n\nこれで、fit_1 に推定結果（係数の推定値など）が保存される。\n基本的な結果は、summary() で見ることができる。\n\nsummary(fit_1)\n\n\nCall:\nlm(formula = voteshare ~ experience, data = HR09)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.867 -12.072  -5.567   8.583  52.123 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  13.8772     0.6203   22.37   &lt;2e-16\nexperience   30.9898     0.9783   31.68   &lt;2e-16\n\nResidual standard error: 16.19 on 1137 degrees of freedom\nMultiple R-squared:  0.4688,    Adjusted R-squared:  0.4684 \nF-statistic:  1004 on 1 and 1137 DF,  p-value: &lt; 2.2e-16\n\n\nこの結果は少し読みにくいので、代わりに broom:tidy() を利用しよう。\n\ntidy(fit_1)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     13.9     0.620      22.4 3.78e- 92\n2 experience      31.0     0.978      31.7 2.18e-158\n\n\nこの出力の、estimate の列に係数の推定値 (coefficient estimates) が示されている。 これにより、\\(\\hat{\\beta}_1=\\) 13.88, \\(\\hat{\\beta}_2=\\) 30.99, \\(\\hat{\\sigma}=\\) 16.19 が得られた。 したがって、 \\[\\widehat{得票率} = 13.88 +  30.99 \\cdot 議員経験\\] と、なる。\n傾きの値を、分散と共分散を利用して求めてみよう（Slack で配布する補足資料を参照）。分散は var()、共分散 は cov() で計算できる。\n\nwith(HR09, cov(voteshare, experience) / var(experience)) \n\n[1] 30.98979\n\n\nlm() で求めた傾きの値と一致することが確認できる。\n次に、行列計算で回帰係数を求めてみよう（Slack で配布する補足資料を参照）。応答変数の\\(N\\)次元列ベクトルを \\(N \\times 1\\)行列として用意する。\n\ny &lt;- matrix(HR09$voteshare, ncol = 1)\n\n計画行列は、第1列がすべて1、第2列が議員経験なので、\n\nN &lt;- length(y)\nX &lt;- matrix(c(rep(1, N), HR09$experience), ncol = 2)\n\n行列の掛け算は %*%、転置は t()、逆行列は solve() で求められるので、回帰係数 b_hat は、\n\nb_hat &lt;- solve(t(X) %*% X) %*% t(X) %*% y\nb_hat\n\n         [,1]\n[1,] 13.87724\n[2,] 30.98979\n\n\nlm() を使った場合と同じ結果が得られる。\nこの結果を図示しよう。\n\np1 &lt;- ggplot(HR09, aes(x = experience, y = voteshare)) +\n  scale_x_continuous(breaks = c(0, 1)) +\n  geom_jitter(position = position_jitter(width = 0.05), size = 1) +\n　geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"議員経験\", y = \"得票率（%）\")\nplot(p1 + ggtitle(\"得票率と議員経験の関係\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nこの図に推定の不確実性を示すには、geom_smooth(method = 'lm', se = TRUE) とすればよい（が、 se = TRUE はデフォルトなので、seを指定する必要はない）。 デフォルトでは、95パーセント信頼区間が回帰直線の周りに表示される（この例では、区間が狭すぎてよく見えない）。\n\np1_ci95 &lt;- p1 + geom_smooth(method = \"lm\")\nplot(p1_ci95 + ggtitle('得票率と議員経験の関係'))\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n信頼度を変えたいとき、例えば99.99パーセント信頼区間を表示したいときは、次のようにlevelを指定する。\n\np1_ci50 &lt;- p1 + geom_smooth(method = \"lm\", level = 0.9999)\nplot(p1_ci50 + ggtitle(\"得票率と議員経験の関係\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nこの直線の切片である13.88は、議員経験がない候補者の平均得票率（予測得票率）である。 予測値の式の「議員経験」に0を代入すれば、これは明らかである。 議員経験がある候補者の平均得票率（予測得票率）は、「議員経験」に1を代入することで得られる。 代入してみると、 \\(13.88 +30.99 \\cdot 1 = 44.87\\) となる。\nRで議員経験ごとに平均得票率を求め、上の式から求めた予測値と一致するか確かめよう。 dplyr::group_by() を使うと、指定した変数の値が同じグループを作ることができる。\n\nHR09 |&gt; \n  group_by(experience) |&gt;\n  summarize(voteshare = mean(voteshare),\n            .groups = \"drop\")\n\n# A tibble: 2 × 2\n  experience voteshare\n       &lt;dbl&gt;     &lt;dbl&gt;\n1          0      13.9\n2          1      44.9\n\n\nこのように、予測値は説明変数の値を与えられたときの、結果変数の平均値であることがわかる。\n\n\n3.2.2 説明変数が連続値をとるとき（モデル2）\n同様に、得票率を選挙費用（測定単位：100万円）で説明するモデルは、次のように推定できる。\n\nfit_2 &lt;- lm(voteshare ~ expm, data = HR09)\ntidy(fit_2)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.74    0.757       10.2 1.61e- 23\n2 expm            3.07    0.0958      32.1 1.14e-160\n\n\n傾きの値を、分散と共分散を利用して求めてみよう。expm には欠測値があるので、で欠測値がない個体のみを利用する。\n\nHR09 |&gt; \n  filter(!is.na(expm)) |&gt; \n  with(cov(voteshare, expm) / var(expm)) \n\n[1] 3.071721\n\n\nlm() で求めた傾きの値と一致することが確認できる。\n回帰直線を図示する。\n\np2 &lt;- ggplot(HR09, aes(x = expm, y = voteshare)) + \n  geom_point(size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"選挙費用（100万円）\", y = \"得票率（%）\") \nplot(p2 + ggtitle(\"得票率と選挙費用の関係\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 15 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n95パーセント信頼区間を加える。\n\np2_ci95 &lt;- p2 + geom_smooth(method = \"lm\")\nplot(p2_ci95 + ggtitle(\"得票率と選挙費用の関係\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 15 rows containing non-finite values (`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 15 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n複数のモデルで回帰分析を実行し、結果を一つの表にまとめたいときは、texreg::screenreg() が便利である（HTMLに出力するなら htmlreg()、LaTeX (PDF) 用には texreg()を使う）。\n\nmodels &lt;- list(`Model 1` = fit_1,\n               `Model 2` = fit_2)\nscreenreg(models, stars = NULL)\n\n\n===============================\n             Model 1   Model 2 \n-------------------------------\n(Intercept)    13.88      7.74 \n               (0.62)    (0.76)\nexperience     30.99           \n               (0.98)          \nexpm                      3.07 \n                         (0.10)\n-------------------------------\nR^2             0.47      0.48 \nAdj. R^2        0.47      0.48 \nNum. obs.    1139      1124    \n===============================\n\n\nHTMLに出力する場合。\nhtmlreg(models, \n        stars = NULL,\n        doctype = FALSE,\n        caption = \"回帰分析の結果\",\n        caption.above = TRUE)\n\n\n回帰分析の結果\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\n\n\n\n(Intercept)\n\n\n13.88\n\n\n7.74\n\n\n\n\n \n\n\n(0.62)\n\n\n(0.76)\n\n\n\n\nexperience\n\n\n30.99\n\n\n \n\n\n\n\n \n\n\n(0.98)\n\n\n \n\n\n\n\nexpm\n\n\n \n\n\n3.07\n\n\n\n\n \n\n\n \n\n\n(0.10)\n\n\n\n\nR2\n\n\n0.47\n\n\n0.48\n\n\n\n\nAdj. R2\n\n\n0.47\n\n\n0.48\n\n\n\n\nNum. obs.\n\n\n1139\n\n\n1124\n\n\n\n\nPDFに knit する場合には、texreg() を使う（出力は省略する）。\n\ntexreg(models, \n       stars = NULL,\n       caption = \"回帰分析の結果\",\n       caption.above = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>回帰分析の基礎</span>"
    ]
  },
  {
    "objectID": "data-handling.html",
    "href": "data-handling.html",
    "title": "\n4  Rによるデータ操作\n",
    "section": "",
    "text": "4.1 準備\n準備として、必要なパッケージを読み込み、図の日本語が正しく表示されるようにする。\npacman::p_load(tidyverse,\n               haven,\n               readxl)\n（大学のPCで）pacman::p_load() がうまくいかない場合は、以下のようにパッケージを1つずつ読み込む（次回以降も同じようにする）。\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(readxl)\n次に、ggplot2のテーマとフォントの設定を行う。自分好みの設定がある場合は自由に変えてよい。LinuxにはIPAexフォント がインストールされていることを想定している（IPAex はインストールすれば maxOSやWindows でも使える）。\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rによるデータ操作</span>"
    ]
  },
  {
    "objectID": "data-handling.html#データの読み込み",
    "href": "data-handling.html#データの読み込み",
    "title": "\n4  Rによるデータ操作\n",
    "section": "\n4.2 データの読み込み",
    "text": "4.2 データの読み込み\n\n4.2.1 CSV 形式のデータを読む\nデータの形式として最もよく使われるものの1つが、CSV (comma separated values) という形式である。これはただのテキストファイルであり、値がカンマで区切られているだけである。\nこの形式のファイルの中身を理解するために、 fake_data_02.csv を利用しよう。 まずは、上のダウンロードして、プロジェクト内の data ディレクトリ（フォルダ）にファイルを保存する。\n\ndownload.file(\n    url = \"https://yukiyanai.github.io/jp/classes/econometrics1/contents/data/fake_data_02.csv\",\n    destfile = \"data/fake_data_02.csv\"\n)\n\nダウンロードがうまくできないとき（この後開いてみたら中身が壊れているとき）は、ブラウザ上でデータのリンクをクリック（あるいは右クリック; 副クリック）してファイルを保存し、プロジェクト内の data フォルダにダウンロードしたファイルをを移動しよう（以下で登場するファイルについても同様）。\nファイルがダウンロードできたら、そのファイルを開いてみよう。\nまず、エクスプローラー（Macの場合はファインダ）でこのファイルを右クリック（副クリックまたは control を押しながらクリック）し、「プログラムから開く」を選び、LibreOffice Calc または Microsoft Excel で開いてみよう。見慣れた形式（スプレッドシート）でデータが見えるはずだ。確認できたらCalc/Excelを閉じよう。\n次に、同じファイルを同様に「プログラムから開く」でVisual Studio Code（またはその他のテキストエディタ）で開いてみよう。ファイルの中身が見えるはずだ。CSV ファイルは、1行目は変数の名前、2行目以降は各行が1つの観測（このデータの場合は1人）、各行で異なる変数の間にカンマがある（そのため、カンマ区切りデータと呼ばれる）という特徴がある。\nこの形式のメリットとして、\n\nテキストファイルなのでファイルの中身が単純明快\n容量が小さい\nどんな統計ソフトでも読める\n統計ソフトがなくてもメモ帳さえあれば編集可能\n\nなどがあげられる（注意：このファイルを Word 等のワープロソフトで編集しないように。余分な内容が追加されてデータの中身が変わってしまう。）。\nExcel 等に自分でデータを打ち込んで新しいデータセットを作るときは、できるだけこのCSV 形式を選んだ方がよい。\nCSV形式のデータは、readr::read_csv() でRに読み込むことができる。\n\nmycsv1 &lt;- read_csv('data/fake_data_02.csv')\n\nRows: 100 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): id, age, height, weight, income\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nプロジェクト内の data という名前のフォルダに入っていることを data/ の部分で示し、そのフォルダ内の fake_data_02.csv を指定して開いている。 このとき、引用符を忘れないように注意する。引用符はシングル「’」でも、ダブル 「“」でもよい。\nRStudio でデータを読み込むと、右下の EnvironmentタブのDataのところに読み込んだデータセットが表示される。\n念のために中身を少しだけ確認しておこう。\n\nglimpse(mycsv1)\n\nRows: 100\nColumns: 6\n$ id     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;chr&gt; \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    &lt;dbl&gt; 52, 33, 22, 33, 26, 37, 50, 30, 62, 51, 55, 36, 66, 42, 36, 47,…\n$ height &lt;dbl&gt; 174.0, 175.3, 175.0, 170.1, 167.4, 159.3, 173.3, 162.5, 160.2, …\n$ weight &lt;dbl&gt; 63.1, 70.2, 82.6, 81.8, 51.2, 57.8, 68.6, 47.2, 68.2, 59.4, 66.…\n$ income &lt;dbl&gt; 3475810, 457018, 1627793, 6070642, 1083052, 2984929, 1481061, 1…\n\n\n\n4.2.2 Excel 形式のデータを読む\nExcel のデータは、.xlsx または .xls というファイル名拡張子付きで保存されている。 このデータをRで読む方法もあるが、ここではExcel 形式のデータをCSV形式に変換し、それを上で説明した方法で読むことにする。\n例として、fake_data_03.xlsx を使う。まず、このデータをダウンロードし、Excel で開こう。\n\ndownload.file(\n    url = \"https://yukiyanai.github.io/jp/classes/econometrics1/contents/data/fake_data_03.xlsx\",\n    destfile = \"data/fake_data_03.xlsx\"\n)\n\nこれを、CSV形式に変換し、プロジェクト内の data フォルダに保存する。そのために、以下を実行する。\n\nCalc/Excel 左上の「ファイル」から「名前を付けて保存」を選ぶ\n保存先として、プロジェクト（例：ドキュメント/econometrics）内の data フォルダを選ぶ\nポップアップで出てきたウィンドウの「ファイルの種類」で、CSV（カンマ区切り）(*.csv) を選び、保存する\n\n保存できたら、RStudioの右下の data フォルダをクリックし、fake_data_03.csv が保存されていることを確かめよう。\nあとは先ほどと同様の方法でデータを読めばいいので、\n\nmycsv2 &lt;- read_csv(\"data/fake_data_03.csv\")\n\nRows: 100 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): id, age, height, weight, income\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nと、する。RStudio の Environment タブで、データが読み込めたこと（mycsv2というデータが追加されたこと）を確認しよう。\n念のために中身を少しだけ確認しておこう。\n\nglimpse(mycsv2)\n\nRows: 100\nColumns: 6\n$ id     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;chr&gt; \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    &lt;dbl&gt; 46, 22, 61, 48, 44, 23, 46, 60, 30, 25, 26, 22, 36, 65, 20, 58,…\n$ height &lt;dbl&gt; 168.3, 177.1, 171.6, 170.2, 168.5, 160.7, 170.3, 163.7, 174.8, …\n$ weight &lt;dbl&gt; 72.1, 85.4, 81.8, 65.2, 66.0, 50.8, 75.1, 67.1, 76.7, 63.7, 72.…\n$ income &lt;dbl&gt; 2102061, 2729262, 1193016, 3014919, 3982087, 3702544, 7930623, …\n\n\nあるいは、readxl::read_excel() でExcelファイルを読み込むこともできる。\n\n#pacman::p_load(readxl)\nmyxl &lt;- read_excel(\"data/fake_data_03.xlsx\")\n\n念のために中身を少しだけ確認しておこう。\n\nglimpse(myxl)\n\nRows: 100\nColumns: 6\n$ id     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;chr&gt; \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    &lt;dbl&gt; 46, 22, 61, 48, 44, 23, 46, 60, 30, 25, 26, 22, 36, 65, 20, 58,…\n$ height &lt;dbl&gt; 168.3, 177.1, 171.6, 170.2, 168.5, 160.7, 170.3, 163.7, 174.8, …\n$ weight &lt;dbl&gt; 72.1, 85.4, 81.8, 65.2, 66.0, 50.8, 75.1, 67.1, 76.7, 63.7, 72.…\n$ income &lt;dbl&gt; 2102061, 2729262, 1193016, 3014919, 3982087, 3702544, 7930623, …\n\n\n\n4.2.3 複数のデータセットの扱い\nここまでで3つのデータセットを読み込んだ（そのうち2つの内容は同じだが）ので、RStudioのEvironment タブには、3つのデータセット（データフレーム）、mycsv1, mycsv2, myxl が表示されているはずである。このように、Rには複数のデータを同時に利用できるというメリットがある。\nこのうち、csvファイルから読み込んだデータセットについて、データに含まれる変数を確認してみよう。\n\nnames(mycsv1)\n\n[1] \"id\"     \"sex\"    \"age\"    \"height\" \"weight\" \"income\"\n\nnames(mycsv2)\n\n[1] \"id\"     \"sex\"    \"age\"    \"height\" \"weight\" \"income\"\n\n\n2つのデータセットに含まれる変数名は同じようである。\nでは、2つのデータはまったく同じものだろうか。ためしに、それぞれのデータセット身長 (height) の平均値を求めてみよう。\n\nmean(mycsv1$height)\n\n[1] 163.746\n\nmean(mycsv2$height)\n\n[1] 162.907\n\n\n平均値が異なる。つまり、変数名は同じでも、データの中身は違うようだ。\nこのように、異なるデータセットが同じ名前の変数を含んでいることがあるので注意が必要だ。既に学習したとおり、Rでは データセット名$変数名 とすることで、同じ名前の変数でも、異なるデータセットに属している場合にはそれらを区別して利用することができる。\n\n4.2.4 他の統計ソフト用のデータを読む\n\n4.2.4.1 Stata\n\nR以外に計量経済学でよく利用される分析ソフトとして、Stataというものがある。Stata のデータセットには、.dta というファイル名拡張子が付いている。\nStataのファイルをRで読みたいときは、haven というパッケージに含まれる read_dta()という関数を使う。\n例として、fake_data_stata.dta をダウンロードし、data フォルダに保存しよう。\n\ndownload.file(\n    url = \"https://yukiyanai.github.io/jp/classes/econometrics1/contents/data/fake_data_stata.dta\",\n    destfile = \"data/fake_data_stata.dta\"\n)\n\nこれを読むには、まず haven パッケージを読み込むことが必要である（インストールされていない場合はまずインストールする）。\n\n#pacman::p_load(haven)\n\nパッケージが読み込めたら、データを読む。\n\nmydta &lt;- read_dta(\"data/fake_data_stata.dta\")\n\nRStudio の Environment タブで、データが読み込めたことを確認しよう。\n念のために中身も少しだけ確認しておこう。\n\nglimpse(mydta)\n\nRows: 100\nColumns: 6\n$ id     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;chr&gt; \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    &lt;dbl&gt; 31, 57, 52, 46, 58, 49, 52, 34, 57, 41, 43, 43, 40, 45, 41, 64,…\n$ height &lt;dbl&gt; 166.6, 154.3, 168.1, 178.9, 168.7, 155.1, 169.1, 174.4, 166.8, …\n$ weight &lt;dbl&gt; 59.8, 51.4, 61.2, 71.8, 70.5, 32.7, 62.2, 70.2, 68.5, 55.3, 56.…\n$ income &lt;dbl&gt; 1094707, 370882, 12449508, 25811696, 1182427, 706000, 825437, 1…\n\n\n\n4.2.4.2 SPSS\n\nかつてよく使われた（今でも経済学以外の分野では使われることがある）統計分析ソフトに、SPSSというものがある。 SPSS 形式のデータには、.savという拡張子が付いている。 Rでは、haven::read_sav() （または haven::read_spss()）で読み込める。\n例として、fake_data_spss.sav をダウンロードし、data フォルダに保存しよう。\n\ndownload.file(url = \"https://yukiyanai.github.io/jp/classes/econometrics1/contents/data/fake_data_spss.sav\",\n              destfile = \"data/fake_data_spss.sav\")\n\nこのファイルは、以下のコマンドで読み込める。\n\nmysav &lt;- read_sav(\"data/fake_data_spss.sav\")\n\nRStudio の Environment タブで、データが読み込めたことを確認しよう。\n念のために中身も少しだけ確認しておこう。\n\nglimpse(mysav)\n\nRows: 100\nColumns: 6\n$ id     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ sex    &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age    &lt;dbl&gt; 67, 57, 58, 40, 24, 59, 58, 31, 24, 53, 31, 29, 40, 61, 43, 53,…\n$ height &lt;dbl&gt; 167.7, 167.1, 164.9, 171.7, 167.2, 172.9, 160.6, 167.7, 167.9, …\n$ weight &lt;dbl&gt; 58.5, 54.5, 62.9, 68.8, 59.8, 83.6, 54.5, 72.9, 57.6, 54.2, 49.…\n$ income &lt;dbl&gt; 1659808, 1550051, 3139595, 4563089, 1864069, 5311530, 42952064,…\n\n\n\n4.2.4.3 その他\n\nRはこの他には様々な形式のデータを読むことができる。必要に応じて他の方法も解説するが、この授業で他の形式が必要になることはないはずである。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rによるデータ操作</span>"
    ]
  },
  {
    "objectID": "data-handling.html#データの前処理",
    "href": "data-handling.html#データの前処理",
    "title": "\n4  Rによるデータ操作\n",
    "section": "\n4.3 データの前処理",
    "text": "4.3 データの前処理\n当たり前のことだが、データ分析にはデータが必要である。データはどうやって手に入れればいいだろうか。\n現代では、インターネットを通じて様々なデータセットを手に入れることができる。例えば、日本の政府が集めたデータ（政府統計）の多くは、総務省統計局のウェブサイト や e-Stat から入手できる。あるいは、先進諸国の経済指標は、OECD.Stat からダウンロードすることができる。\nデータを入手したらすぐ分析したくなるだろう。しかし、たいていの場合、入手したデータをそのままの状態で分析するのは難しい。インターネットからダウンロードしたデータセットは、データ分析に適した形式でなかったり、分析対象となる変数以外の余計な情報を含んでいたり、変数の中におかしな値（典型的には、入力ミス）をもっていたりする。そのようなデータセットをありのままで分析しようとすると、誤った推論をしたり、分析を実行するためのRコードがそもそも動かないという問題に直面する。\nそこで必要になるのが、データの前処理 (pre-processing) である。データの収集から分析結果の報告までの一連の過程全体を「データ分析」と呼ぶことにすると、通常、データ分析でもっとも多くの時間を割くのが「前処理」の部分である。たとえば、線形回帰分析を実行することを考えよう。自分が推定した特定の統計モデル（統計モデルについては今後の授業で説明する）とそのために必要なデータフレームさえあれば、回帰分析は lm() ですぐに実行可能である。つまり、統計モデルを推定するのは、1つのコマンドで実行可能である。\nしかし、これを可能にするためには、lm() が期待する形式でデータフレームを用意する必要がある。具体的には、行列形式のデータセットで、各行\\(i\\)が1ひとつの観測個体を表しており、各列\\(j\\)が各変数を表し、各セル (\\(i, j\\)) が個体\\(i\\)の変数\\(j\\)の値を保持している必要がある。これまではすでにこの形式で用意されたデータセットを使って実習してきたが、この形式のデータを作るのは、必ずしも楽ではない。少なくとも、決まったRのコマンドを1つ実行しさえすれば望んだデータフレームができるというような簡単な作業ではない。\nデータの前処理は、データ分析をする上で避けて通れない道である。今回は、Rでデータの前処理をするための便利な方法を学習しよう。\n\n4.3.1 Tidy なデータ\nまず、最終的にどのようなデータフレームが必要かを理解しよう。ここでは、データ分析の方法として一般的な線形回帰分析（あるいは、一般化線形モデル; GLM）を行うためのデータフレームを考える（他の方法で分析を行う場合は、異なる形式のデータフレームを用意する必要があるかもしれない。たとえば、コンジョイント分析を行う場合には、今回説明するものとは異なるデータフレームが必要である）。\n私たちが通常必要とするのは、tidy data（整然データ）と呼ばれるものである。整然データについては、宋・矢内『私たちのR』第16章を参照されたい。整然データを用意すれば、回帰分析だけでなく、ggplot2 を使った作図にも使える。\nTidy data は、次の4つの条件を満たすデータである。\n\n1つの列は、1つの変数を表す。\n1つの行は、1つの観測を表す。\n1つのセル（特定の列の特定の行）は、1つの値を表す。\n1つの表は、1つの観測単位 (unit of observation) をもつ（異なる観測単位が混ざっていない）\n\nデータを入手したら（あるいは、自分でデータセットを作るときは）、この条件がすべて満たされているか確認しよう。満たされていなければ、tidy data に変換するための前処理が必要になる。\n\n4.3.2 様々な前処理\nCSVファイルは用意されていると仮定する。\n官庁のウェブサイト等で公開されているデータは、ファイルの冒頭にデータの説明文などの、データセットの中身ではない情報が含まれている場合がある。例えば、最初の3行が余計だとすると、その3行をとばしてデータを読み込みたい。そういう場合は、readr::read_csv() の skip 引数を指定する。foo.csv というデータセットがあるとすると（実際にはないので、以下のコマンドを実行してもエラーになる。以下、「あるとする」と言った場合は同様）、次のようにして読める。\n\nMYD &lt;- read_csv(\"foo.csv\", skip = 3)\n\nRでは欠測値（本来ならセルに入っているべき値が、何らかの理由 [アンケートでの回答拒否、政府が情報を公開していない、etc.] で欠けている場合）は、NA で表すことになっている。 自分が用意したCSVファイル（あるいはその元になったMS Excel ファイル）で、 NA と入力されているか完全に空欄になっているセルがある場合、readr::read_csv() は自動的にRのNA に変換してくれる。しかし、インターネット等でダウンロードしたファイルでは、欠測を他の方法で表記している場合があり、対応が必要である。read_csv() では、na 引数を指定すればよい。例えば、欠測が.（ドット）で表されている foo.csv があるとすれば、\n\nMYD &lt;- read_csv(\"foo.csv\", na = '.') \n\nとすればよい。あるいは、欠測が 99 または -9 のいずれかで表現されているなら、\n\nMYD &lt;- read_csv(\"foo.csv\", na = c(99, -9))\n\nとする。\nここからは、実際のデータを使って実習しよう。 『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\nまず、データをダウンロードして保存する。\n\ndownload.file(\n    url = \"https://raw.githubusercontent.com/yukiyanai/quant-methods-R/master/data/hr-data.csv\",\n    destfile = \"data/hr-data.csv\"\n)\n\nデータを読み込む。\n\nmyd &lt;- read_csv(\"data/hr-data.csv\")\n\nRows: 8803 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): ku, status, name, party, wl, smd, party_jpn\ndbl (15): year, kun, party_code, previous, voteshare, age, nocand, rank, vot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\ndownload.file() でダウンロードできなかったり、ダウンロードしたファイルが壊れているときは、データのリンクをクリック（または右クリック）して手動でダウンロードして使う（今後も同様）。\n既に学習済みのはずだが、特定の条件を満たす部分だけ利用したい場合は、dplyr::filter() を使う。 year の値が1996で、party_jpn が自民党のものだけ取り出してみよう。 取り出す前のデータを確認する。\n\nwith(myd, table(year, party_jpn))\n\n      party_jpn\nyear   さきがけ その他 みんな 保守党 保守新党 公明党 共産党 国民党 国民新党\n  1996       13     20      0      0        0      0    299     10        0\n  2000        0      8      0     16        0     18    300      0        0\n  2003        0      3      0      0       11     10    300      1        0\n  2005        0      1      0      0        0      9    275      0       10\n  2009        0      1     14      0        0      6    152      0        9\n  2012        0      5     65      0        0      9    299      0        2\n  2014        0      5      0      0        0      9    292      0        0\n  2017        0     44      0      0        0      9    206      0        0\n      party_jpn\nyear   大地 希望 幸福実現党 新党日本 新社会党 新進党 未来 次世代 民主党 無所属\n  1996    0    0          0        0       37    235    0      0    143     85\n  2000    0    0          0        0        1      0    0      0    242     79\n  2003    0    0          0        0        0      0    0      0    267     92\n  2005    1    0          0        6        0      0    0      0    289     70\n  2009    0    0        292        2        0      0    0      0    271     70\n  2012    7    0         20        1        0      0  111      0    264     48\n  2014    0    0          0        0        0      0    0     39    178     45\n  2017    0  198          0        0        0      0    0      0      0     73\n      party_jpn\nyear   無所属の会 生活 社民党 立憲民主党 維新の会 維新の党 自民党 自由党\n  1996          0    0     43          0        0        0    288      0\n  2000          9    0     71          0        0        0    271     61\n  2003          0    0     64          0        0        0    277      0\n  2005          0    0     38          0        0        0    290      0\n  2009          0    0     31          0        0        0    291      0\n  2012          0    0     23          0      151        0    289      0\n  2014          0   13     18          0        0       77    283      0\n  2017          0    0     19         63       47        0    277      0\n      party_jpn\nyear   自由連合\n  1996       88\n  2000      123\n  2003        1\n  2005        0\n  2009        0\n  2012        0\n  2014        0\n  2017        0\n\n\nfilter で条件（1996年の自民党候補）を満たすものを取り出す。\n\nLDP1996 &lt;- filter(myd, year == 1996, \n                  party_jpn == \"自民党\")\n\n確認する。\n\nwith(LDP1996, table(year, party_jpn))\n\n      party_jpn\nyear   自民党\n  1996    288\n\n\n上の操作は、パイプ |&gt; を使うと次のように書ける。\n\nLDP1996 &lt;- myd |&gt; \n    filter(year == 1996, \n           party_jpn == \"自民党\")\n\n特定の変数だけを残したい場合は、dplyr::select() で変数を指定する。 まず、myd にどんな変数があるのか見てみよう。\n\nnames(myd)\n\n [1] \"year\"       \"ku\"         \"kun\"        \"status\"     \"name\"      \n [6] \"party\"      \"party_code\" \"previous\"   \"wl\"         \"voteshare\" \n[11] \"age\"        \"nocand\"     \"rank\"       \"vote\"       \"eligible\"  \n[16] \"turnout\"    \"exp\"        \"expm\"       \"vs\"         \"exppv\"     \n[21] \"smd\"        \"party_jpn\" \n\n\nこの中で、year と name と vs だけ残してみよう。\n\nsub1 &lt;- myd |&gt; \n    select(year, name, vs)\nnames(sub1)\n\n[1] \"year\" \"name\" \"vs\"  \n\n\nkun からparty までの変数をすべて残したいときは、次のように書ける。\n\nsub2 &lt;- myd |&gt; \n    select(kun:party)\nnames(sub2)\n\n[1] \"kun\"    \"status\" \"name\"   \"party\" \n\n\n特定の変数だけ除外したいときは、!を使って指定する。status と vs だけ消してみよう。\n\nsub3 &lt;- myd |&gt; \n    select(!c(status, vs))\nnames(sub3)\n\n [1] \"year\"       \"ku\"         \"kun\"        \"name\"       \"party\"     \n [6] \"party_code\" \"previous\"   \"wl\"         \"voteshare\"  \"age\"       \n[11] \"nocand\"     \"rank\"       \"vote\"       \"eligible\"   \"turnout\"   \n[16] \"exp\"        \"expm\"       \"exppv\"      \"smd\"        \"party_jpn\" \n\n\n特定の文字から始まる変数だけ残したいときは、starts_with() が使える。変数名が “e” から始まるものだけ残してみよう（この例には特に意味はないが、変数名が x1, x2, x3, y1, y2, y3,… のようになっていて、xから始まる変数だけ取り出したいときなどに便利である）。\n\nsub4 &lt;- myd |&gt; \n    select(starts_with(\"e\"))\nnames(sub4)\n\n[1] \"eligible\" \"exp\"      \"expm\"     \"exppv\"   \n\n\n同じように、特定の文字で終わるものは、ends_with() で取り出せる。変数名が “d” で終わるものだけ残してみよう（この例には特に意味はないが、変数名が x2000, x2001, x2002, …, y2000, y2001, y2002,… のようになっていて、“2000”で終わる変数だけ取り出したいときなどに便利である）。\n\nsub5 &lt;- myd |&gt; \n    select(ends_with(\"d\"))\nnames(sub5)\n\n[1] \"nocand\" \"smd\"   \n\n\n変数名に特定の文字列を含むものは、contains() で取り出せる。変数名に”te” が含まれるものだけ取り出してみよう。\n\nsub6 &lt;- myd |&gt; \n    select(contains(\"te\"))\nnames(sub6)\n\n[1] \"voteshare\" \"vote\"     \n\n\nfilter()してからselect() するなど、複数の操作を行いたいときは、パイプでつなぐ。例えば、\n\nLDP1996_sub1 &lt;- myd |&gt; \n    filter(year == 1996, \n           party_jpn == \"自民党\") |&gt; \n    select(year, name, vs)\nnames(LDP1996_sub1)\n\n[1] \"year\" \"name\" \"vs\"  \n\n\nということができる。つまり、|&gt; （パイプ）は、“and then” という接続詞である考えることができる。\nこれをパイプを使わずに実行するには、次のように書く必要がある。\n\nLDP1996_sub1_2 &lt;- select(filter(myd, year == 1996, party_jpn == \"自民党\"), year, name, vs)\nnames(LDP1996_sub1_2)\n\n[1] \"year\" \"name\" \"vs\"  \n\n\n書くのも読むのも大変である。\n新しい変数を作りたいときは、dplyr::mutate() を使う。例えば、パーセント（0以上100以下）で測定されている turnout（投票率）という変数を元に、0から1の範囲で投票率を測るturnout2という変数を作りたいなら、次のようにする。\n\nmyd &lt;- myd |&gt; \n    mutate(turnout2 = turnout / 100)\nrbind(\n  summary(myd$turnout),\n  summary(myd$turnout2)\n)\n\n       Min. 1st Qu. Median       Mean  3rd Qu.   Max. NA's\n[1,] 48.900  57.800 62.700 62.9562247 67.52500 83.800 1895\n[2,]  0.489   0.578  0.627  0.6295622  0.67525  0.838 1895\n\n\n複数の変数を同時に作ることもできる。自民党候補であることを表す LDP というダミー変数と、民主党候補のDPJダミーを作ろう。\n\nmyd &lt;- myd |&gt; \n    mutate(LDP = ifelse(party_jpn == \"自民党\", 1, 0),\n           DPJ = ifelse(party_jpn == \"民主党\", 1, 0))\nwith(myd, table(party_jpn, LDP))\n\n            LDP\nparty_jpn       0    1\n  さきがけ     13    0\n  その他       87    0\n  みんな       79    0\n  保守党       16    0\n  保守新党     11    0\n  公明党       70    0\n  共産党     2123    0\n  国民党       11    0\n  国民新党     21    0\n  大地          8    0\n  希望        198    0\n  幸福実現党  312    0\n  新党日本      9    0\n  新社会党     38    0\n  新進党      235    0\n  未来        111    0\n  次世代       39    0\n  民主党     1654    0\n  無所属      562    0\n  無所属の会    9    0\n  生活         13    0\n  社民党      307    0\n  立憲民主党   63    0\n  維新の会    198    0\n  維新の党     77    0\n  自民党        0 2266\n  自由党       61    0\n  自由連合    212    0\n\nwith(myd, table(party_jpn, DPJ))\n\n            DPJ\nparty_jpn       0    1\n  さきがけ     13    0\n  その他       87    0\n  みんな       79    0\n  保守党       16    0\n  保守新党     11    0\n  公明党       70    0\n  共産党     2123    0\n  国民党       11    0\n  国民新党     21    0\n  大地          8    0\n  希望        198    0\n  幸福実現党  312    0\n  新党日本      9    0\n  新社会党     38    0\n  新進党      235    0\n  未来        111    0\n  次世代       39    0\n  民主党        0 1654\n  無所属      562    0\n  無所属の会    9    0\n  生活         13    0\n  社民党      307    0\n  立憲民主党   63    0\n  維新の会    198    0\n  維新の党     77    0\n  自民党     2266    0\n  自由党       61    0\n  自由連合    212    0\n\n\n変数名を変えるには、dplyr::rename() を使う。\n例えば、turnout2 の名前を tohyoritsu に変更するには、次のようにする。\n\nmyd &lt;- myd |&gt;  \n    rename(tohyoritsu = turnout2)\nnames(myd)\n\n [1] \"year\"       \"ku\"         \"kun\"        \"status\"     \"name\"      \n [6] \"party\"      \"party_code\" \"previous\"   \"wl\"         \"voteshare\" \n[11] \"age\"        \"nocand\"     \"rank\"       \"vote\"       \"eligible\"  \n[16] \"turnout\"    \"exp\"        \"expm\"       \"vs\"         \"exppv\"     \n[21] \"smd\"        \"party_jpn\"  \"tohyoritsu\" \"LDP\"        \"DPJ\"       \n\n\n教科書 5.3.3節 (p.78から) の例を考える。 まず、横長データ を手に入れる（download.file() がうまくいかないときは、リンクをクリックして保存）。\n\ndownload.file(url = \"https://git.io/fAnmx\",\n              destfile = \"data/wide-table.csv\")\n\nデータファイルを読んで中身を確認する。\n\nGDP &lt;- read_csv(\"data/wide-table.csv\")\n\n\nGDP\n\n# A tibble: 3 × 4\n  country gdp2000 gdp2005 gdp2010\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 A         40000   42000   44000\n2 B         38000   40000   43000\n3 C         52000   52100   52500\n\n\nこれを縦長に変更する。（教科書第1刷では、tidyr::gather() の使い方が紹介されているが、）ここではtidyr::pivot_longer() を使おう。\n\nGDP_long &lt;- GDP |&gt; \n    pivot_longer(cols = !country,      # 縦長にする範囲：country 以外\n                 names_to = \"year\",    # 元の列がどれだっかを区別する変数：年\n                 names_prefix = \"gdp\", # 元の変数名のうち、区別に不要な部分\n                 values_to = \"gdp\")    # 元の値を保持する変数名\nGDP_long\n\n# A tibble: 9 × 3\n  country year    gdp\n  &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n1 A       2000  40000\n2 A       2005  42000\n3 A       2010  44000\n4 B       2000  38000\n5 B       2005  40000\n6 B       2010  43000\n7 C       2000  52000\n8 C       2005  52100\n9 C       2010  52500\n\n\nこのように、望んだ形式のデータに一発で変換できる。\nこれを横長に戻してみよう。（教科書1刷で紹介されているtidyr::spread() の代わりに、）tidyr::pivot_wider() を使おう。\n\nGDP_wide &lt;- GDP_long |&gt;  \n    pivot_wider(names_from = year,    # 横長にした後の列を区別する変数\n                names_prefix = \"gdp\", # 横長にした後の変数名の冒頭につける文字列（オプション）\n                values_from = gdp)    # 縦長から横長に分配する値\nGDP_wide\n\n# A tibble: 3 × 4\n  country gdp2000 gdp2005 gdp2010\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 A         40000   42000   44000\n2 B         38000   40000   43000\n3 C         52000   52100   52500\n\n\nこのように、元の横長データに戻すことができる。\npivot_longer() とpivot_wider() を比較して、対応関係を理解しよう。\n自分でデータフレームを作りたいときは、tibble::tibble() を使う。\n\nnewd &lt;- tibble(id = 1:100,\n               x = rnorm(100, mean = 10, sd = 2)) |&gt; \n    mutate(y = 1.2 + 0.8 * x + rnorm(100, mean = 0, sd = 1))\nglimpse(newd)\n\nRows: 100\nColumns: 3\n$ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ x  &lt;dbl&gt; 12.024695, 12.288869, 7.033155, 8.856460, 10.349913, 12.129229, 11.…\n$ y  &lt;dbl&gt; 10.543795, 11.870085, 7.612501, 7.491888, 9.963130, 11.272057, 9.40…\n\n\n複数のデータセットを結合する方法については、教科書第5章と宋・矢内『私たちのR』第14章を参照されたい。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rによるデータ操作</span>"
    ]
  },
  {
    "objectID": "regression-estimation.html",
    "href": "regression-estimation.html",
    "title": "\n5  回帰分析による統計的推定\n",
    "section": "",
    "text": "5.1 準備\nまず、必要なパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom, \n               shiny)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>回帰分析による統計的推定</span>"
    ]
  },
  {
    "objectID": "regression-estimation.html#単回帰のシミュレーション",
    "href": "regression-estimation.html#単回帰のシミュレーション",
    "title": "\n5  回帰分析による統計的推定\n",
    "section": "\n5.2 単回帰のシミュレーション",
    "text": "5.2 単回帰のシミュレーション\n授業用のShiny アプリを使ってみよう。 shiny::runGitHub() でアプリを呼び出して使う。使い方は実習中に説明する(username は自分の名前ではなく、yukiyanai のままにする)。\n\nrunGitHub(username = \"yukiyanai\",\n          repo = \"simple_ols_sim\",\n          ref = \"main\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>回帰分析による統計的推定</span>"
    ]
  },
  {
    "objectID": "regression-estimation.html#回帰分析のシミュレーション",
    "href": "regression-estimation.html#回帰分析のシミュレーション",
    "title": "\n5  回帰分析による統計的推定\n",
    "section": "\n5.3 回帰分析のシミュレーション",
    "text": "5.3 回帰分析のシミュレーション\n応答変数 \\(Y\\) と説明変数 \\(X\\) の真の関係（つまり、母集団における関係）が以下の式で表されるとする。 \\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i.\n\\]\nここで、\\(\\beta_0\\) が\\(y\\)切片、\\(\\beta_1\\) が回帰直線の傾きである。 \\(\\varepsilon\\) は誤差項と呼ばれるもので、\\(\\varepsilon \\sim \\mbox{Nomarl}(0, \\sigma)\\)であり、\\(\\sigma\\) は正規分布 (normal distribution) の標準偏差である。 つまり、誤差\\(\\varepsilon_i\\)は平均0、標準偏差\\(\\sigma\\)の正規分布に従う。\nこの関係は、次のように書くこともできる。 \\[\nY_i \\sim \\mbox{Normal}(\\beta_0 + \\beta_1 X_i, \\sigma).\n\\]\n例として、\\(\\beta_0 = 2\\)、\\(\\beta_1 = 0.8\\) の場合について考えよう。このとき、\\(Y\\) と\\(X\\) の真の関係（「真」の関係などというものがあれば、だが）は、 \\[\nY_i = 2 + 0.8X_i + \\varepsilon_i\n\\] と表せる。\n回帰分析では、観測された\\(Y\\) と\\(X\\) の値から、\\(\\beta_0\\) と \\(\\beta_1\\) の値を推定することになる。 以下のシミュレーションでは、回帰分析による推定が、\\(\\beta_0 = 2\\)、\\(\\beta_1 = 0.8\\)という値にどれだけ近い値を出せるかどうかを確かめる。\n\n5.3.1 シミュレーションの方法\nシミュレーションを行うために、データを生成する。私たちは真の関係を知っているので、その関係を利用する。\nまず、標本サイズ \\(N\\) を決める。試しに、標本サイズを5にしてみよう。\n\nN &lt;- 5\n\n次に、\\(X\\) の値を決める。とりあえず、\\([-5, 5]\\) の一様分布から\\(X\\)の実現値（観測値）\\(x\\) をランダムに作ってみよう。\n\nx &lt;- runif(N, min = -5, max = 5)\n\n続いて、\\(Y\\)の実現値\\(y\\) を生成する。真の関係は、\\(Y = 2 + 0.8X + \\varepsilon\\) である。\nまず、切片と傾きの値を設定する。\n\nbeta0 &lt;- 2\nbeta1 &lt;- 0.8\n\n次に、\\(\\varepsilon\\) を作る。 \\(\\varepsilon \\sim \\mbox{Normal}(0, \\sigma)\\) なので、誤差項の標準偏差 \\(\\sigma\\)（あるいは分散 \\(\\sigma^2\\)）を決める必要がある。ここでは、\\(\\sigma = 2\\) としてみよう。\n\nsigma &lt;- 2\n\nこの標準偏差を使って、\\(\\varepsilon\\) をランダムに生成する。\n\nepsilon &lt;- rnorm(N, mean = 0, sd = sigma)\n\nこれで、\\(y\\) が生成できる。\n\ny &lt;- beta0 + beta1 * x + epsilon\n\n\\(X\\) の観測値 \\(x\\) と\\(Y\\) の観測値 \\(y\\) が手に入ったので、回帰分析を実行してみよう。 まず、（必要ではないが）tidy data の条件を満たすデータフレーム df を作ろう。\n\ndf &lt;- tibble(y = y,\n             x = x)\n\nこのデータフレームを使って、回帰分析を実行してみよう。\n\nfit &lt;- lm(y ~ x, data = df)\ntidy(fit) |&gt; \n  mutate_if(is.double, round, digits = 2)  # 小数第2位まで表示\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)     2.34      1.44      1.62    0.2 \n2 x               0.43      0.5       0.87    0.45\n\n\n\\(\\beta_0\\)と\\(\\beta_1\\)の推定値をそれぞれ \\(b_0\\)、\\(b_1\\) とすると、\\(b_0\\)=2.34、\\(b_1\\)=0.43 である。推定はどれくらい正確だろうか？\n\n5.3.2 複数回のシミュレーション\n1回だけのシミュレーションでは、その結果が偶然得られたものなのか、必然的な結果なのかの区別がつかない。そこで、上のシミュレーションを繰り返す。複数のコマンドを何度も実行するのは面倒なので、シミュレーション用の関数を function() で定義してしまおう。\n単回帰 (simple regression) のシミュレーションを行うので、関数名をsimple_reg にする。\n\nsimple_reg &lt;- function(n, beta0 = 0, beta1 = 1, sigma = 1) {\n  ## 単回帰のシミュレーションを実行するための関数\n  ## 引数：n = 標本サイズ\n  ##       beta0 = 真のy切片（既定値は0）\n  ##       beta1 = 真の傾き（既定値は1）\n  ##       sigma = 誤差項の標準偏差（既定値は1）\n  \n  # x を一様分布 Uniform(-5, 5) から作る\n  x &lt;- runif(n, min = -5, max = 5)\n  \n  # epsilon を正規分布 N(0, sigma^2) から作る\n  epsilon &lt;- rnorm(n, mean = 0, sd = sigma)\n  \n  # 真のモデルからyを作る\n  y &lt;- beta0 + beta1 * x + epsilon\n  \n  # 回帰分析を実行する\n  fit &lt;- lm(y ~ x)\n  \n  # beta の推定値を関数の出力として返す\n  return(coef(fit))\n}\n\nfunction() で定義した関数は、return() で指定された対象を返し（これを戻り値または返り値, [return value] と呼ぶ）、終了する。ここで定義した関数は、切片と傾きの推定値を返す。\n試しに、この関数を使ってみよう。私たちが実行したいのは、\\(N = 5\\)、\\(\\beta_0 = 2\\)、\\(\\beta_1 = 0.8\\)、\\(\\sigma = 2\\) の場合なので、次のようにする。\n\nsimple_reg(n = 5, beta0 = 2, beta1 = 0.8, sigma = 2)\n\n(Intercept)           x \n  2.5469506   0.9807717 \n\n\nもう1度やってみよう。\n\nsimple_reg(n = 5, beta0 = 2, beta1 = 0.8, sigma = 2)\n\n(Intercept)           x \n -0.1090080   0.3118554 \n\n\nもう1度やってみよう。\n\nsimple_reg(n = 5, beta0 = 2, beta1 = 0.8, sigma = 2)\n\n(Intercept)           x \n  2.4922408   0.6920176 \n\n\nこのように、実行する度に異なる結果が得られる。\nこれを繰り返し実行すれば、最小二乗法がどれくらい正確に推定を行えるか理解することができるはずである。しかし、得られた結果が偶然の結果ではないと信じるためには、繰り返し回数を多くする必要がある。たとえば、1,000回のシミュレーションを行う場合、上のように毎回コマンドを実行するのは面倒である。\nそこで、forループを使ってシミュレーションを自動化しよう。まず、シミュレーション回数 n_sims を決める。\n\nn_sims &lt;- 1000\n\n次に、シミュレーション結果を保存するための容器を用意する。私たちのシミュレーションでは、シミュレーションの繰り返し回数が n_sims 回、推定する母数（パラメタ, parameters）の数が2つなので、n_sims行$$2列の行列を用意しよう。行列は、matrix() で作れる。 matrix() では、行列の要素と、行数 (nrow)、列数 (ncol) を指定する。ここでは空の容器を作りたいので、要素をすべて NA（欠測値）にした行列を作る。\n\nresult &lt;- matrix(NA, nrow = n_sims, ncol = 2)\n\n行列の最初の5行を確認してみよう。\n\nresult[1:5, ]\n\n     [,1] [,2]\n[1,]   NA   NA\n[2,]   NA   NA\n[3,]   NA   NA\n[4,]   NA   NA\n[5,]   NA   NA\n\n\n要素がすべて NA になっていることがわかる。\nわかりやすいように、行列の列に名前をつけておこう。\n\ncolnames(result) &lt;- c(\"b0\", \"b1\")\n\n準備ができたので、forループ でシミュレーションを実行する。上で作った行列 result の \\(i\\) 行目に、\\(i\\)番目のシミュレーションの結果を保存する。\n\nfor (i in 1:n_sims) {\n  result[i, ] &lt;- simple_reg(n = 5, beta0 = 2, beta1 = 0.8, sigma = 2)\n}\n\n結果の最初の5行を確認してみよう。\n\nresult[1:5, ]\n\n            b0        b1\n[1,] 1.7149743 0.3521188\n[2,] 1.5272431 0.4034422\n[3,] 0.8485352 1.4109607\n[4,] 2.5715007 0.9114845\n[5,] 2.4098839 0.3374894\n\n\nシミュレーションの実行結果が保存されていることがわかる。\nシミュレーションの結果を確認してみよう。 私たちが知りたいのは、回帰分析で、\\(\\beta_0=2\\)、\\(\\beta_1 = 0.8\\) がどれだけ正確に推定できるかということである。\nまず、\\(\\beta_0\\) の推定値である、\\(b_0\\) (b0) をヒストグラムにしてみよう。\n\nres_data &lt;- as_tibble(result)  # 行列をデータフレームに変換する\nhist_b0 &lt;- ggplot(data = res_data, aes(x = b0)) +\n  geom_histogram(color = \"black\") +\n  labs(x = expression(b[0]), y = \"度数\") +\n  geom_vline(xintercept = 2, color = \"tomato\")  # beta0 の真の値を示す\nplot(hist_b0)\n\n\n\n\n\n\n\nヒストグラムに加えられた赤い直線が真の値を示している。データ生成と推定を繰り返すと、推定がうまくいくこともあれば、そうでないこともあるということがわかる。分布の形に注目すると、分布の中心は真の値付近にあり、平均すると推定がうまくいっているように見える。\n実際、1000個得られたb0の平均値を求めると、\n\nmean(res_data$b0)\n\n[1] 1.980265\n\n\nであり、真の値である2に近い。\n同様に、\\(\\beta_1\\) の推定値である、\\(b_1\\) (b1) をヒストグラムにしてみよう。\n\nhist_b1 &lt;- ggplot(data = res_data, aes(x = b1)) +\n  geom_histogram(color = \"black\") +\n  labs(x = expression(b[1]), y = \"度数\") +\n  geom_vline(xintercept = 0.8, color = \"tomato\")  # beta1 の真の値を示す\nplot(hist_b1)\n\n\n\n\n\n\n\nヒストグラムに加えられた赤い直線が真の値を示している。やはり、データ生成と推定を繰り返すと、推定がうまくいくこともあれば、そうでないこともあるということがわかる。分布の形に注目すると、分布の中心は真の値付近にあり、平均すると推定がうまくいっているように見える。\n実際、b1の平均値は、\n\nmean(res_data$b1)\n\n[1] 0.8123114\n\n\nであり、真の値である0.8に近い。\n最後に、得られた回帰直線を図示してみよう。\n\nplt &lt;- ggplot(NULL) +\n  geom_abline(intercept = res_data$b0, \n              slope = res_data$b1, \n              color = \"gray\") +\n  geom_abline(intercept = 2, \n              slope = 0.8, \n              color = \"dodgerblue\") +\n  xlim(-5, 5) + \n  ylim(-3, 7) +\n  labs(x = \"x\", y = \"y\")\nplot(plt)\n\n\n\n\n\n\n\nこの図は、推定された回帰直線をグレーで、真の回帰直線を青で描いている。回帰直線1つをランダムに選ぶと、その線は必ずしも真の関係を正しく捉えていない。しかし、平均してみると、真の直線の周りに推定された線が集まっていることがわかる。つまり、平均的には、回帰分析はうまくいきそうである。\n上の図では1000個の回帰直線が互いに重なり合っている部分が多く、ひとつひとつの直線がよく見えないので、ランダムに10個だけ選んで同様の図を作ろう。\n\nres_data_sub &lt;- slice_sample(res_data, n = 10)  # データからランダムに10行選ぶ\nplt_sub10 &lt;- ggplot(NULL) +\n  geom_abline(intercept = res_data_sub$b0, \n              slope = res_data_sub$b1, \n              color = \"gray\") +\n  geom_abline(intercept = 2, \n              slope = 0.8, \n              color = \"dodgerblue\") +\n  xlim(-5, 5) + \n  ylim(-3, 7) +\n  labs(x = \"x\", y = \"y\")\nplot(plt_sub10)\n\n\n\n\n\n\n\n推定された回帰直線をグレーで、真の回帰直線を青で描いている。回帰直線1つをランダムに選ぶと、その線は必ずしも真の関係を正しく捉えていないことがよくわかる。\n実際のデータ分析では、1つ（または少数）のデータセットを対象に分析を行うことが多い。つまり、グレーの直線のうちどれか1つ（または少数）だけが得られることになる。その直線は、\\(X\\)と\\(Y\\)の真の関係を捉えているとは言えないことが、今回のシミュレーションでよくわかっただろう。私たちは、標本（サンプル）から得られた1つの直線を手がかりにして統計的検定や統計的推定を行い、母集団（真の関係）についての理解を深めることを目指すことになる。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>回帰分析による統計的推定</span>"
    ]
  },
  {
    "objectID": "regression-estimation.html#実習課題",
    "href": "regression-estimation.html#実習課題",
    "title": "\n5  回帰分析による統計的推定\n",
    "section": "\n5.4 実習課題",
    "text": "5.4 実習課題\n\n上のシミュレーションと同じことを、標本サイズ \\(N\\) を 10、50、100 に設定して実行しなさい。標本サイズが大きくなると、どんなことが起きる？\n\n\\(\\beta_0\\)、\\(\\beta_1\\)、\\(\\sigma\\) の値を自由に変更してシミュレーションを実行しなさい。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>回帰分析による統計的推定</span>"
    ]
  },
  {
    "objectID": "regression-test-inference.html",
    "href": "regression-test-inference.html",
    "title": "\n6  回帰分析による統計的検定と推論\n",
    "section": "",
    "text": "6.1 準備\nまず、必要なパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom) \n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>回帰分析による統計的検定と推論</span>"
    ]
  },
  {
    "objectID": "regression-test-inference.html#回帰分析における仮説検定",
    "href": "regression-test-inference.html#回帰分析における仮説検定",
    "title": "\n6  回帰分析による統計的検定と推論\n",
    "section": "\n6.2 回帰分析における仮説検定",
    "text": "6.2 回帰分析における仮説検定\n\n6.2.1 データの準備\n説明のために『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\n既にこのデータは入手済みだと思われるが、持っていない場合は上のリンクからダウンロードする。\nデータを読み込み、中身を確認する。\n\nHR &lt;- read_csv(\"data/hr-data.csv\")\n\nRows: 8803 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): ku, status, name, party, wl, smd, party_jpn\ndbl (15): year, kun, party_code, previous, voteshare, age, nocand, rank, vot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(HR)\n\nRows: 8,803\nColumns: 22\n$ year       &lt;dbl&gt; 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996,…\n$ ku         &lt;chr&gt; \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aichi\", \"aich…\n$ kun        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,…\n$ status     &lt;chr&gt; \"現職\", \"元職\", \"現職\", \"新人\", \"新人\", \"新人\", \"新人\", \"現…\n$ name       &lt;chr&gt; \"KAWAMURA, TAKASHI\", \"IMAEDA, NORIO\", \"SATO, TAISUKE\", \"IWA…\n$ party      &lt;chr&gt; \"NFP\", \"LDP\", \"DPJ\", \"JCP\", \"others\", \"kokuminto\", \"indepen…\n$ party_code &lt;dbl&gt; 8, 1, 3, 2, 100, 22, 99, 8, 1, 3, 2, 10, 100, 99, 22, 8, 1,…\n$ previous   &lt;dbl&gt; 2, 3, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0,…\n$ wl         &lt;chr&gt; \"当選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"当…\n$ voteshare  &lt;dbl&gt; 40.0, 25.7, 20.1, 13.3, 0.4, 0.3, 0.2, 32.9, 26.4, 25.7, 12…\n$ age        &lt;dbl&gt; 47, 72, 53, 43, 51, 51, 45, 51, 71, 30, 31, 44, 61, 47, 43,…\n$ nocand     &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7,…\n$ rank       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5,…\n$ vote       &lt;dbl&gt; 66876, 42969, 33503, 22209, 616, 566, 312, 56101, 44938, 43…\n$ eligible   &lt;dbl&gt; 346774, 346774, 346774, 346774, 346774, 346774, 346774, 338…\n$ turnout    &lt;dbl&gt; 49.2, 49.2, 49.2, 49.2, 49.2, 49.2, 49.2, 51.8, 51.8, 51.8,…\n$ exp        &lt;dbl&gt; 9828097, 9311555, 9231284, 2177203, NA, NA, NA, 12940178, 1…\n$ expm       &lt;dbl&gt; 9.828097, 9.311555, 9.231284, 2.177203, NA, NA, NA, 12.9401…\n$ vs         &lt;dbl&gt; 0.400, 0.257, 0.201, 0.133, 0.004, 0.003, 0.002, 0.329, 0.2…\n$ exppv      &lt;dbl&gt; 28.341505, 26.851941, 26.620462, 6.278449, NA, NA, NA, 38.2…\n$ smd        &lt;chr&gt; \"当選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"落選\", \"当…\n$ party_jpn  &lt;chr&gt; \"新進党\", \"自民党\", \"民主党\", \"共産党\", \"その他\", \"国民党\",…\n\n\n衆議院議員経験があることを表す変数（ダミー変数）と選挙費用を100万円単位で測定する変数を作る。新しい変数は dplyr::mutate() で作る。\n\nHR &lt;- HR |&gt;\n    mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"),\n           expm = exp / 10^6)\n\n1996年のデータだけ取り出す。\n\nHR1996 &lt;- HR |&gt; \n  filter(year == 1996)\n\n\n6.2.2 単回帰の例（1）\n1996年の選挙データを使って、「議員経験 (experience; \\(X\\)) が得票率 (voteshare; \\(V\\)) に影響する」という仮説を検証する。この仮説を、統計モデルとして以下のように表現する。 \\[\nV_i \\sim \\mbox{Normal}(\\alpha + \\beta X_i, \\sigma)\n\\] このモデルは分析上の仮定 (assumption)であり、正しいとは限らないことに注意。\nここで検証する帰無仮説と対立仮説は、以下のとおりである。\n\n帰無仮説：\\(\\beta = 0\\)\n\n対立仮説：\\(\\beta \\neq 0\\)\n\n\nこれを回帰分析で検証する。\nまず、lm() 関数を使って回帰式を推定する。\n\nfit1 &lt;- lm(voteshare ~ experience, \n           data = HR1996)\n\n結果を確認する。まず。summary() を使って結果を表示してみよう。\n\nsummary(fit1)\n\n\nCall:\nlm(formula = voteshare ~ experience, data = HR1996)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.334 -10.007  -2.207   8.593  67.393 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  16.0070     0.4608   34.74   &lt;2e-16\nexperience   22.8274     0.7891   28.93   &lt;2e-16\n\nResidual standard error: 13.28 on 1259 degrees of freedom\nMultiple R-squared:  0.3993,    Adjusted R-squared:  0.3988 \nF-statistic: 836.8 on 1 and 1259 DF,  p-value: &lt; 2.2e-16\n\n\n表示された結果のうち、Coefficients（係数） と書かれたブロックに注目する。Estimate（推定値）の列の、(Intercept) の行にある数値が\\(\\alpha\\) の推定値\\(a\\)、experince の行にある数値が \\(\\beta\\)の推定値\\(b\\)である。よって、この結果から、 \\[\n\\hat{V}_i = 16.0 + 22.8 X_i\n\\] という予測が得られる。\nしかし、回帰分析による統計的推定 で学習したとおり、推定値は標本を取り直すごとに変わる。したがって、ここで得られた値をそのまま信じるわけにはいかない。これらの値は、偶然得られただけで、真の値とはかけ離れているかもしれない。そこで、統計的検定を行う。検定には、\\(t\\)分布を利用する。\n私たちが立てた帰無仮説は、\\(\\beta = 0\\) である。推定量の標準誤差 (standard error) は分析結果の Std. Error の列に表示されている。よって、\\(t\\)値は、 \\[\nT\n= \\frac{b - \\tilde{\\beta}}{\\mathrm{SE}(b)}\n= \\frac{b}{\\mathrm{SE}(b)}\n\\approx \\frac{22.8274}{0.7891}\n\\approx 28.93\n\\] である。 Rで\\(b\\) の値を取り出すには、\n\ncoef(fit1)[2]\n\nexperience \n  22.82744 \n\n\nまたは、\n\nsummary(fit1)$coefficients[2, 1]\n\n[1] 22.82744\n\n\nとする。また、SE(\\(b\\)) は、\n\nsummary(fit1)$coefficients[2, 2]\n\n[1] 0.7891199\n\n\nなので、\\(t\\)値は、\n\nwith(summary(fit1), coefficients[2, 1] / coefficients[2, 2])\n\n[1] 28.92772\n\n\nである。この値が、上の表のt value の列に表示されている。この値を \\(t\\) 分布の臨界値と比較する。\n有意水準を5%にして検定を実施しよう。利用する\\(t\\)分布の自由度は、\\(N - K - 1\\) である。\\(N\\) は、\n\n(N1 &lt;- nrow(HR1996))\n\n[1] 1261\n\n#N1 &lt;- length(fit1$fitted.values)  # 欠測値がある場合は、推定したモデルで確かめたほうが安全\n\nである。単回帰のなので \\(K=1\\) である。よって、求める臨界値は、\n\n(c1 &lt;- qt(p = 0.05 / 2, df = N1 - 1 - 1, lower.tail = FALSE))\n\n[1] 1.96185\n\n\nである。\n\\[\n|T| = 28.93 &gt; 1.96 = |c|\n\\] となるので、有意水準5％で帰無仮説を棄却する。よって、\\(\\beta \\neq 0\\) である。\nここから、過去の議員経験は得票率に影響すると考える。\\(b \\approx 22.8\\) なので、議員経験がない場合に比べ、議員経験がある場合には平均すると22.8ポイント得票が増えることが期待される。 22.8ポイントの差は実質的に大きな差であり、議員経験が実質的にも重要な意味をもっていると言えそうだ。（ただし、この結論は仮定した統計モデルに依存しているという点に注意する必要がある。）\n続いて、\\(\\beta\\)の95%信頼区間を求めよう。95％信頼区間の下限値は、\n\ncoef(fit1)[2] - c1 * summary(fit1)$coefficients[2, 2]\n\nexperience \n   21.2793 \n\n\n上限値は、\n\ncoef(fit1)[2] + c1 * summary(fit1)$coefficients[2, 2]\n\nexperience \n  24.37557 \n\n\nである。よって、求める95%信頼区間は、[21.28, 24.38] である。\nこの区間は、confint() によって求めることもできる。\n\nconfint(fit1, level = 0.95)\n\n               2.5 %   97.5 %\n(Intercept) 15.10294 16.91102\nexperience  21.27930 24.37557\n\n\nまた、summary() の代わりに、broom::tidy() を使うこともできる。\n\ntidy(fit1, conf.int = TRUE, conf.level = 0.95)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     16.0     0.461      34.7 5.66e-186     15.1      16.9\n2 experience      22.8     0.789      28.9 1.68e-141     21.3      24.4\n\n\n\n6.2.3 単回帰の例（2）\n次に、「選挙費用 [単位：百万円] (expm; \\(M\\)) が得票率 (voteshare; \\(V\\)) に影響する」という仮説を検証する。この仮説を、統計モデルとして以下のように表現する。 \\[\nV_i \\sim \\mbox{Normal}(\\alpha + \\beta M_i, \\sigma)\n\\] このモデルは分析上の仮定 (assumption)であり、正しいとは限らないことに注意。\nここで検証する帰無仮説と対立仮説は、以下のとおりである。\n\n帰無仮説：\\(\\beta = 0\\)\n\n対立仮説：\\(\\beta \\neq 0\\)\n\n\nこれを回帰分析で検証する。\nまず、lm() 関数を使って回帰式を推定する。\n\nfit2 &lt;- lm(voteshare ~ expm, \n           data = HR1996)\n\n結果を確認する。broom::tidy() を使って結果を表示してみよう。\n\ntidy(fit2)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.44    0.665       11.2 9.82e- 28\n2 expm            1.88    0.0609      30.8 3.80e-154\n\n\n表示された結果のうち、estimate（推定値）の列の、(Intercept) の行にある数値が\\(\\alpha\\) の推定値\\(a\\)、expm の行にある数値が \\(\\beta\\)の推定値\\(b\\)である。よって、この結果から、 \\[\n  \\hat{V}_i = 7.4 + 1.9 M_i\n\\] という予測が得られる。\n繰り返しになるが、推定値は標本を取り直すごとに変わる。したがって、ここで得られた値をそのまま信じるわけにはいかない。これらの値は、偶然得られただけで、真の値とはかけ離れているかもしれない。そこで、統計的検定を行う。検定には、\\(t\\)分布を利用する。\n私たちが立てた帰無仮説は、\\(\\beta = 0\\) である。よって、\\(t\\)値は、 \\[\nT\n= \\frac{b - \\tilde{\\beta}}{\\mathrm{SE}(b)}\n= \\frac{b}{\\mathrm{SE}(b)}\n\\approx \\frac{1.87687}{0.06086}\n\\approx 30.84\n\\] である。この値が、上の表のstatistic の列に表示されている。この値を \\(t\\) 分布の臨界値と比較する。\n有意水準を7%にして検定を実施しよう。利用する\\(t\\)分布の自由度は、\\(N - K - 1\\) である。\\(N\\) は、\n\n(N2 &lt;- length(fit2$fitted.values))  # 欠測値がある!\n\n[1] 1198\n\n\nである（expm に欠測があるので、1,261にはならない）。単回帰のなので \\(K=1\\) である。よって、求める臨界値は、\n\n(c2 &lt;- qt(p = 0.07 / 2, df = N2 - 1 - 1, lower.tail = FALSE))\n\n[1] 1.813534\n\n\nである。\n\\[\n|T| = 30,84 &gt; 1.81 = |c|\n\\] だから、有意水準7%で帰無仮説を棄却する。よって、\\(\\beta \\neq 0\\) である。 ここから、選挙費用は得票率に影響すると考える。\\(b \\approx 1.9\\) なので、選挙費用を100万円増やすごとに平均すると1.9ポイント得票が増えることが期待される。 得票を10ポイント上昇させるには、\\(10/1.9 \\approx 5.3\\) 百万円選挙費用を増やせばよいことになる。得票率は、選挙の支出によってある程度変化するといえるかもしれない。（ただし、この結論は仮定した統計モデルに依存しているという点に注意する必要がある。）\n93%信頼区間を求めよう。下限値は、\n\ncoef(fit2)[2] - c2 * summary(fit2)$coefficients[2, 2]\n\n    expm \n1.766503 \n\n\n上限値は、\n\ncoef(fit2)[2] + c2 * summary(fit2)$coefficients[2, 2]\n\n    expm \n1.987246 \n\n\nである。よって、求める95%信頼区間は、[1.77, 1.99] である。\nこの区間は、confint() によって求めることもできる。\n\nconfint(fit2, level = 0.93)\n\n               3.5 %   96.5 %\n(Intercept) 6.238630 8.650744\nexpm        1.766503 1.987246\n\n\nbroom::tidy()で求めることもできる。\n\ntidy(fit2, conf.int = TRUE, conf.level = 0.93)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.44    0.665       11.2 9.82e- 28     6.24      8.65\n2 expm            1.88    0.0609      30.8 3.80e-154     1.77      1.99\n\n\n\n6.2.4 重回帰の例\n「過去の議員経験（experience; \\(X\\)）と選挙費用 [単位：百万円] (expm; \\(M\\)) が得票率 (voteshare; \\(V\\)) に影響する」という仮説を検証する。この仮説を、統計モデルとして以下のように表現する。 \\[\nV_i \\sim \\mbox{Normal}(\\beta_0 + \\beta_1 X_i + \\beta_2 M_i, \\sigma)\n\\] このモデルは分析上の仮定 (assumption)であり、正しいとは限らないことに注意。\n\n6.2.4.1 包括的仮説検定（結合仮説の検定）\n以下の帰無仮説と対立仮説を利用する。\n\n帰無仮説：\\(\\beta_1 = \\beta_2 = 0\\)\n\n対立仮説：\\(\\beta_1 \\neq 0\\) または \\(\\beta_2 \\neq 0\\) （両方正しくてもOK）\n\n6.2.4.2 個別的仮説検定\n\n以下の帰無仮説と対立仮説を利用する。\n\n議員経験に関する仮説\n\n帰無仮説1：\\(\\beta_1 = 0\\)\n\n対立仮説1：\\(\\beta_1 \\neq 0\\)\n\n\n\n選挙費用に関する仮説\n\n帰無仮説2：\\(\\beta_2 = 0\\)\n\n対立仮説2：\\(\\beta_2 \\neq 0\\)\n\n\n\n\n回帰式を推定する。回帰式自体は、包括的仮説検定でも個別的仮説検定でも同じである。\n\nfit3 &lt;- lm(voteshare ~ experience + expm, \n           data = HR1996)\n\nまず、包括的仮説（結合仮説）検定を考えよう。summary() で結果を表示する。\n\nsummary(fit3)\n\n\nCall:\nlm(formula = voteshare ~ experience + expm, data = HR1996)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.919  -7.419  -0.936   6.088  53.340 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  7.77407    0.59742   13.01   &lt;2e-16\nexperience  13.61318    0.80134   16.99   &lt;2e-16\nexpm         1.31223    0.06396   20.52   &lt;2e-16\n\nResidual standard error: 11.34 on 1195 degrees of freedom\n  (63 observations deleted due to missingness)\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5506 \nF-statistic: 734.2 on 2 and 1195 DF,  p-value: &lt; 2.2e-16\n\n\n包括的検定では、この結果のうち Residual standard error ブロックに表示される値を利用する。 帰無仮説が正しい場合、\\(F\\)値 \\[\nF_0 = \\frac{R^2}{1 - R^2} \\frac{N - K - 1}{K}\n\\] が、第1自由度\\(K\\)、第2自由度\\(N-K-1\\)の\\(F\\)分布に従って分布する。この回帰分析における\\(F\\)値は、上の結果の一番下の行に F-statistic として表示されている。すなわち、\\(F_0 = 734.2\\) である。この値を、\\(F\\)分布の臨界値と比較する。\n実際に検定を行う前に、\\(F\\)分布がどんな分布になるか確認しておこう。 \\(F\\)分布の母数（パラメタ）は、2つの自由度である。 \\[\nx \\sim F(\\mathrm{df1}, \\mathrm{df2})\n\\] として、\\(F\\)分布からランダムに抽出した\\(x\\) の分布の例を示す。\n\nseq1 &lt;- c(2, 5, 10)\nseq2 &lt;- c(10, 50, 100)\nFdist &lt;- tibble()\nfor (i in seq_along(seq1)) {\n  for (j in seq_along(seq2)) {\n    Fdist &lt;- tibble(\n      df1 = seq1[i],\n      df2 = seq2[j],\n      x = rf(1000, df1 = seq1[i], df2 = seq2[j])\n    ) |&gt; \n      bind_rows(Fdist)\n  }\n}\nFdist &lt;- Fdist |&gt; \n  mutate(df1 = paste(\"df1 =\", df1),\n         df2 = paste(\"df2 =\", df2),\n         df1 = factor(df1, \n                      levels = c(\"df1 = 2\", \"df1 = 5\", \"df1 = 10\")),\n         df2 = factor(df2, \n                      levels = c(\"df2 = 10\", \"df2 = 50\", \"df2 = 100\")))\nplt_F &lt;- ggplot(Fdist, aes(x = x, y = after_stat(density))) +\n  geom_histogram(color = \"black\") +\n  facet_grid(df2 ~ df1) +\n  labs(y = \"確率密度\", title = \"F(df1, df2)\")\nplot(plt_F)\n\n\n\n\n\n\n\nこのように、\\(F\\)分布は正の値しか取らない。したがって、\\(F\\)分布を使った検定では、\\(F\\)値や臨界値の絶対値を考える必要はない。\n仮説検定で利用する\\(F\\)分布の自由度も結果の最終行に表示されており、第1自由度は2（説明変数の数 \\(K = 2\\) である）、第2自由度は1195である。有意水準を5%として、検定の臨界値を求めよう。\\(F\\)分布の臨界値は qf() で求めることができる。\n\nqf(0.05, df1 = 2, df2 = 1195, lower.tail = FALSE)\n\n[1] 3.003255\n\n\nこの結果を使うと、 \\[\nF_0 = 734.2 &gt; 3.00 = c\n\\] なので、有意水準5％で帰無仮説を棄却する。よって、\\(\\beta_1 \\neq 0\\)または\\(\\beta_2 \\neq 0\\) である。\n続いて、個別的仮説検定を行う。そのために、broom::tidy() で結果を表示する。\n\ntidy(fit3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.77    0.597       13.0 2.67e-36     6.60      8.95\n2 experience     13.6     0.801       17.0 3.83e-58    12.0      15.2 \n3 expm            1.31    0.0640      20.5 2.22e-80     1.19      1.44\n\n\n議員経験 experience について私たちが立てた帰無仮説は、\\(\\beta_1 = 0\\) である。よって、\\(t\\)値は、 \\[\nT_1\n= \\frac{b_1 - \\tilde{\\beta}_1}{\\mathrm{SE}(b_1)}\n= \\frac{b_1}{\\mathrm{SE}(b_1)}\n\\approx \\frac{13.613177}{0.08013375}\n\\approx 16.99\n\\] である。この値が、上の表のstatistic の列に表示されている。この値を \\(t\\) 分布の臨界値と比較する。\n有意水準を4%にして検定を実施しよう。利用する\\(t\\)分布の自由度は、\\(N - K - 1\\) である。\\(N\\) は、\n\n(N3 &lt;- length(fit3$fitted.values))  # 欠測値がある!\n\n[1] 1198\n\n\nである（expm に欠測があるので、1,261にはならない）。説明変数が2つあるので \\(K=2\\) である。よって、求める臨界値は、\n\n(c3 &lt;- qt(p = 0.04 / 2, df = N3 - 2 - 1, lower.tail = FALSE))\n\n[1] 2.055993\n\n\nである。\n\\[\n|T_1| = 16.99 &gt; 2.06 = |c|\n\\] だから、有意水準4%で帰無仮説を棄却する。よって、\\(\\beta_1 \\neq 0\\) である。\n同様に、選挙費用 expme について私たちが立てた帰無仮説は、\\(\\beta_2 = 0\\) である。よって、\\(t\\)値は、 \\[\nT_2\n= \\frac{b_2 - \\tilde{\\beta}_2}{\\mathrm{SE}(b_2)}\n= \\frac{b_2}{\\mathrm{SE}(b_2)}\n\\approx \\frac{1.312231}{0.0639582   }\n\\approx 20.52\n\\] である。この値が、上の表のstatistic の列に表示されている。この値を \\(t\\) 分布の臨界値と比較する。有意水準4%の臨界値は上で求めた c3 である。 \\[\n|T_2| = 20.52 &gt; 2.06 = |c|\n\\] だから、有意水準4%で帰無仮説を棄却する。よって、\\(\\beta_2 \\neq 0\\) である。\nここから、議員経験と選挙費用はどちらも得票率に影響すると考える。\\(b_1 \\approx 13.6\\)なので、選挙費用が同じ候補者同士を比べると、議員経験がある者のほうが経験がない者よりも平均して13.6ポイント得票率が高いと予測できる。同様に、\\(b_2 \\approx 1.3\\) なので、議員経験の有無が同じ場合には、選挙費用を100万円増やすごとに平均すると1.3ポイント得票が増えることが予測される。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>回帰分析による統計的検定と推論</span>"
    ]
  },
  {
    "objectID": "regression-test-inference.html#シミュレーションで回帰分析を理解する",
    "href": "regression-test-inference.html#シミュレーションで回帰分析を理解する",
    "title": "\n6  回帰分析による統計的検定と推論\n",
    "section": "\n6.3 シミュレーションで回帰分析を理解する",
    "text": "6.3 シミュレーションで回帰分析を理解する\n回帰分析のしくみ（特に信頼区間の意味）を理解するために、簡単なモンテカルロシミュレーションを行おう。 シミュレーションでは、自分で母数（パラメタ）を設定し、データを生成する。 そのうえで、特徴を知りたい分析手法（今回の場合は線形回帰を用いた回帰分析）を生成したデータに当てはめ、母数をうまく推測できるかどうか確認する。\n今回は、単回帰を例にシミュレーションを行う。 このシミュレーションを行う主な目的は以下の3つである。\n\n線形回帰が想定するデータ生成過程 (data generating process) を理解する\n線形回帰の推定量の基本的な性質を理解する\n信頼区間の意味を理解する\n\n単回帰モデルは、以下のとおりである。 \\[\nY_i \\sim \\mbox{Normal}(\\beta_1 + \\beta_2 X_i,  \\sigma)\n\\]\nしたがって、設定する母数は3つ（\\(\\beta_1\\), \\(\\beta_2\\), \\(\\sigma\\)）ある。\n\nbeta1 &lt;- 10   # 切片の値を決める\nbeta2 &lt;- 3    # 傾き（予測変数の係数）を決める\nsigma &lt;- 6    # 誤差の標準偏差を決める\n\n次に、単回帰モデルが想定するデータ生成過程に従って、データを生成する。\n\nN &lt;- 100   ## サンプルサイズを決める\n## x ~ U(0, 10) とする：他の設定でもかまわない\nx &lt;- runif(N, min = 0, max = 10)   ## 最小値0, 最大値10の一様分布から長さNのxベクトルを抽出する\ny &lt;- rnorm(N, beta1 + beta2 * x, sd = sigma)  ## 設定に従って、yを正規分布から抽出する\n\nここで、手に入れたデータを散布図にして直線を当てはめてみよう。\n\ndf &lt;- data.frame(y, x)\nscat &lt;- ggplot(df, aes(x, y)) + \n  geom_point() + \n  geom_smooth(method = 'lm')\nplot(scat)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n回帰式を推定すると、\n\neg_1 &lt;- lm(y ~ x, \n           data = df)\ntidy(eg_1)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     9.14     1.28       7.14 1.66e-10\n2 x               3.10     0.215     14.4  5.91e-26\n\n\n3つの母数のうち、関心がある\\(\\beta_1=10\\)と\\(\\beta_2=3\\) に対する推定値は、それぞれ9.14, 3.1であることがわかる。\nこのとき、係数の95パーセント信頼区間は、\n\nconfint(eg_1)\n\n               2.5 %    97.5 %\n(Intercept) 6.602367 11.686254\nx           2.672670  3.526034\n\n\nで求められる。 95パーセント信頼区間は、切片が[6.60, 11.69]、傾きが[2.67, 3.53] であり、どちらの信頼区間も母数を含んでいる。 つまり、ここで得られた信頼区間が母数を含む確率は1（100%）である！\n以上の過程を、母数とサンプルサイズは変えずに何度も繰り返す。 同じコードを何度も繰り返し使うのは面倒なので、関数にしてしまおう。\n\nsim_ols1 &lt;- function(beta, sigma, n = 100, trials = 10000, x_rng = c(0,10)) {\n    ## 単回帰をシミュレートする関数\n    ## 引数\n    ##   beta: 係数パラメタのベクトル\n    ##   sigma: 誤差の標準偏差\n    ##   n: 標本サイズ、既定値は100\n    ##   trials: シミュレーションの繰り返し回数、既定値は10000\n    ##   x_rng: 説明変数xの値の範囲、既定値は (0, 10)\n    ## 返り値:\n    ##   df: 以下の列を含むデータフレーム\n    ##      (1) パラメタの推定値\n    ##      (2) 各パラメタの推定値の標準誤差\n    ##      (3) 各パラメタの95％信頼区間\n    \n    ## 結果を保存するためのデータフレームを作る\n    col_names &lt;- c('b1', 'b1_se', 'b1_lower', 'b1_upper',\n                   'b2', 'b2_se', 'b2_lower', 'b2_upper', 'sigma_hat')\n    df &lt;- as.data.frame(matrix(rep(NA, trials * length(col_names)),\n                               ncol = length(col_names)))\n    names(df) &lt;- col_names\n    \n    for (i in 1:trials) { # ループ\n        # データ生成\n        x &lt;- runif(n, x_rng[1], x_rng[2])\n        y &lt;- rnorm(n, mean = beta[1] + beta[2]*x, sd = sigma)\n        \n        # y を x に回帰する\n        fit &lt;- lm(y ~ x)\n        \n        # 残差平方和\n        sigma_hat &lt;- summary(fit)$sigma\n        \n        # 係数の推定値\n        b1 &lt;- coef(fit)[1]\n        b2 &lt;- coef(fit)[2]\n        \n        # 推定の標準誤差\n        b1_se &lt;- sqrt(summary(fit)$cov.unscaled[1,1]) * sigma_hat\n        b2_se &lt;- sqrt(summary(fit)$cov.unscaled[2,2]) * sigma_hat\n        \n        # 95% CI\n        b1_ci95 &lt;- confint(fit)[1,]\n        b2_ci95 &lt;- confint(fit)[2,]\n        \n        # 結果をまとめる\n        df[i,] &lt;- c(b1, b1_se, b1_ci95,\n                    b2, b2_se, b2_ci95,\n                    sigma_hat)      \n    }\n    \n    return(df)\n}\n\nこの関数を利用して、実際にシミュレーションを行ってみよう。 自分で母数とサンプルサイズ（ここでは規定値のn = 100を利用）を指定し、データの生成と回帰式の推定を1,000回繰り返すことにする。\n\nbeta1 &lt;- 10\nbeta2 &lt;- 3\nsigma &lt;- 6\nsim_1 &lt;- sim_ols1(beta = c(beta1, beta2), sigma = sigma, trials = 1000)\nhead(sim_1)　# 得られた結果の最初の6行のみ表示\n\n         b1    b1_se b1_lower b1_upper       b2     b2_se b2_lower b2_upper\n1 10.519381 1.333821 7.872455 13.16631 2.840636 0.2276824 2.388807 3.292464\n2  9.195160 1.558476 6.102415 12.28790 3.157845 0.2427141 2.676187 3.639503\n3  8.675866 1.365326 5.966421 11.38531 3.169810 0.2311890 2.711023 3.628597\n4  9.693470 1.422950 6.869673 12.51727 2.911867 0.2347170 2.446079 3.377655\n5  8.809144 1.111461 6.603487 11.01480 3.040280 0.2021615 2.639097 3.441463\n6  9.211938 1.086019 7.056770 11.36711 3.375313 0.1891709 2.999909 3.750716\n  sigma_hat\n1  6.304427\n2  6.559746\n3  6.609825\n4  6.311905\n5  5.704105\n6  5.662732\n\n\nこれで、シミュレーションで得られた数字は sim_1に保存された。\n\n\n6.3.1 係数の推定値を理解する\n説明変数 \\(x\\) の係数の推定値 b2 の分布を確認してみよう。 私たちは母数\\(\\beta_2=3\\)であることを知っているが、この数値をうまく推定できるだろうか？\n\nhist_b2 &lt;- ggplot(sim_1, aes(x = b2, y = after_stat(density))) +\n    geom_histogram(binwidth = 0.1, color = 'black')\nhist_b2 &lt;- hist_b2 + \n    labs(y = '確率密度', title = 'シミュレーションで得たb2の分布') +\n    geom_vline(xintercept = 3, color = 'tomato')\nplot(hist_b2)\n\n\n\n\n\n\n\nこのヒストグラムが示すように、線形回帰は平均すると、母数をうまく推定してくれる（不偏性, unbiasedness）。しかし、常に正しい推定をするわけではなく、係数の値を過小推定することもあれば、過大推定することもある。実際の分析では、データセットが1つしかないのが普通であり、自分のデータ分析が係数を「正しく」推定しているとは限らならい。そのために、推定の不確実性を明示することが求められるのである。\n\n\n6.3.2 標準誤差を理解する\n次に、b2の標準誤差 (standard error) をヒストグラムにしてみよう。\n\nhist_se &lt;- ggplot(sim_1, aes(x = b2_se, y = after_stat(density))) + \n    geom_histogram(binwidth = .01, color = 'black') +\n    labs(x = 'b2の標準誤差', y = '確率密度', title = 'b2の標準誤差の分布')\nplot(hist_se)\n\n\n\n\n\n\n\nこのように、標準誤差自体が推定量なので、値はサンプルごとに異なる（分布する）。\n標準誤差をseとすると、 \\[\\frac{\\hat{\\beta} - \\beta}{\\mathrm{se}}\\] は自由度\\(N - K - 1\\)（ここでは、100 - 1 - 1 = 98）の\\(t\\)分布に従うはずである。 まず、この値をヒストグラムにして、自由度98の\\(t\\)分布の確率密度曲線を重ね書きしてみよう。\n\nsim_1 &lt;- sim_1 |&gt; \n  mutate(b2_t = (b2 - beta2) / b2_se)\n## t分布の確率密度を求め、true_tという名前のデータフレームに保存する\ntrue_t &lt;- data.frame(x = seq(-4, 4, length = 100)) |&gt;\n    mutate(density = dt(x, df = 98))\nhist_t &lt;- ggplot(sim_1, aes(x = b2_t, y = after_stat(density))) +\n    geom_histogram(binwidth = 0.5, color = 'black') + \n    geom_line(data = true_t, aes(x = x, y = density), color = 'tomato')\nhist_t &lt;- hist_t +\n    labs(x = expression(frac(hat(beta) - beta, 'se')),\n         y = '確率密度', title = '標準化されたb2と自由度98のt分布')\nplot(hist_t)\n\n\n\n\n\n\n\nこの図から、\\(t\\)分布に近い分布であることがわかる。 Q-Qプロットでも確かめてみよう。\n\nqqplot_t &lt;- ggplot(sim_1, aes(sample = b2_t)) + \n    stat_qq(distribution = qt, dparams = list(df = 98)) +\n    geom_abline(intercept = 0, slope = 1, color = \"tomato\") +\n    labs(title = \"Q-Q プロット\", \n         x = '自由度 N - K - 1 = 98のt分布',\n         y = expression(paste(\"シミュレートした\", \n                              frac(hat(beta) - beta, \"se\"), \n                              \" の分布\")))\nplot(qqplot_t)\n\n\n\n\n\n\n\nQ-Qプロットの点がほぼ一直線に並んでおり、\\((\\hat{\\beta}-\\beta)/\\mathrm{se}\\)が\\(t\\)分布に従っていることがわかる。ただし、分布の裾では、理論値との乖離が大きいことに注意が必要である。\n今回のシミュレーションで得られた標準誤差の平均値は、\n\nmean(sim_1$b2_se)\n\n[1] 0.209381\n\n\nである。標準誤差は推定値の標準偏差のはずだが、本当にそうなっているかどうか確認してみよう。\n\nsd(sim_1$b2)\n\n[1] 0.2144247\n\n\nこれで、実際に標準誤差は推定値の標準偏差に（ほぼ）一致することがわかった。\n\n\n6.3.3 信頼区間を理解する\n係数の推定値b2の95パーセント信頼区間を例として考える。 シミュレーションで得られた1つ目の信頼区間は、\n\nsim_1[1, c('b2_lower', 'b2_upper')]\n\n  b2_lower b2_upper\n1 2.388807 3.292464\n\n\nすなわち、[2.39, 3.29] がb2[1] の95パーセント信頼区間である。 この区間は母数である\\(\\beta_2=3\\)を区間内に含んでいる。 したがって、この信頼区間が母数を含む確率は1（100%)である。\n同様に、2つ目の信頼区間は、\n\nsim_1[2, c('b2_lower', 'b2_upper')]\n\n  b2_lower b2_upper\n2 2.676187 3.639503\n\n\nであり、これも母数を区間内に含んでいる。\nしかし、39番目の信頼区間は、\n\nsim_1[39, c('b2_lower', 'b2_upper')]\n\n   b2_lower b2_upper\n39 3.025416 3.749442\n\n\nであり、これは母数を区間内に含んでいない。 つまり、この信頼区間が母数を含む確率は0である。\nシミュレーションで得た1,000個の信頼区間のうち、どの信頼区間が母数を含んでいるか調べてみよう。 母数を信頼区間内に含むのは、信頼区間の下限値が母数以下かつ上限値が母数以上のものである。\n\ncheck_ci &lt;- sim_1$b2_lower &lt;= beta2 & sim_1$b2_upper &gt;= beta2\n\nこの結果、TRUEとなっているものが母数を区間内に捉えているもの、FALSEがそうでないものである。これを表にすると、\n\ntable(check_ci)\n\ncheck_ci\nFALSE  TRUE \n   49   951 \n\n\nと、なる。つまり、1000個の95パーセント信頼区間のうち、951個（95.1%）は母数を区間内に捉え、残りの49個が捉えないということである。このように、一定のデータ生成過程から得られた異なるデートセットに対し、信頼区間を求める作業を繰り返したとき、「得られた信頼区間のうち何パーセントが母数を区間内に含むか」というのが、信頼区間の信頼度である。\nこれを図にしてみよう。 1,000個は多すぎるので、無作為に100個だけ選んで図示する。\n\n# シミュレーションの結果にIDを割り当てる\nsim_1 &lt;- sim_1 |&gt; \n  mutate(id = 1:n())\n# 信頼区間が母数を含むかどうかの判定結果をデータフレームに加える\nsim_1$check_ci &lt;- check_ci\n# 100個の結果をランダムに選ぶ\nsim_1_sub &lt;- sim_1 |&gt; \n  slice_sample(n = 100)\n# 100個の信頼区間を図示する\nctplr &lt;- ggplot(sim_1_sub,\n                aes(x = reorder(id, b2), y = b2,\n                    ymin = b2_lower, ymax = b2_upper,\n                    color = check_ci)) +\n    geom_hline(yintercept = beta2, linetype = 'dashed') +\n    geom_pointrange() +\n    labs(x = 'シミュレーションID', y = 'b2', title = '95％信頼区間') +\n    scale_color_brewer(palette = \"Set1\",\n                       name = '母数を', \n                       labels = c('含まない', '含む')) +\n    coord_flip()\nplot(ctplr)\n\n\n\n\n\n\n\nこのように、100個中94個（94パーセント; 約95パーセント）の95パーセント信頼区間が、母数である3にかかっている（つまり、信頼区間内に母数を含む）ことがわかる。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>回帰分析による統計的検定と推論</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html",
    "href": "multiple-regression.html",
    "title": "\n7  重回帰分析\n",
    "section": "",
    "text": "7.1 準備\n今回使うパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>重回帰分析</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#重回帰分析",
    "href": "multiple-regression.html#重回帰分析",
    "title": "\n7  重回帰分析\n",
    "section": "\n7.2 重回帰分析",
    "text": "7.2 重回帰分析\n説明のために『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\n\nHR &lt;- read_csv(\"data/hr-data.csv\")\n\nRows: 8803 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): ku, status, name, party, wl, smd, party_jpn\ndbl (15): year, kun, party_code, previous, voteshare, age, nocand, rank, vot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#glimpse(HR)\n\n衆議院議員経験があることを表すダミー変数と選挙費用を100万円単位で測定する変数を作る。\n\nHR &lt;- HR |&gt; \n  mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"),\n         expm = exp / 10^6)\n\n2009年の結果だけ抜き出し、HR09として保存する（expm が欠測しているものを除外する）。\n\nHR09 &lt;- HR |&gt; \n  filter(year == 2009,\n         !is.na(expm))\n\n\n\n7.2.1 Rで重回帰分析を実行する\n得票率 (voteshare, \\(V\\)) を議員経験 (experience, \\(X\\)) と選挙費用 [100万円] (expm, \\(M\\)) で説明するモデルを推定する。モデルは次のように表記できる。 \\[\nV_i \\sim \\mbox{Normal}(\\beta_0 + \\beta_1 X_i + \\beta_2 M_i, \\sigma)\n\\]\nlm() で重回帰を行うときは、説明変数を + でつなぐ。\n\nfit_3 &lt;- lm(voteshare ~ experience + expm, \n            data = HR09)\ntidy(fit_3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.89     0.691      11.4 1.17e-28     6.54      9.25\n2 experience     18.4      1.23       15.0 1.99e-46    16.0      20.8 \n3 expm            1.83     0.120      15.2 1.40e-47     1.59      2.07\n\n\n課題：この結果を解釈してみよう。˙1つひとつの数字 (p.value を除く）は何を表しているのだろうか。\n###　重回帰分析の係数の意味\n重回帰分析の結果として得られた各説明変数の係数は、偏回帰係数と呼ばれる。偏回帰係数は、どんな意味をもっているのだろうか。これには、2つの解釈がある。\n\n他の説明変数の値を一定としたとき（固定したとき）、特定の説明変数1単位の増加が、応答変数をどれだけ変化させるか。\nある説明変数が応答変数に与える影響から、その他の説明変数の影響を取り除いたもの。\n\nこれらのそれぞれについて、以下で検討しよう。\n\n他の値を一定にしたときの、説明変数の影響\n上のモデルで推定した、選挙費用 expm の偏回帰係数について考える。推定された値は、約 1.83 である。つまり、他の説明変数である「議員経験」が同じ候補者同士を比べると、選挙費用が1単位すなわち100万円増加するごとに、得票率が平均1.83ポイント上昇することが予測される。（回帰式から明らかではあるが）これを確認しよう。\nこのデータにおける選挙費用は、\n\nsummary(HR09$expm)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n 0.01002  1.79454  4.80944  6.11818  9.10911 25.35407 \n\n\nなので、最小値が約0.01（つまり1万円）、最大値が25.35（2,535万円）である。様々な選挙費用について考えるために、 選挙費用 [百万円]を0から25（つまり、2,500万円）まで、1刻み（つまり、実際には100万円刻み）で測るベクトルを作る。\n\nmoney &lt;- 0:25\n\n選挙費用の各値について、得票率の予測値がいくつになるか考える。\nまず、議員経験がない場合について考えよう。得票率の予測値は、\n\npred0 &lt;- coef(fit_3)[1] +       # 切片\n         coef(fit_3)[2] * 0  +  # 議員経験なしなので0\n         coef(fit_3)[3] * money # 選挙費用の値ごとに計算する\n\n選挙費用ごとに異なる得票率の予測値が得られる。最初の3つだけ表示してみよう。\n\npred0[1:3]\n\n[1]  7.891485  9.722161 11.552836\n\n\nこの結果をデータフレーム (tibble) にまとめる。\n\ndf0 &lt;- tibble(money = money,\n              predicted0 = pred0)\ndf0\n\n# A tibble: 26 × 2\n   money predicted0\n   &lt;int&gt;      &lt;dbl&gt;\n 1     0       7.89\n 2     1       9.72\n 3     2      11.6 \n 4     3      13.4 \n 5     4      15.2 \n 6     5      17.0 \n 7     6      18.9 \n 8     7      20.7 \n 9     8      22.5 \n10     9      24.4 \n# ℹ 16 more rows\n\n\nこの結果から、得票率の予測値は、選挙費用が0のときは 7.8914854、100万円のときは 9.7221608、\\(\\dots\\) ということがわかる。百万円増えるごとの得票率の変化は、\n\nfor (i in 2:length(money)) {\n  print(pred0[i] - pred0[i - 1])\n}\n\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n\n\nとなり、常に一定であることがわかる（当たり前だが）。つまり、議員経験がない者だけを比べると、選挙費用が100万円増えるごとに、得票率が約1.83ポイント上昇する。\n同様に、議員経験がある場合についても考えよう。\n\npred1 &lt;- coef(fit_3)[1] +       # 切片\n         coef(fit_3)[2] * 1  +  # 議員経験ありなので1\n         coef(fit_3)[3] * money # 選挙費用の値ごとに計算する\n\n選挙費用ごとに異なる得票率の予測値が得られる。最初の3つだけ表示してみよう。\n\npred1[1:3]\n\n[1] 26.26251 28.09319 29.92386\n\n\nこの結果をデータフレーム (tibble) にまとめる。\n\ndf1 &lt;- tibble(money = money,\n              predicted1 = pred1)\ndf1\n\n# A tibble: 26 × 2\n   money predicted1\n   &lt;int&gt;      &lt;dbl&gt;\n 1     0       26.3\n 2     1       28.1\n 3     2       29.9\n 4     3       31.8\n 5     4       33.6\n 6     5       35.4\n 7     6       37.2\n 8     7       39.1\n 9     8       40.9\n10     9       42.7\n# ℹ 16 more rows\n\n\nこの結果から、得票率の予測値は、選挙費用が0のときは 26.2625109、100万円のときは 28.0931863、\\(\\dots\\) ということがわかる。百万円増えるごとの得票率の変化は、\n\nfor (i in 2:length(money)) {\n  print(pred1[i] - pred1[i - 1])\n}\n\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n[1] 1.830675\n\n\nとなり、常に一定であることがわかる（当たり前だが）。つまり、議員経験がある者だけを比べると、選挙費用が100万円増えるごとに、得票率が約1.83ポイント上昇する。\n次に、議員経験の偏回帰係数について考えよう。 そのために、以上の結果を、1つのデータフレームにまとめる。\n\ndf01 &lt;- df0 |&gt; \n  right_join(df1, by = \"money\")\ndf01\n\n# A tibble: 26 × 3\n   money predicted0 predicted1\n   &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1     0       7.89       26.3\n 2     1       9.72       28.1\n 3     2      11.6        29.9\n 4     3      13.4        31.8\n 5     4      15.2        33.6\n 6     5      17.0        35.4\n 7     6      18.9        37.2\n 8     7      20.7        39.1\n 9     8      22.5        40.9\n10     9      24.4        42.7\n# ℹ 16 more rows\n\n\nこのデータフレームに、predicted1 と predicted0 の差 dif_experienceを加えてみよう。\n\ndf01 &lt;- df01 |&gt; \n  mutate(dif_experience = predicted1 - predicted0)\ndf01\n\n# A tibble: 26 × 4\n   money predicted0 predicted1 dif_experience\n   &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;\n 1     0       7.89       26.3           18.4\n 2     1       9.72       28.1           18.4\n 3     2      11.6        29.9           18.4\n 4     3      13.4        31.8           18.4\n 5     4      15.2        33.6           18.4\n 6     5      17.0        35.4           18.4\n 7     6      18.9        37.2           18.4\n 8     7      20.7        39.1           18.4\n 9     8      22.5        40.9           18.4\n10     9      24.4        42.7           18.4\n# ℹ 16 more rows\n\n\ndif_experience の値は、すべて、約18.37になっている。この値は、重回帰におけるexperienceの偏回帰係数である。ここから、選挙費用（このデータフレームではmoney の値）を一定にしたとき、議員経験があると得票率の予測値が18.37 ポイント上昇することがわかる。\n以上の結果から、「他の説明変数の値を一定にしたとき」に、ある説明変数1単位の増加が応答変数をどれだけ変化させるかが、偏回帰係数であることがわかる。\n\n他の変数を取り除いた、特定の説明変数の影響\n再び、選挙費用の偏回帰係数について考えよう。 回帰モデルには「得票率」、「選挙費用」、「議員経験」という3つの変数が登場する。 選挙費用の額と得票率は、どちらも議員経験と関連しているかもしれない（関連していると想定されるので、回帰式に含められている）ので、その関連を取り除いてみよう。\nまず、選挙費用から議員経験に関連する部分（変動）を取り除く。そのために、選挙費用を議員経験に回帰する。\n\nreg1 &lt;- lm(expm ~ experience, \n           data = HR09)\n\nこの単回帰の残差 (residuals) を取り出す。\n\nres1 &lt;- reg1$residuals\n\nこの残差は、議員経験によっては説明できない選挙費用の変動だと考えられる。つまり、この残差は、選挙費用から議員経験の影響を取り除いたものであると考えることができる。\n同様に、得票率から議員経験に関連する部分（変動）を取り除く。そのために、得票率を議員経験に回帰する。\n\nreg2 &lt;- lm(voteshare ~ experience, \n           data = HR09)\n\nこの単回帰の残差 (residuals) を取り出す。\n\nres2 &lt;- reg2$residuals\n\nこの残差は、議員経験によっては説明できない得票率の変動だと考えられる。つまり、この残差は、得票率から議員経験の影響を取り除いたものであると考えることができる。\nこれらの残差を使い、「得票率のうち議員経験とは関係ない部分」を「選挙費用のうち、議員経験とは関係ない部分」に回帰する。\n\nreg3 &lt;- lm(res2 ~ res1)\ncoef(reg3)\n\n (Intercept)         res1 \n4.775712e-16 1.830675e+00 \n\n\nこの単回帰によって得られた係数 1.83は、重回帰によって得られた選挙費用の偏回帰係数に一致することがわかる。 ここから、偏回帰係数が、他の変数の影響を取り除いた後に、ある説明変数が応答変数に与える影響であることが読み取れる。\n課題\n上と同じ方法（単回帰で得られる残差同士の単回帰で、重回帰の偏回帰係数を求める方法; この方法を回帰解剖と呼ぶ）で、議員経験の偏回帰係数 18.3710255 を求めなさい。\n\n7.2.2 重回帰分析の信頼区間を図示する\n上の重回帰分析の結果を図示しよう。\n議員経験を\\(\\{0, 1\\}\\)のいずれかとして、選挙費用 [100万円] を最小値から最大値まで動かし、それぞれの組み合わせで \\(\\hat{V}_i\\) を計算したい。そのために、まずは2つの変数の値の組み合わせ考慮するためのデータフレームを作る。2つ以上の変数のすべての組み合わせを作るために、tidyr::expand_grid() を利用する。\n\npred &lt;- expand_grid(\n  expm = seq(from = min(HR09$expm, na.rm = TRUE), \n             to = max(HR09$expm, na.rm = TRUE), \n             length.out = 100),\n  experience = c(0,1))\n\nこれを利用して予測値を計算する。予測値は、predict() で求めることができる。\n\npred &lt;- pred |&gt; \n  mutate(v_hat = predict(fit_3, newdata = pred))\n\nこのデータを使って重回帰の結果を図示する。散布図の点 （観測値） は元データ HR09 で描き、回帰直線は予測値 pred で描く\n\np3 &lt;- ggplot(HR09, aes(x = expm,\n                       color = as.factor(experience),\n                       shape = as.factor(experience))) +\n  geom_point(size = 1, aes(y = voteshare)) +\n  geom_line(data = pred, aes(y = v_hat)) +\n  scale_color_brewer(palette = \"Set1\",\n                     name = '議員経験', \n                     labels = c('なし', 'あり')) +\n  scale_shape_discrete(name = '議員経験',\n                       labels = c('なし', 'あり')) +\n  guides(color = guide_legend(reverse = TRUE),\n         shape = guide_legend(reverse = TRUE)) +\n  labs(x = \"選挙費用（100万円）\", \n       y = \"得票率（%）\",\n       title = \"得票率と選挙費用の関係\")\nplot(p3)\n\n\n\n\n\n\n\nこの図からわかるように、このモデルは2つの直線が平行になる（傾きが同じになる）ように設定されている。これは、私たちが選んだ統計モデルの仮定による。\nこの図に95パーセント信頼区間を加えよう。 信頼区間を求めるために標準誤差を利用する。 また、標準誤差は\\(t\\) 分布に従うので、qt() で分布の95%が収まる範囲を求める （標準正規分布で近似し、\\(\\pm 1.96\\) を使っても結果に大きな違いはないが、せっかくRを使っているのだから、より正確な数値を利用したほうがよい）。\n予測値と標準誤差を求める。predict() で se.fit = TRUE とすると、予測値とともに標準誤差（の推定値）も計算される。\n\nerr &lt;- predict(fit_3, \n               newdata = pred, \n               se.fit = TRUE)\n\nこの予測値と標準誤差を使って95パーセント信頼区間を求める。両側から2.5パーセントずつの領域を除外したいので、下側の臨界値までの累積確率は2.5パーセント、上側臨界値までは97.5パーセントである。\n\npred$lower &lt;- err$fit + qt(0.025, df = err$df) * err$se.fit\npred$upper &lt;- err$fit + qt(0.975, df = err$df) * err$se.fit\n\nこの信頼区間を図に上書きする。geom_smooth() を使う。（ggplot2 が計算する値ではなく）自分で計算した値を使うために、stat = \"identity\" を指定する。\n\np3_ci95 &lt;- p3 +\n    geom_smooth(data = pred, \n                aes(y = v_hat, ymin = lower, ymax = upper), \n                stat = \"identity\")\nplot(p3_ci95)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>重回帰分析</span>"
    ]
  },
  {
    "objectID": "multiple-regression.html#欠落変数バイアスと処置後変数バイアス",
    "href": "multiple-regression.html#欠落変数バイアスと処置後変数バイアス",
    "title": "\n7  重回帰分析\n",
    "section": "\n7.3 欠落変数バイアスと処置後変数バイアス",
    "text": "7.3 欠落変数バイアスと処置後変数バイアス\n重回帰分析では複数の説明変数を使う。複数の説明変数を使う理由の1つは、ある結果（応答変数）に影響を与える原因が複数あると考えられるからである。そのようなとき、原因と考えられる複数の説明変数を回帰分析に含めるというの自然な発想である。しかし、応答変数の原因の中には、必ず回帰分析に含める必要があるものもあれば、回帰分析に入れても入れなくてもよいものや、回帰分析に入れてはいけないものもある。回帰分析では主な説明変数以外の変数を統制変数 (control variables) や共変量 (covariates) と呼ぶことがあるが、回帰分析で統制 (control) すべき変数はどのようなものだろうか。\n\n\n7.3.1 欠落変数バイアス\n2つの変数 \\(y\\) と\\(x\\) があり、この2変数の間に強い相関があるとする。このとき、\\(x\\)が\\(y\\)の原因であるとは限らない。1つの可能性は、\\(y\\)が\\(x\\)の原因であるというものである。因果の向きが逆の場合は比較的見抜きやすいので、ここではその可能性はとりあえず考えない（実際の研究では、フィードバック効果などもあり、注意すべき問題である。どちらが原因でどちらが結果なのか判別できない場合もある）。\nもう1つの可能性は、第三の変数 \\(z\\) が存在し、\\(z\\)が\\(x\\)の原因でもあると同時に、\\(y\\)の原因でもあるという場合である。 \\(x\\)と\\(y\\)の相関が\\(z\\)によって説明されてしまうとき、\\(x\\)と\\(y\\)の相関は、見せかけの因果関係 (spurious correlation) と呼ばれる。また、実際に\\(x\\)が\\(y\\)の原因だとしても、 \\(z\\)のように\\(x\\)と\\(y\\)の両者に影響する変数があるかもしれない。このような\\(z\\) は、交絡変数 (confouding variable or confounder)  と呼ばれる。\n交絡変数は、必ず統制する必要がある。交絡変数を統制しないと、推定にバイアスが生じる。このバイアスを欠落変数バイアス (omitted variable bias) と呼ぶ。経済学では、セレクションバイアス（selection bias） とも呼ばれる。\n\\(y\\)と\\(x\\)の両者に影響を与える\\(z\\)という変数があるとき、\\(z\\)を無視して、 \\[y_i = \\beta_0 + \\beta_1 x_i + u_i\\] という式を考えると、\\(z\\) は誤差項\\(u\\)に含まれることになる。 そうすると、当然ながら、説明変数\\(x\\)と誤差項\\(u\\)の間に相関があるので、最小二乗法を使うための前提（「誤差の独立性」教科書 pp.245-246）が満たされず、\\(\\beta_1\\) の推定が偏ったもの（つまり、バイアスをもったもの）になってしまうのである。\nこのことを、シミュレーションで確認してみよう。 まず、データを作る。ここでは、x, z1, z2 という3つの変数がyの原因となっている（muを計算する行を参照）。また、z1はxの原因でもあるので、z1は交絡変数である。したがって、z1を統制(（コントロール）しないと、xの係数が正しく推定できないはずである。z3は応答変数とは無関係の変数である。\n\n# シミュレーションを再度実行したときに同じ結果が得られるように、乱数の種を指定する\n# 異なる結果を得たいときは、set.seed() の中身を変える\nset.seed(777)   \nN &lt;- 100\nz1 &lt;- runif(N, -5, 5)\nz2 &lt;- runif(N, -5, 5) \nz3 &lt;- runif(N, -5, 5)\nx &lt;- 0.2 * z1 + rnorm(N)\nmu &lt;- 1.5 + 0.4 * x + 0.5 * z1 - 0.2 * z2 \ny &lt;- rnorm(N, mean = mu, sd = 1)\ndf &lt;- tibble(y, x, z1, z2, z3)\n\nまず、正しいモデルを作り、パラメタを推定する。\n\ntrue_model &lt;- lm(y ~ x + z1 + z2, data = df)\ntidy(true_model)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    1.58     0.114      13.8  1.55e-24\n2 x              0.419    0.104       4.04 1.07e- 4\n3 z1             0.507    0.0432     11.7  3.19e-20\n4 z2            -0.159    0.0415     -3.83 2.26e- 4\n\n\nxの係数に注目すると、パラメタとして設定した 0.4 にある程度近い値0.42 が得られる。\n次に、交絡変数であるz1を除外した「正しくない」モデルでパラメタを推定する。\n\nomitted_1 &lt;- lm(y ~ x + z2, data = df)\ntidy(omitted_1)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    1.55     0.177       8.77 6.16e-14\n2 x              0.983    0.142       6.91 5.14e-10\n3 z2            -0.157    0.0644     -2.44 1.64e- 2\n\n\nこのモデルでは、xの係数の推定値が 0.98 になり、xのyに対する影響がかなり過大に推定されている。\n続いて、\\(y\\) の原因ではあるが、交絡変数ではないz2 を除外してみる。\n\nomitted_2 &lt;- lm(y ~ x + z1, data = df)\ntidy(omitted_2)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    1.62     0.121      13.3  1.18e-23\n2 x              0.384    0.110       3.48 7.48e- 4\n3 z1             0.506    0.0462     11.0  1.16e-18\n\n\nここでは、xの係数は、正しい値である0.4に近い。\n最後に、yの原因ではない（関係のない）z3 を加えて回帰分析をしてみよう。\n\nextra_model &lt;- lm(y ~ x + z1 + z2 + z3, data = df)\ntidy(extra_model)\n\n# A tibble: 5 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  1.57       0.115     13.7   2.82e-24\n2 x            0.422      0.105      4.02  1.17e- 4\n3 z1           0.507      0.0435    11.7   5.21e-20\n4 z2          -0.159      0.0417    -3.81  2.46e- 4\n5 z3          -0.00954    0.0395    -0.241 8.10e- 1\n\n\nxの係数についてはほぼ正しい値に近い推定値が得られた。また、z3の係数が0に近く、影響がないという事実に合致する結果が得られた。\nここまでのシミュレーションは、データセットを1つ生成し、それを分析しただけである。1つのデータだけでは偶然そうなっただけかもしれないので、上のシミュレーションを繰り返し行い、推定結果を調べてみよう。\nまず、繰り返しシミュレーションを行うための関数を作る。\n\nsim_regression &lt;- function(trials = 200, n = 50, beta = .4) {\n    ## 重回帰分析をシミュレートするための関数\n    ## 引数：trials = シミュレーションの繰り返し回数（既定値は200)\n    ##       n = 標本サイズ（既定値は50）\n    ##       beta = x 係数 (beta) の母数（パラメタ）\n    ## 返り値：res = 係数の推定値を要素にもつ行列\n    \n    z1 &lt;- matrix(runif(trials * n, -5, 5), nrow = n)\n    z2 &lt;- matrix(runif(trials * n, -5, 5), nrow = n)\n    z3 &lt;- matrix(runif(trials * n, -5, 5), nrow = n)\n    x &lt;- 0.2*z1 + rnorm(trials * n)\n    mu &lt;- 1.5 + beta * x + 0.5 * z1 - 0.2 * z2 \n    y &lt;- mu + rnorm(trials*n, mean = 0, sd = 1)\n    \n    beta_hat &lt;- matrix(NA, nrow = trials, ncol = 4)\n\n    colnames(beta_hat) &lt;- c('true', 'omit1', 'omit2', 'extra')\n   \n    for (i in 1:trials) {\n        df &lt;- tibble(y = y[,i], \n                     x = x[,i], \n                     z1 = z1[,i], \n                     z2 = z2[,i], \n                     z3 = z3[,i])\n        true_fit &lt;- lm(y ~ x + z1 + z2, data = df)\n        fit_omit1 &lt;- lm(y ~ x + z2, data = df)\n        fit_omit2 &lt;- lm(y ~ x + z1, data = df)\n        fit_extra &lt;- lm(y ~ x + z1 + z2 + z3, data = df)  \n        beta_hat[i, ] &lt;- c(coef(true_fit)[2], \n                           coef(fit_omit1)[2],\n                           coef(fit_omit2)[2], \n                           coef(fit_extra)[2])\n    }\n    return(beta_hat)\n}\n\n作った関数を使い、シミュレーションを実行する。xの係数のパラメタ（母数）は0.4に設定する。\n\nbeta &lt;- 0.4\nset.seed(2019-11-11)\nsim1 &lt;- sim_regression(trials = 200, n = 50, beta = beta)\n\n各モデルの係数の最小二乗推定値の平均値を確認する。\n\napply(sim1, 2, mean)\n\n     true     omit1     omit2     extra \n0.4143817 1.0331296 0.4128824 0.4135912 \n\n\nこの結果をみると問題がある（推定値の平均が母数である0.4から外れている）のはomit1だけである。それぞれのモデルから得られた係数betaの推定値の分布を図示してみよう。\n\nsim1_beta &lt;- as_tibble(sim1)  # ggplot2 を使うためにデータフレームに変換\n# 全モデルに共通する図のベースを作る\nplt_base &lt;- ggplot(sim1_beta, aes(y = after_stat(density))) +\n  xlab(expression(paste(beta, \"の推定値\", sep = \"\"))) +\n  ylab(\"確率密度\")\n\n正しいモデル。\n\nplt_true &lt;- plt_base + \n    geom_histogram(aes(x = true), color = 'black', bins = 12) +\n    geom_vline(xintercept = beta, color = 'red') +\n    ggtitle(\"正しいモデルの推定値の分布\")\nplot(plt_true)\n\n\n\n\n\n\n\n交絡変数を除外したモデル。\n\nplt_omit1 &lt;- plt_base + \n    geom_histogram(aes(x = omit1), color = 'black', bins = 12) +\n    geom_vline(xintercept = beta, color = 'red') +\n    ggtitle(\"交絡変数を除外したモデルの推定値の分布\")\nplot(plt_omit1)\n\n\n\n\n\n\n\n交絡ではない原因を除外したモデル。\n\nplt_omit2 &lt;- plt_base + \n    geom_histogram(aes(x = omit2), color = 'black', bins = 12) +\n    geom_vline(xintercept = beta, color = 'red') +\n    ggtitle(\"交絡ではない原因を除外したモデルの推定値の分布\")\nplot(plt_omit2)\n\n\n\n\n\n\n\n応答変数の原因ではない余分な変数を加えたモデル。\n\nplt_extra &lt;- plt_base + \n    geom_histogram(aes(x = extra), color = 'black', bins = 12) +\n    geom_vline(xintercept = beta, color = 'red') +\n    ggtitle(\"余分な変数を追加したモデルの推定値の分布\")\nplot(plt_extra)\n\n\n\n\n\n\n\nこのシミュレーションから、交絡変数ではない原因を入れ損ねたり、原因ではない変数を入れてしまうのは問題ないが、交絡変数を説明変数に加え忘れると、平均して誤った分析結果を出してしまうことがわかる。したがって、交絡変数は必ず回帰分析に加える必要がある。\n交絡を入れ損ねるとバイアスが生じ、関係ない変数を入れても問題がないのであれば、できるだけ多くの変数を統制した方がよさそうである。実際、欠落変数バイアスを防ぐためには、できるだけたくさんの要因を統制した方がよい。ただし、手当たり次第に変数を投入すると起きる問題が、（少なくとも）2つある。\nまず、モデルが現実（真実）から乖離する確率が大きくなる。 この問題が起きるのは、モデルに含む説明変数が増えるにつれて、変数同士の関係のあり方のパタン（例えば、2変数以上の相互作用があるかどうか）が増えるのに対し、実際に正しいモデル（実際にデータが生成される過程）は1つしかないはずだからである。この問題は、ノンパラメトリックな方法を使えば、回避することができる（今回は考えない）。\n2つ目の問題は、処置後変数バイアスという異なる種類のバイアスが生じる可能性である。 この問題は、以下のシミュレーションで理解しよう。\n\n\n7.3.2 処置後変数バイアス\n処置後変数バイアス（post treatment variable bias）とは、\\(y\\) の原因の1つであるが、主な説明変数（因果推論の文脈ではこれを処置変数 [treatment variable] と呼ぶ）である\\(x\\)の結果でもあるような変数、つまり、\\(x\\)と\\(y\\)の関係を仲介するような変数である\\(z\\)や、\\(x\\)からも\\(y\\)からも影響を受ける合流点\\(z\\)を予測変数として使うことによって生じるバイアスである。処置後変数バイアスがあると、\\(x\\)が\\(y\\)に及ぼす効果を正しく推定することができない。\n以下のシミュレーションで、処置後変数バイアス（特に、媒介変数によるバイアス）を確認してみよう。\nまず、\\(x\\)が\\(y\\)に与える効果を設定する。\n\ntrue_effect &lt;- .25\n\n次に、処置後変数を含むデータ生成過程を表す関数を作る。\n\nptb_dgp &lt;- function(n = 100) {\n    # 処置後変数バイアス問題をシミュレートする関数\n    x &lt;- rbinom(n, size = 1, prob = .5)\n    z &lt;- 0.3 + 0.2 * x + rnorm(n, mean = 0, sd = 0.1)\n    y &lt;- 0.2 + (true_effect / 0.2) * z  + rnorm(n, mean = 0, sd = 0.1)\n    return(tibble(y, x, z))\n}\n\n試しにデータセットを1つ作る。\n\nset.seed(2011-11-06)\ndf &lt;- ptb_dgp()\nglimpse(df)\n\nRows: 100\nColumns: 3\n$ y &lt;dbl&gt; 0.5931201, 0.8924408, 0.8392817, 0.8599872, 0.9411503, 0.3442116, 0.…\n$ x &lt;int&gt; 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,…\n$ z &lt;dbl&gt; 0.3249840, 0.5714314, 0.4143175, 0.5307784, 0.5359589, 0.1685075, 0.…\n\n\nここで、\\(x\\)と\\(z\\)の相関関係を確認してみよう。\n\nwith(df, cor(x, z))\n\n[1] 0.6949966\n\n\n\\(z\\)と\\(x\\)の間に正の相関があることがわかる。また、\\(y\\)と\\(z\\)については、\n\nwith(df, cor(y, z))\n\n[1] 0.8771216\n\n\nとなり、やはり正の相関を示している。\nそこで、「欠落変数バイアスを避けるために」（モチベーションは正しいが、方法が間違っている）、\\(z\\)を予測変数に含む以下のモデルを考える。 \\[y_i = \\alpha + \\beta x_i + \\gamma z_i + u.\\] このモデルのパラメタを推定してみよう。\n\nfit_with &lt;- lm(y ~ x + z, data = df)\ntidy(fit_with)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   0.167     0.0353     4.72  7.96e- 6\n2 x            -0.0257    0.0282    -0.911 3.65e- 1\n3 z             1.37      0.101     13.6   3.00e-24\n\n\n推定値を見ると、xの係数\\(\\beta\\)は過小推定（本当は 0.25）されている。\nここで、説明変数 \\(z\\)を除外して、以下のモデルを考えてみよう。 \\[y_i = \\alpha + \\beta x_i + u.\\] このモデルのパラメタを推定しよう。\n\nfit_wo &lt;- lm(y ~ x, data = df)\ntidy(fit_wo)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    0.601    0.0258     23.3  9.02e-42\n2 x              0.241    0.0344      7.01 3.09e-10\n\n\nコントロールすべきと考えていた \\(z\\) を除外したモデルなのに、\\(\\beta\\)の推定値は設定した値である0.25 に近い。 これは偶然だろうか？シミュレーションで確かめてみよう。\n1回シミュレーションを実行し、処置後変数を含むモデルと含まないモデルの係数の推定値を返す関数を作る。\n\nsim_ptb &lt;- function(true_effect = 0.25, n = 100) {\n    df &lt;- ptb_dgp(n = n)\n    fit_with &lt;- lm(y ~ x + z, data = df)\n    fit_wo &lt;- lm(y ~ x, data = df)\n    betas &lt;- c(coef(fit_with)[2], coef(fit_wo)[2])\n    names(betas) &lt;- c('with', 'without')\n    return(betas)\n}\n\nこの関数を、replicate() で複数回実行する。500回繰り返してみよう。\n\nptb_1 &lt;- replicate(500, sim_ptb())\n\n結果をヒストグラムで確認する。処置後変数を含む場合。\n\ndd &lt;- tibble(with = ptb_1[1, ],\n             without = ptb_1[2, ])  # ggplot で使うためのデータセット\nhist_with &lt;- ggplot(dd, aes(x = with, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 bins = 12) +\n  geom_vline(xintercept = true_effect, \n             color = \"red\") +\n  labs(x = \"処置後変数を含むモデルの推定値\", \n       y = \"確率密度\")\nplot(hist_with)\n\n\n\n\n\n\n\n処置後変数を含まない場合。\n\nhist_wo &lt;- ggplot(dd, aes(x = without, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 bins = 12) +\n  geom_vline(xintercept = true_effect, \n             color = \"red\") +\n  labs(x = \"処置後変数を含まない（正しい）モデルの推定値\", \n       y = \"確率密度\")\nplot(hist_wo)\n\n\n\n\n\n\n\nこのように、ある変数\\(x\\)の効果を推定したいときは、その変数の結果として出てくる変数を統制してはいけない。変数間に時間的な前後関係があれば、このバイアスを回避するのは比較的容易である。しかし、時間的な前後関係が不明なとき、ある変数が交絡変数か処置後変数かを見抜くのは難しい場合がある。統計モデルを作るときには、自分が統制する変数は交絡であり、処置後変数ではないことを理論的に示す必要がある。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>重回帰分析</span>"
    ]
  },
  {
    "objectID": "regression-misc.html",
    "href": "regression-misc.html",
    "title": "\n8  回帰分析の応用\n",
    "section": "",
    "text": "8.1 準備\nまず、必要なパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))\n説明のために『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\nデータを読み込み、HRという名前のデータフレームを作る。\nHR &lt;- read_csv(\"data/hr-data.csv\")\n#glimpse(HR)\n衆議院議員経験があることを表すダミー変数を作る。\nHR &lt;- HR |&gt; \n  mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"))\n2009年の結果だけ抜き出したデータフレームをHR09として保存する。 （本来はmi() などで欠測値を推定すべきだが、説明を単純化するために、今回は）na.omit() を使って完全データ (complete observations) だけ残す。\nHR09 &lt;- HR |&gt;\n    filter(year == 2009) |&gt;\n    na.omit()",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>回帰分析の応用</span>"
    ]
  },
  {
    "objectID": "regression-misc.html#回帰分析で使うテクニック",
    "href": "regression-misc.html#回帰分析で使うテクニック",
    "title": "\n8  回帰分析の応用\n",
    "section": "\n8.2 回帰分析で使うテクニック",
    "text": "8.2 回帰分析で使うテクニック\n\n8.2.1 線形変換\n選挙費用を説明変数、得票率を応答変数とする回帰式を推定する。\n選挙費用を1円単位で測定した exp を使った回帰式は、次のように求めることができる。\n\nfit_1 &lt;- lm(voteshare ~ exp, \n            data = HR09)\ntidy(fit_1, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term          estimate    std.error statistic   p.value   conf.low  conf.high\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept) 7.71       0.758             10.2 2.98e- 23 6.22       9.19      \n2 exp         0.00000308 0.0000000961      32.0 3.64e-160 0.00000289 0.00000327\n\n\nよって、 \\[\\widehat{得票率} = 7.74  + 0.00000307 \\cdot 選挙費用（1円）\\] である。\nこれに対し、選挙費用を100万円単位で測定した expm を使うと、次のような結果になる。\n\nfit_2 &lt;- lm(voteshare ~ expm, \n            data = HR09)\n## expm という変数をあらかじめ作っていないときは、次のようにする\n#fit_3 &lt;- lm(voteshare ~ I(exp / 10^6), data = HR09)\ntidy(fit_2, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     7.71    0.758       10.2 2.98e- 23     6.22      9.19\n2 expm            3.08    0.0961      32.0 3.64e-160     2.89      3.27\n\n\nよって、 \\[\\widehat{得票率} = 7.74+ 3.07 \\cdot 選挙費用（100万円）\\] である。\nこれらの2つの回帰式の内容は、実質的にはまったく同じである。 どちらがわかりやすい？\n\n\n8.2.2 標準化\n\\(z\\)値で標準化した変数を使って回帰分析を行ってみよう。 変数\\(x\\)の\\(z\\)値は、 \\[z_x=\\frac{x - \\bar{x}}{u_x}\\] で求められる。ただし、\\(u_x\\)は\\(x\\)の不偏分散の平方根である。\n例として、選挙費用（測定単位：100万円）を標準化し、得票率を説明してみよう。\n\nHR09 &lt;- HR09 |&gt; \n  mutate(z_expm = (expm - mean(expm, na.rm = TRUE)) / sd(expm, na.rm = TRUE))\nsummary(HR09$z_expm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-1.2221 -0.8650 -0.2624  0.0000  0.6002  3.8514 \n\n\nこれで、expm の\\(z\\)値 z_expm が得られた（scale()を使うともっと簡単に計算できる）。この変数を利用して回帰式を求める。\n\nfit_4 &lt;- lm(voteshare ~ z_expm, \n            data = HR09)\ntidy(fit_4, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     26.5     0.480      55.3 5.93e-322     25.6      27.5\n2 z_expm          15.4     0.480      32.0 3.64e-160     14.4      16.3\n\n\nこの結果は、選挙費用（100万円）が1標準偏差増えるごとに、得票率が平均して15.37ポイント上昇することを示している。 切片の26.52は、選挙費用が平均値をとったときの得票率の予測値（平均値）である。\n\n8.2.3 中心化\n議員経験と選挙費用で得票率を説明するモデルを考える。 回帰式を求めると、\n\nfit_5 &lt;- lm(voteshare ~ experience * expm, data = HR09)\ntidy(fit_5, conf.int = TRUE)\n\n# A tibble: 4 × 7\n  term            estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -2.09     0.714     -2.93 3.48e-  3    -3.49    -0.690\n2 experience         46.2      1.57      29.4  2.62e-141    43.1     49.3  \n3 expm                4.86     0.165     29.5  7.50e-142     4.53     5.18 \n4 experience:expm    -4.76     0.206    -23.1  1.60e- 96    -5.16    -4.35 \n\nglance(fit_5)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.707         0.706  12.0      895. 2.72e-296     3 -4371. 8752. 8777.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nと、なる。このとき、係数の推定値は何を表しているだろうか。 特に、相互作用（後のトピックの講義で説明する）を表す係数には注意が必要である。\n説明変数を中心化してから、同様の回帰式を求めてみよう。\n\nHR09 &lt;- HR09 |&gt; \n  mutate(c_experience = experience - mean(experience),\n         c_expm = expm - mean(expm, na.rm = TRUE))\nfit_5_c &lt;- lm(voteshare ~ c_experience * c_expm, data = HR09)\ntidy(fit_5_c, conf.int = TRUE)\n\n# A tibble: 4 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)            34.5      0.501      69.0 0            33.6      35.5 \n2 c_experience           17.1      1.01       16.9 4.27e- 57    15.1      19.1 \n3 c_expm                  2.93     0.110      26.6 5.99e-121     2.71      3.14\n4 c_experience:c_expm    -4.76     0.206     -23.1 1.60e- 96    -5.16     -4.35\n\nglance(fit_5)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.707         0.706  12.0      895. 2.72e-296     3 -4371. 8752. 8777.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nまず、残差の標準偏差 (sigmaの値、すなわち 12.0) と\\(R^2\\) (0.706) が説明変数を中心化する前のモデルとまったく同じことを確認してほしい。 これは、変数の中心化を行っても、回帰式の実質的な内容に変化がないことを示している。\n次に、係数の意味を考えよう。切片である34.6 が表しているのは、すべての説明変数が平均値をとったときの得票率の予測値である。中心化する前のモデルでは、すべての説明変数が0のとき（非現実的でデータを代表しない値）の予測値が示されていたが、説明変数を中心化することによって、実質的に意味のある切片（データを代表するケースの予測値）を得ることができた。\nc_experience の係数は、選挙費用が平均値のとき、議員経験がある候補者のほうが、議員経験がない候補者より16.99ポイント高い得票率を得ると期待されることを示す。中心化する前のモデルでは選挙費用が0の候補者（そのような候補者は存在しない！）の傾きが示されていたのに対し、ここではデータ全体を代表する傾きが示されている。\nc_expmの係数は、議員経験が平均値のとき、選挙費用を1単位（100万円）増やすごとに得票率が平均2.937ポイント上昇することが期待されることを示す。中心化する前のモデルでは議員経験がない候補者の傾きが示されていたのに対し、ここではデータ全体を代表する（平均的な候補者の）傾きが示されている。\nそして、c_experienceとc_expmの交差項の係数は、議員経験がある候補者とない候補者の間には、選挙費用1単位が得票率に与える影響（傾き）の差が4.77であることを示す。この値は、中心化する前のモデルと同じである。\n\n8.2.4 対数変換\nRで自然対数に変換するにはlog() を、10を底とする対数に変換するにはlog10() を使う。 その他の値\\(b\\)を底とする\\(x\\)の対数\\(\\log_b(x)\\)はlog(x, base = b) で求めることができる。\n対数変換した変数を回帰分析で利用するときは、事前に変数を変換してもよいが、分析と同時に変換することもできる。たとえば、次のようにする。\n\nfit_6 &lt;- lm(log(voteshare) ~ expm, \n            data = HR)\ntidy(fit_6, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    1.83    0.0174      105.        0    1.79      1.86 \n2 expm           0.134   0.00187      71.9       0    0.130     0.138\n\n\n係数の値を元の測定単位に戻したいときは、exp() で計算すればよい。対数変換していない説明変数である expm 1単位の増加すなわち100万円の支出増は、得票率を\n\nexp(coef(fit_6)[2]) - 1\n\n     expm \n0.1434833 \n\n\nだけ変化させる。つまり、得票率を14.3パーセント増加させる。",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>回帰分析の応用</span>"
    ]
  },
  {
    "objectID": "regression-misc.html#二次関数の推定",
    "href": "regression-misc.html#二次関数の推定",
    "title": "\n8  回帰分析の応用\n",
    "section": "\n8.3 二次関数の推定",
    "text": "8.3 二次関数の推定\n教育の収益率について考えよう。労働経済学においてミンサー方程式 (Mincer equation, Mincer earnings function) と呼ばれる、次のような式がある（田中 2015: 第6章を参照 [電子書籍]）。 \\[\n\\log(賃金_i) = \\beta_0 + \\beta_1 修学年数_i + \\beta_2 就業経験_i + \\beta_3 就業経験_i^2 + \\epsilon_i\n\\] ただし、「就業経験」は、 \\[\n就業経験 = 年齢 - 修学年数 - 6\n\\] である（田中 [2015] では「就業可能年数」とされている）。最後の項の6は、小学校に入学する年齢である。\nこのミンサー方程式を、回帰分析で推定してみよう。ここで確かめたいのは、 1. 修学年数が賃金を上昇させるか（そして、どれくらい上昇させるか） 2. 就業経験が賃金を上昇させるか（そして、どれくらい上昇させるか） であるが、就業経験の二乗項も説明変数に含まれている。これは、経験が浅いうちは、経験が賃金に与える正の効果が大きいが、年齢が上がると経験を積んでも賃金が上がりにくくなる（場合によっては下がる）ことが想定されるからである。つまり、経験が賃金に及ぼす影響は逓減すると想定されている。\n練習のために fake_income.csv を使う（名前からわかる通り、架空のデータである）。データをダウンロードしてプロジェクト内のdata ディレクトリに保存しよう。保存できたら、データを読み込む。\n\ndownload.file(\n  url = \"https://yukiyanai.github.io/jp/classes/econometrics1/contents/data/fake_income.csv\",\n  dest = \"data/fake_income.csv\")\nmyd &lt;- read_csv(\"data/fake_income.csv\")\n\nRows: 1000 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): income, education, experience\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(myd)\n\nRows: 1,000\nColumns: 3\n$ income     &lt;dbl&gt; 33.9522, 124.6808, 140.4259, 79.6559, 145.1946, 1000.2209, …\n$ education  &lt;dbl&gt; 12, 16, 12, 14, 16, 16, 15, 14, 15, 16, 18, 12, 13, 15, 14,…\n$ experience &lt;dbl&gt; 3, 18, 16, 14, 14, 11, 10, 16, 20, 18, 19, 6, 20, 19, 10, 5…\n\n\nこの回帰分析における応答変数は所得 income （万円）の自然対数、説明変数は修学年数 education、就業経験年数 experience と就業経験年数の二乗である。\nまず、lm() を使って推定を行う。推定式の中で自然対数を計算するために log() を、二乗の計算を行うために、二乗した式を I() で囲む。\n\nfit_mincer &lt;- lm(log(income) ~ education + experience + I(experience^2), \n                 data = myd)\n\n結果を確認してみよう。\n\ntidy(fit_mincer, conf.int = TRUE)\n\n# A tibble: 4 × 7\n  term            estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      2.07     0.215         9.60 6.09e-21  1.65      2.49   \n2 education        0.138    0.0143        9.61 5.61e-21  0.109     0.166  \n3 experience       0.202    0.0162       12.5  2.92e-33  0.170     0.233  \n4 I(experience^2) -0.00637  0.000683     -9.34 6.32e-20 -0.00771  -0.00503\n\n\n応答変数が自然対数になっていて、修学年数 (education) の係数の推定値が 0.14なので、教育の収益率は14%ほどであることがわかる。また、\\(t\\)値（statistic の列の値）が2よりもだいぶ大きいので、5パーセントの有意水準でこの効果は統計的に有意であることがわかる。\n問： では、この効果は実質的に重要だろうか？\n修学年数の影響とは異なり、就業経験の効果は、推定値を見ただけではわかりにくい。なぜなら、就業経験年数を動かすと、就業経験年数の二乗も一緒に動いてしまうからだ。そこで、修学年数を固定し、就業経験年数と就業経験年数の二乗を動かすと、応答変数である年収の対数がどのように動くか図示してみよう。\nまず、データ内の修学年数の平均値を求める。\n\n(mean_educ &lt;- mean(myd$education))\n\n[1] 13.832\n\n\n次に、就業経験年数の最小値と最大値を求め、その範囲の値をとる長さ1,000のベクトルを作る。\n\nexper_vec &lt;- with(myd, \n                  seq(from = min(experience), \n                      to = max(experience), \n                      length.out = 1000))\n\n修学年数を平均値に固定し、就業経験年数と就業経験年数の二乗を動かして予測値を求める。\n\npred_mean &lt;- coef(fit_mincer)[1] + \n             coef(fit_mincer)[2] * mean_educ +\n             coef(fit_mincer)[3] * exper_vec +\n             coef(fit_mincer)[4] * exper_vec^2\n\n就業経験年数の変化に応じて年収の自然対数がどのように変化するか図示してみよう。\n\ndd &lt;- tibble(exper = exper_vec,\n             pred_mean  = pred_mean)   # ggplot2 で使うためにデータフレームを作る\nplt_1 &lt;- ggplot(dd, aes(x = exper, y = pred_mean)) +\n  geom_line() +\n  labs(x = \"就業経験年数\", y = \"対数年収の予測値\", \n       title = \"修学年数が平均値（13.8年）のとき\")\nplot(plt_1)\n\n\n\n\n\n\n\nこれで、就業経験年数と対数年収の間にある非線形の関係が図示できた。 対数年収はわかりにくいので、exp() で元の単位に戻そう。\n\nplt_2 &lt;- ggplot(dd, aes(x = exper, y = exp(pred_mean))) +\n  geom_line() +\n  labs(x = \"就業経験年数\", \n       y = \"年収の予測値（万円）\", \n       title = \"修学年数が平均値（13.8年）のとき\")\nplot(plt_2)\n\n\n\n\n\n\n\nこれで、修学年数が平均値のとき、就業経験年数と年収の間にある関係が図示できた。\n修学年数が最小値のとき、最大値のときはどうだろうか。\n修学年数が最小値のときは、\n\n(min_educ &lt;- min(myd$education))\n\n[1] 9\n\npred_min &lt;- coef(fit_mincer)[1] + \n            coef(fit_mincer)[2] * min_educ +\n            coef(fit_mincer)[3] * exper_vec +\n            coef(fit_mincer)[4] * exper_vec^2\ndd$pred_min &lt;- pred_min\nplt_3 &lt;- ggplot(dd, aes(x = exper, y = exp(pred_min))) +\n  geom_line() +\n  labs(x = \"就業経験年数\", \n       y = \"年収の予測値（万円）\", \n       title = \"修学年数が最小値（9年）のとき\")\nplot(plt_3)\n\n\n\n\n\n\n\n修学年数が最大値のときは、\n\n(max_educ &lt;- max(myd$education))\n\n[1] 18\n\npred_max &lt;- coef(fit_mincer)[1] + \n            coef(fit_mincer)[2] * max_educ +\n            coef(fit_mincer)[3] * exper_vec +\n            coef(fit_mincer)[4] * exper_vec^2\ndd$pred_max &lt;- pred_max\nplt_4 &lt;- ggplot(dd, aes(x = exper, y = exp(pred_max))) +\n  geom_line() +\n  labs(x = \"就業経験年数\", \n       y = \"年収の予測値（万円）\", \n       title = \"修学年数が最大値（18年）のとき\")\nplot(plt_4)\n\n\n\n\n\n\n\n以上の結果を1つの図にまとめたいときは、以下のようにする（やや難しい）。 まず、データを変換する。 現在のデータは、\n\nhead(dd)\n\n# A tibble: 6 × 4\n   exper pred_mean pred_min pred_max\n   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0           3.97     3.31     4.54\n2 0.0260      3.98     3.31     4.55\n3 0.0521      3.98     3.32     4.56\n4 0.0781      3.99     3.32     4.56\n5 0.104       3.99     3.33     4.57\n6 0.130       4.00     3.33     4.57\n\ndim(dd)\n\n[1] 1000    4\n\n\nのように横長 (wide) になっている。これを縦長 (long) に変換する。そのために、tidyr::pivot_longer() を使う。\n\ndd_long &lt;- dd |&gt;\n  pivot_longer(cols = pred_mean:pred_max,\n               names_to = \"education\",\n               names_prefix = \"pred_\",\n               values_to = \"predicted\")\n\nどのように変換されたか確認してみよう。\n\nhead(dd_long)\n\n# A tibble: 6 × 3\n   exper education predicted\n   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 0      mean           3.97\n2 0      min            3.31\n3 0      max            4.54\n4 0.0260 mean           3.98\n5 0.0260 min            3.31\n6 0.0260 max            4.55\n\ndim(dd_long)\n\n[1] 3000    3\n\n\n1000行4列のデータが、3000行3列になったことがわかる。これで、3つの曲線を1つの図に示せる。 以下のようにする。\n\nplt5 &lt;- ggplot(dd_long, \n               aes(x = exper, y = exp(predicted), color = education)) +\n  geom_line() +\n  labs(x = \"就業経験年数\", y = \"年収の予測値（万円）\") +\n  scale_color_brewer(palette = \"Accent\",\n                     name = \"修学年数\",\n                     labels = c(\"最大値 (18年）\", \"平均値（13.8年）\", \"最小値（9年）\"))\nplot(plt5)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>回帰分析の応用</span>"
    ]
  },
  {
    "objectID": "regression-reports.html",
    "href": "regression-reports.html",
    "title": "\n9  分析結果の提示法\n",
    "section": "",
    "text": "9.1 準備\n必要なパッケージを読み込む。\npacman::p_load(tidyverse, \n               broom, \n               coefplot, \n               texreg)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))\n説明のために『Rによる計量政治学』（浅野正彦, 矢内勇生. 2018）で使用されているデータ（hr-data.csv）を使う。\nHR &lt;- read_csv(\"data/hr-data.csv\")\n#glimpse(HR)\n衆議院議員経験があることを表すダミー変数と選挙費用を100万円単位で測定する変数を作る。\nHR &lt;- HR |&gt; \n  mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"))\n2009年の結果だけ抜き出し、HR09として保存する（expm が欠測しているものを除外する）。\nHR09 &lt;- HR |&gt; \n  filter(year == 2009,\n         !is.na(expm))\n4つの回帰モデルを推定しておく。\nfit_1 &lt;- lm(voteshare ~ experience, data = HR09)\nfit_2 &lt;- lm(voteshare ~ expm, data = HR09)\nfit_3 &lt;- lm(voteshare ~ experience + expm, data = HR09)\nfit_4 &lt;- lm(voteshare ~ experience * expm, data = HR09)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>分析結果の提示法</span>"
    ]
  },
  {
    "objectID": "regression-reports.html#分析結果の提示",
    "href": "regression-reports.html#分析結果の提示",
    "title": "\n9  分析結果の提示法\n",
    "section": "\n9.2 分析結果の提示",
    "text": "9.2 分析結果の提示\n\n9.2.1 式を書く\n説明変数の数がそれほど多くない場合は、式で結果を示しても良い。\n例えば、fit_1 の推定結果は、次の式にまとめられる。 \\[\n\\begin{aligned}\n\\widehat{得票率} = &13.91 & + & 31.18 & \\cdot 議員経験\\\\\n                   &(0.62) & & (0.98) &\n\\end{aligned}\n\\] ただし、カッコ内は標準誤差である。\nこの式は、次のコードで書いた。\n$$\n\\begin{aligned}\n  \\widehat{得票率} \n   = & 13.91 \n      & + & 31.18 &  議員経験 \\\\\n     & (0.62) \n      &   & (0.98) & \n\\end{aligned}\n$$\nこのように、Quarto文書では$$で囲んだブロックに \\(\\TeX\\) 形式の数式を書くことができる（注意：Quarto [あるいは R Markdown] 以外で\\(\\LaTeX\\) の数式を書く際は、日本語を \\mathrm{} または \\mbox{} に入れる必要がある）。また、数式の中に推定値を利用する場合、数値を打ち込む代わりにRで計算した結果を利用することができる。上の例では、傾きである\\(31.18\\) をタイプする代わりに、round(coef(fit_1)[2], 2) というRコードを使っている。数式ブロックを独立させずに、文章中に数式を入れる場合は、$ で囲む（$ の数が異なるだけ）。\nこれに加え、サンプルサイズと決定係数（重回帰なら自由度調整済み決定係数）を表示する必要がある。サンプルサイズは、 length(fit_1$residuals) で、決定係数は summary(fit1)$r.squared （自由度調整済み決定係数は adj.r.squared）で表示することができるので、その値を記載する。\nさらに、信頼区間も表示することが望ましい。97%信頼区間は、次のように求めることができる。\n\nconfint(fit_1, level = 0.97)\n\n               1.5 %   98.5 %\n(Intercept) 12.55696 15.25858\nexperience  29.05440 33.30061\n\n\nよって、議員経験の回帰係数の97%信頼区間は [29.05,33.3] である。\n\\(\\TeX\\) 形式の数式の書き方については、以下のページ・サイトが参考になる。\n\n参考1\n参考2\n参考3\n\n9.2.2 表を作る\n回帰分析の結果を表にするには、texregパッケージ を使う（他にもさまざまなパッケージがある）。 どこに表示するかによって、使う関数が異なる。\n\nRStudio 内（またはR のコンソール）で表示：texreg::screenreg()\n\nHTML に render する：texreg::htmlreg()\n\n(LaTeXを使って) PDFに render する：texreg::texreg()\n\n\n基本的な使い方は、\n\nscreenreg(fit_1, \n          stars = NULL,\n          caption = \"得票率を応答変数とする単回帰の推定結果\",\n          caption.above = TRUE)\n\n\n=====================\n             Model 1 \n---------------------\n(Intercept)    13.91 \n               (0.62)\nexperience     31.18 \n               (0.98)\n---------------------\nR^2             0.48 \nAdj. R^2        0.48 \nNum. obs.    1124    \n=====================\n\n\nである。stars = NULL は必ず指定するようにしよう！\nこの資料のように、HTML にknit するときは、次のようにする。ただし、チャンクオプションで results: 'asis' を指定する。つまり、コードチャンクの冒頭が、\n\nのようになる。\nhtmlreg(fit_1, \n        stars = NULL,\n        caption = \"得票率を応答変数とする単回帰の推定結果\",\n        caption.above = TRUE)\n\n\n得票率を応答変数とする単回帰の推定結果\n\n\n\n \n\n\nModel 1\n\n\n\n\n\n(Intercept)\n\n\n13.91\n\n\n\n\n \n\n\n(0.62)\n\n\n\n\nexperience\n\n\n31.18\n\n\n\n\n \n\n\n(0.98)\n\n\n\n\nR2\n\n\n0.48\n\n\n\n\nAdj. R2\n\n\n0.48\n\n\n\n\nNum. obs.\n\n\n1124\n\n\n\n\n\nPDF にrenderする場合は、次のようにする（この資料はPDFではないので、結果は省略する）。results = 'asis' は必要。\n\ntexreg(fit_1, \n       stars = NULL,\n       caption = \"得票率を応答変数とする単回帰の推定結果\",\n       caption.above = TRUE)\n\n複数のモデルで回帰分析を実行した場合、結果を1つの表にまとめることもできる。また、日本語で論文・レポートを書くなら、表の中身も日本語にすべきである。\nmodels &lt;- list(fit_1, fit_2, fit_3, fit_4)\nhtmlreg(models, \n        stars = NULL,\n        caption = \"得票率を応答変数とする回帰モデルの推定結果\",\n        caption.above = TRUE,\n        custom.model.names = paste(\"モデル\", 1:4),  \n        custom.coef.name = c(\"切片\", \n                             \"議員経験\", \n                             \"選挙費用 (100万円）\", \n                             \"議員経験 x 選挙費用\"),\n        custom.gof.names = c(\"R&lt;sup&gt;2&lt;/sup&gt;\", \n                             \"自由度調整済みR&lt;sup&gt;2&lt;/sup&gt;\", \n                             \"観測数\"),\n        custom.note = \"注：括弧内は標準誤差。\")\n\n\n得票率を応答変数とする回帰モデルの推定結果\n\n\n\n \n\n\nモデル 1\n\n\nモデル 2\n\n\nモデル 3\n\n\nモデル 4\n\n\n\n\n\n切片\n\n\n13.91\n\n\n7.74\n\n\n7.89\n\n\n-2.10\n\n\n\n\n \n\n\n(0.62)\n\n\n(0.76)\n\n\n(0.69)\n\n\n(0.71)\n\n\n\n\n議員経験\n\n\n31.18\n\n\n \n\n\n18.37\n\n\n46.19\n\n\n\n\n \n\n\n(0.98)\n\n\n \n\n\n(1.23)\n\n\n(1.57)\n\n\n\n\n選挙費用 (100万円）\n\n\n \n\n\n3.07\n\n\n1.83\n\n\n4.87\n\n\n\n\n \n\n\n \n\n\n(0.10)\n\n\n(0.12)\n\n\n(0.16)\n\n\n\n\n議員経験 x 選挙費用\n\n\n \n\n\n \n\n\n \n\n\n-4.77\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.21)\n\n\n\n\nR2\n\n\n0.48\n\n\n0.48\n\n\n0.57\n\n\n0.71\n\n\n\n\n自由度調整済みR2\n\n\n0.48\n\n\n0.48\n\n\n0.56\n\n\n0.71\n\n\n\n\n観測数\n\n\n1124\n\n\n1124\n\n\n1124\n\n\n1124\n\n\n\n\n\n注：括弧内は標準誤差。\n\n\n\nただし、texreg()を使ってPDF にrender するときは、\"R&lt;sup&gt;2&lt;/sup&gt;\" の代わりに \"$R^2$ とする。\n\n\n9.2.3 図を作る\nキャタピラプロットと（飛行機図とも）呼ばれる図を使って、回帰分析の結果図示しよう。Jared Lander が作ったcoefplot パッケージを使うのが便利である。\n上で推定した4つのモデルについて、キャタピラプロットを作ってみよう。\n1つのモデルを図示するときは、coefplot::coefplot() を使う。チャンクオプションに fig.cap = \"ここに図のキャプションを書く\" を加えると図にキャプションをつけることができる。例えば、コードチャンクの冒頭に{r, fig.width = 5, fig.height = 3, fig.cap = \"モデル3の推定結果\"} とする。\n\nplt_fit3 &lt;- coefplot(\n  fit_3, \n  lwdOuter = 1,       # 95%信頼区間を表示する線分の太さ\n  intercept = FALSE,  # 切片は興味の対象ではないので非表示\n  title = \"係数の推定値：応答変数は得票率（％）\", \n  xlab = \"係数の推定値\", \n  ylab = \"説明変数\",\n  newNames = c(experience = \"議員経験\",　expm = \"選挙費用（100万円）\"))\nplot(plt_fit3)\n\n\n\nモデル3の推定結果\n\n\n\nこれで図ができる。（しかし、このモデルの場合、回帰係数の大きさがばらばらなので、1つの図に収めようとすると信頼区間がよくわからなくなってしまうという問題がある。）\nここで、興味があるのは選挙費用が得票率に与える影響のみであり、議員経験は交絡としてコントロールしたものであると仮定しよう。そうすると、結果として表示すべきは、選挙費用の係数と信頼区間のみである。言い換えると、議員経験の推定結果は表示したくない。次のようにする。\n\nplt_fit3b &lt;- coefplot(\n  fit_3, \n  lwdOuter = 1,      \n  coefficients = c(\"expm\"),  # この行を加える\n  intercept = FALSE, \n  title = \"係数の推定値：応答変数は得票率（％）\", \n  xlab = \"係数の推定値\", \n  ylab = \"説明変数\",\n  newNames = c(expm = \"選挙費用（100万円）\"))\nplot(plt_fit3b)\n\n\n\n選挙費用が得票率に与える影響\n\n\n\n複数のモデルを1つの図に示すときは、coefplot::multiplot() を使う。\n\nplt_multi &lt;- multiplot(\n  fit_1, fit_2, fit_3, fit_4,\n  intercept = FALSE, \n  numberAngle = 0,\n  title = \"係数の推定値：応答変数は得票率（％）\", \n  xlab = \"係数の推定値\", \n  ylab = \"説明変数\",\n  newNames = c(experience = \"議員経験\",　expm = \"選挙費用（100万円）\",\n               \"experience:expm\" = \"議員経験x選挙費用\")) +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"\", \n                     labels = paste(\"モデル\", 1:4))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nprint(plt_multi)\n\n\n\n複数のモデルの推定結果を1つの図で示す\n\n\n\nモデルごとに推定値の値が大きく異なるので、この図はあまりよくない。変数変換などを利用して、推定値の見かけ上の値がだいたい同じ範囲に収まるようにすることが望ましい。\nこれ（この程度の調整）で満足いく図ができるときは、ここで説明したようにcoefplot::coefplot()や coefplot::multiplot() を使うのが楽だ。さらなる微調整をしたいならggplot2::geom_pointrange() などを使って自力で作図することもできる。\nレポートや論文に載せる図表には必ず通し番号（図と表の番号は別々）とキャプションを付ける必要がある。これについては「統計学2」で学習済み なので、復習しておこう。",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>分析結果の提示法</span>"
    ]
  },
  {
    "objectID": "interaction.html",
    "href": "interaction.html",
    "title": "\n10  交差項の利用\n",
    "section": "",
    "text": "10.1 準備\n今回使うパッケージを読み込む。\npacman::p_load(tidyverse, \n               interplot, \n               broom)\n\nif (.Platform$OS.type == \"windows\") { \n  if (require(fontregisterer)) {\n    my_font &lt;- \"Yu Gothic\"\n  } else {\n    my_font &lt;- \"Japan1\"\n  }\n} else if (capabilities(\"aqua\")) {\n  my_font &lt;- \"HiraginoSans-W3\"\n} else {\n  my_font &lt;- \"IPAexGothic\"\n}\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>交差項の利用</span>"
    ]
  },
  {
    "objectID": "interaction.html#交差項の利用-1-調整変数がダミー変数の場合",
    "href": "interaction.html#交差項の利用-1-調整変数がダミー変数の場合",
    "title": "\n10  交差項の利用\n",
    "section": "\n10.2 交差項の利用 (1) 調整変数がダミー変数の場合",
    "text": "10.2 交差項の利用 (1) 調整変数がダミー変数の場合\n説明のために、浅野正彦・矢内勇生 (2018)『Rによる計量政治学』のデータ hr-data.csv を使う。\n\nHR &lt;- read_csv(\"data/hr-data.csv\")\n#glimpse(HR)\n\n衆議院議員経験があることを表すダミー変数と選挙費用を100万円単位で測定する変数を作る。\n\nHR &lt;- HR |&gt; \n  mutate(experience = as.numeric(status == \"現職\" | status == \"元職\"))\n\n2009年の結果だけ抜き出し、HR09として保存する（expm が欠測しているものを除外する）。 また、voteshare, expm, experienceの3変数だけ残す。select() という名前の関数は、dplyrパッケージ (tidyverseで読み込んだ) と interplot パッケージの両者に含まれるので、dplyr::select() と書いて、dplyrのselect() を使う。\n\nHR09 &lt;- HR |&gt; \n  filter(year == 2009,\n         !is.na(expm)) |&gt; \n  dplyr::select(voteshare, expm, experience)\n\n\n10.2.1 記述統計\n2009年の衆院選データについて、上で選んだ3変数の基本的な統計量を確認する。\n\nsummary(HR09)\n\n   voteshare          expm            experience    \n Min.   : 0.10   Min.   : 0.01002   Min.   :0.0000  \n 1st Qu.: 2.50   1st Qu.: 1.79454   1st Qu.:0.0000  \n Median :30.40   Median : 4.80944   Median :0.0000  \n Mean   :26.53   Mean   : 6.11818   Mean   :0.4048  \n 3rd Qu.:47.33   3rd Qu.: 9.10911   3rd Qu.:1.0000  \n Max.   :95.30   Max.   :25.35407   Max.   :1.0000  \n\n\n標準偏差も確認する。apply() を使うと、複数の変数の標準偏差を一挙に求めることができる。\n\napply(HR09, MARGIN = 2, FUN = sd)\n\n voteshare       expm experience \n22.1976087  4.9972111  0.4910726 \n\n\nこのように、apply() の最初の引数は対象となるデータ（行列）である。MARGIN は、計算を行に対して実行する (MARGIN = 1) か、列に対して実行する (MARGIN = 2) かを指定する。ここでは、各列が各変数に対応しているので、列を指定する。次に、FUN (function) として、sd() を指定する。ここで関数を指定する際は、() を省略して書く。 FUN で指定した関数が、第1引数で指定した各列（MARGIN = 1 なら各行）に適用される。FUN の関数に追加で引数を指定したいときは、続けて書く。たとえば、sd(x, na.rm = TRUE) を apply() で使いたいときは、 apply(HR09, MARGIN = 2, FUN = sd, na.rm = TRUE) とすれば良い。\n\n10.2.2 交差項を使った回帰分析\n得票率 \\(V\\) を応答変数、選挙費用 \\(M\\) を主な説明変数、議員経験の有無 \\(X\\) を調整変数とする回帰分析を考えよう。この回帰モデルは、 \\[\nV_i \\sim \\mbox{Normal}\\left(\\gamma_0 + \\gamma_1 M_i + \\gamma_2 X_i + \\gamma_3 M_i X_i, \\sigma \\right)\n\\] と書ける。まず、回帰分析で \\(\\gamma_k\\) (\\(k = 0, 1, 2, 3\\)) の値を推定しよう。\n\nfit_1 &lt;- lm(voteshare ~ expm * experience, data = HR09)\ntidy(fit_1, conf.int = TRUE)\n\n# A tibble: 4 × 7\n  term            estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -2.10     0.713     -2.94 3.36e-  3    -3.50    -0.697\n2 expm                4.87     0.164     29.6  5.97e-143     4.55     5.19 \n3 experience         46.2      1.57      29.5  9.13e-142    43.1     49.3  \n4 expm:experience    -4.77     0.206    -23.2  2.19e- 97    -5.18    -4.37 \n\n\nこのように、lm(Y ~ M * X, data = d) と書くと、\\(M\\) (expm), \\(X\\) (experience), \\(M \\times X\\) (expm:experience) の3つの説明変数をもつ重回帰が実行される。\n推定された偏回帰係数の意味を意味を考えよう。まず、\\(\\gamma_0\\) の推定値は -2.1 である。これは、すべての説明変数の値が0のときの得票率の予測値である。つまり、選挙費用が0（そんな候補者はいない！）で、議員経験がない候補者の得票率の予測値が、 -2.1 である（が、そんな得票率はあり得ない）。\n次に、\\(\\gamma_1\\) の推定値は 4.87 である。これは、議員経験がない (experience = 0の) 候補者について、選挙費用1単位の増加が、平均すれば得票率を4.87ポイント増加させることを示している。\n続いて、\\(\\gamma_2\\) の推定値は 46.19 である。これは、選挙費用 (expm)　が0の候補者について、議員経験があることが得票率をどれだけ増やすかを示している。つまり、選挙費用が0のとき、議員経験は平均すれば得票率を46.19ポイント上昇させる。\n最後に、\\(\\gamma_3\\) の推定値は -4.77 である。これは、議員経験が、選挙費用が得票率に与える影響の大きさ（つまり、得票率を選挙費用に回帰した直線の傾き）をどれだけ変えるかを示している。\n偏回帰係数に実質的に意味がない値が示されているので、選挙費用を中心化して推定し直そう。\n\nHR09 &lt;- HR09 |&gt; \n  mutate(expm_c = expm - mean(expm))\nfit_2 &lt;- lm(voteshare ~ expm_c * experience, data = HR09)\ntidy(fit_2, conf.int = TRUE)\n\n# A tibble: 4 × 7\n  term              estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)          27.7      0.658      42.1 9.52e-233    26.4      29.0 \n2 expm_c                4.87     0.164      29.6 5.97e-143     4.55      5.19\n3 experience           17.0      1.01       16.8 8.69e- 57    15.0      19.0 \n4 expm_c:experience    -4.77     0.206     -23.2 2.19e- 97    -5.18     -4.37\n\n\n推定された偏回帰係数の意味を意味を考えよう。まず、\\(\\gamma_0\\) の推定値は 27.7 である。これは、すべての説明変数の値が0のときの得票率の予測値である。つまり、選挙費用が平均値で、議員経験がない（議員経験は中心化していないことに注意）候補者の得票率の予測値が、 27.7 である。\n次に、\\(\\gamma_1\\) の推定値は 4.87 である。これは、議員経験がない (experience = 0の) 候補者について、選挙費用1単位の増加が、平均すれば得票率を4.87ポイント増加させることを示している。先程とまったく同じ推定値が得られた。これは、調整変数である議員経験を中心化していないからである。\n続いて、\\(\\gamma_2\\) の推定値は 16.99 である。これは、選挙費用 (expm)　が平均値の候補者について、議員経験があることが得票率をどれだけ増やすかを示している。つまり、、選挙費用が平均値のとき、議員経験は平均すれば得票率を16.99ポイント上昇させる。この値は、fit_1 で得られた値とは異なる。これは、説明変数である選挙費用を中心化したためである。fit_1では、「選挙費用が0のとき」という非現実的（かつ観測されていない）値についての推定値が示されていた。それに対し、fit_2 では、「中心化された選挙費用が0、すなわち選挙費用が平均値のとき」という、実際に意味がある場合の推定値が表示されている。\n最後に、\\(\\gamma_3\\) の推定値は -4.77 である。これは、議員経験が、選挙費用が得票率に与える影響の大きさ（つまり、得票率を選挙費用に回帰した直線の傾き）をどれだけ変えるかを示している。この値は、fit_1 と同じである。このように説明変数（と調整変数）を中心化しても、交差項の偏回帰係数の推定値は変化しない（交差項の意味を考えれば当たり前である）。\nこのように、調整変数がダミー変数の場合には、偏回帰係数の意味を説明することもできる。しかし、やはりわかりにくいので、結果を図にしよう。調整変数がダミー変数の場合には、調整変数が0の場合と1の場合のそれぞれについて、回帰直線を求めて図示すればよい。これは、geom_smooth() を使えば簡単にできる。experience() の値は連続ではないので、as.factor() を使う。\n\nint1 &lt;- ggplot(HR09, aes(x = expm, \n                         y = voteshare, \n                         color = as.factor(experience))) +\n  geom_smooth(method = \"lm\") +\n  geom_point() +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"議員経験\",\n                     labels = c(\"なし\", \"あり\")) +\n  labs(x = \"選挙費用（100万円）\", \n       y = \"得票率 (%)\")\nplot(int1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nこの図を見れば、選挙費用が得票率に与える影響は、議員経験の有無によってまったく異なることが一目瞭然である。議員経験がない場合には、選挙費用が得票率と強く相関するが、議員経験がある場合にはあまり関連がないことが見てとれる。 （ただし、推定した回帰モデルが「良い」モデルかどうかは別問題である。）",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>交差項の利用</span>"
    ]
  },
  {
    "objectID": "interaction.html#交差項を構成する項",
    "href": "interaction.html#交差項を構成する項",
    "title": "\n10  交差項の利用\n",
    "section": "\n10.3 交差項を構成する項",
    "text": "10.3 交差項を構成する項\n上の例では、\\(V\\) を \\(M\\), \\(X\\), \\(M \\times X\\) という3つの説明変数に回帰した。これらのうちの一部を省略すると、どのような問題が生じるのだろうか。\n\n10.3.1 主な説明変数 \\(M\\) を省く\nまず、\\(M\\) を省いてみよう。つまり、\\(\\gamma_1 = 0\\) という仮定をモデルに追加する。\n\nfit_3 &lt;- lm(voteshare ~ experience + expm_c:experience, \n            data = HR09)\ntidy(fit_3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term              estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        13.9        0.622    22.4   6.67e- 92   12.7      15.1  \n2 experience         30.8        1.20     25.7   4.70e-115   28.4      33.1  \n3 experience:expm_c   0.0962     0.166     0.580 5.62e-  1   -0.229     0.421\n\n\n（偏回帰係数の意味は各自で考えてもらうこととして）この結果を図にしてみよう。調整変数がダミー変数なので、場合分けして考える。選挙費用については、観測された最小値から最大値までを考える。\n\nmoney &lt;- seq(from = min(HR09$expm),\n             to = max(HR09$expm),\n             length.out = 100)\nmoney_c &lt;- money - mean(money)\n\nexperience = 0のときの予測値は、\n\nfitted3_x0 &lt;- \n  coef(fit_3)[1] +\n  coef(fit_3)[2] * 0 + \n  coef(fit_3)[3] * money_c * 0\n\nである。\nexperinece = 1 のときの予測値は、\n\nfitted3_x1 &lt;- \n  coef(fit_3)[1] + \n  coef(fit_3)[2] * 1 + \n  coef(fit_3)[3] * money_c * 1\n\nである。\n図を作るために、これらの値を tibble にする。\n\ndf_fitted &lt;- tibble(money, money_c, fitted3_x0, fitted3_x1)\n\n図を描く。（信頼区間を加えるには、もうひと手間必要。今回は割愛する。）\n\nplt3 &lt;- ggplot(df_fitted) +\n  geom_line(aes(x = money, y = fitted3_x0), color = \"red\") +\n  geom_line(aes(x = money, y = fitted3_x1), color = \"blue\") +\n  geom_point(data = HR09, aes(x = expm,\n                              y = voteshare,\n                              color = as.factor(experience))) +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"議員経験\",\n                     labels = c(\"なし\", \"あり\")) +\n  labs(x = \"選挙費用（100万円）\", y = \"得票率 (%)\")\nplot(plt3)\n\n\n\n\n\n\n\n\\(\\gamma_1 = 0\\) という制約のせいで、議員経験がない場合の傾きが0になってしまっている。そのせいで、議員経験がないときの選挙費用と得票率の関係がうまく捉えられていない。選挙費用が得票率に与える影響を知りたいのであれば、「選挙費用」を説明変数から除外してはいけないということだ（当たり前だ）。\n\n10.3.2 調整変数 \\(X\\) を省く\n次に、\\(X\\) を省いてみよう。つまり、\\(\\gamma_2 = 0\\) という仮定をモデルに追加する。\n\nfit_4 &lt;- lm(voteshare ~ expm_c + expm_c:experience, \n            data = HR09)\ntidy(fit_4, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term              estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)          34.9      0.558      62.5 0            33.8      36.0 \n2 expm_c                6.14     0.163      37.7 3.25e-201     5.82      6.46\n3 expm_c:experience    -4.98     0.230     -21.6 4.41e- 87    -5.43     -4.53\n\n\n（偏回帰係数の意味は各自で考えてもらうこととして）この結果を図にしてみよう。調整変数がダミー変数なので、場合分けして考える。選挙費用については、先程と同様に考える。\nexperience = 0のときの予測値は、\n\nfitted4_x0 &lt;- \n  coef(fit_4)[1] + \n  coef(fit_4)[2] * money_c +\n  coef(fit_4)[3] * money_c * 0\n\nである。\nexperinece = 1 のときの予測値は、\n\nfitted4_x1 &lt;- \n  coef(fit_4)[1] + \n  coef(fit_4)[2] * money_c + \n  coef(fit_4)[3] * money_c * 1\n\nである。\n図を作るために、これらの値を df_fitted に追加する。\n\ndf_fitted$fitted4_x0 &lt;- fitted4_x0\ndf_fitted$fitted4_x1 &lt;- fitted4_x1\n\n図を描く。（信頼区間を加えるには、もうひと手間必要。今回は割愛する。）\n\nplt4 &lt;- ggplot(df_fitted) +\n  geom_line(aes(x = money, y = fitted4_x0), color = \"red\") +\n  geom_line(aes(x = money, y = fitted4_x1), color = \"blue\") +\n  geom_point(data = HR09, aes(x = expm,\n                              y = voteshare,\n                              color = as.factor(experience))) +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"議員経験\",\n                     labels = c(\"なし\", \"あり\")) +\n  labs(x = \"選挙費用（100万円）\", \n       y = \"得票率 (%)\")\nplot(plt4)\n\n\n\n\n\n\n\n\\(\\gamma_2 = 0\\) という制約のせいで、議員経験がある場合とない場合の回帰直線の切片（選挙費用を中心化したので、選挙費用が平均値のときの \\(\\hat{V}\\) の値）が同じになることが強制されている。そのせいで、議員経験がないときの選挙費用と得票率の関係がうまく捉えられていない。このように、調整変数そのものを説明変数に加えないと、回帰直線が特定の点を通過するよう無理やり調整されるので、推定がうまくいかない。\n\n10.3.3 交差項 \\(M \\times X\\) を省く\n最後に、\\(M \\times X\\) を省いてみよう。つまり、\\(\\gamma_3 = 0\\) という仮定をモデルに追加する。 これは、交差項を使わないモデルであり、このトピックを学習するまで考えてきた交差項なしの回帰モデルと式の上では同じである。\n\nfit_5 &lt;- lm(voteshare ~ expm_c + experience, \n            data = HR09)\ntidy(fit_5, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    19.1      0.661      28.9 1.51e-137    17.8      20.4 \n2 expm_c          1.83     0.120      15.2 1.40e- 47     1.59      2.07\n3 experience     18.4      1.23       15.0 1.99e- 46    16.0      20.8 \n\n\n（偏回帰係数の意味は各自で考えてもらうこととして）この結果を図にしてみよう。調整変数がダミー変数なので、場合分けして考える。選挙費用については、先程と同様に考える。\nexperience = 0のときの予測値は、\n\nfitted5_x0 &lt;- \n  coef(fit_5)[1] +\n  coef(fit_5)[2] * money_c +\n  coef(fit_5)[3] * 0\n\nである。\nexperinece = 1 のときの予測値は、\n\nfitted5_x1 &lt;- \n  coef(fit_5)[1] + \n  coef(fit_5)[2] * money_c + \n  coef(fit_5)[3] * 1\n\nである。\n図を作るために、これらの値を df_fitted に追加する。\n\ndf_fitted$fitted5_x0 &lt;- fitted5_x0\ndf_fitted$fitted5_x1 &lt;- fitted5_x1\n\n図を描く。（信頼区間を加えるには、もうひと手間必要。今回は割愛する。）\n\nplt5 &lt;- ggplot(df_fitted) +\n  geom_line(aes(x = money, y = fitted5_x0), color = \"red\") +\n  geom_line(aes(x = money, y = fitted5_x1), color = \"blue\") +\n  geom_point(data = HR09, aes(x = expm,\n                              y = voteshare,\n                              color = as.factor(experience))) +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"議員経験\",\n                     labels = c(\"なし\", \"あり\")) +\n  labs(x = \"選挙費用（100万円）\", \n       y = \"得票率 (%)\")\nplot(plt5)\n\n\n\n\n\n\n\n\\(\\gamma_3 = 0\\) という制約のせいで、議員経験がある場合とない場合の回帰直線の傾きが同じになることが強制されている。そのせいで、交差項を含むモデルと比べると、議員経験がある場合とない場合のそれぞれについて、選挙費用と得票率の関係がうまく捉えられていない。このように、「交差項を使わない」という決断自体が、モデルに制約を加えているということを自覚する必要がある。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>交差項の利用</span>"
    ]
  },
  {
    "objectID": "interaction.html#交差項の利用-2-調整変数が量的変数の場合",
    "href": "interaction.html#交差項の利用-2-調整変数が量的変数の場合",
    "title": "\n10  交差項の利用\n",
    "section": "\n10.4 交差項の利用 (2) 調整変数が量的変数の場合",
    "text": "10.4 交差項の利用 (2) 調整変数が量的変数の場合\n引き続き、浅野・矢内 (2018) の衆院選データを使う。 2005年の衆院選について、voteshare, exppv, eligibleの3変数だけ残す。select() という名前の関数は、dplyrパッケージ (tidyverseで読み込んだ) と interplot パッケージの両者に含まれるので、dplyr::select() と書いて、dplyrのselect() を使う。\n\nHR05 &lt;- HR |&gt;\n  filter(year == 2005) |&gt; \n  dplyr::select(voteshare, exppv, eligible)\n\n\n10.4.1 記述統計\n2005年の衆院選データについて、上で選んだ3変数の基本的な統計量を確認する。\n\nsummary(HR05)\n\n   voteshare         exppv           eligible     \n Min.   : 0.60   Min.   : 0.148   Min.   :214235  \n 1st Qu.: 8.80   1st Qu.: 8.352   1st Qu.:297385  \n Median :34.80   Median :22.837   Median :347866  \n Mean   :30.33   Mean   :24.627   Mean   :344654  \n 3rd Qu.:46.60   3rd Qu.:35.269   3rd Qu.:397210  \n Max.   :73.60   Max.   :89.332   Max.   :465181  \n                 NA's   :4                        \n\n\nexppv （有権者1人あたりに費やした選挙費用）に欠測値 NA が4つあることがわかる。\n3変数の標準偏差を求める。\n\napply(HR05, MARGIN = 2, FUN = sd, na.rm = TRUE)\n\n  voteshare       exppv    eligible \n   19.23023    17.90740 63898.23016 \n\n\n得票率 voteshare と 一人当たり選挙費用 exppv の関係を、散布図で確認する。\n\nplt_vs_ex &lt;- ggplot(HR05, aes(x = exppv, y = voteshare)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"有権者一人当たり選挙費用\", y = \"得票率\")\nplot(plt_vs_ex)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n有権者数 elgible と exppv の関係を、散布図を使って確認する。\n\nplt_vs_el &lt;- ggplot(HR05, aes(x = eligible, y = voteshare)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") + \n  labs(x = \"有権者数\", y = \"得票率\")\nplot(plt_vs_el)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n10.4.2 交差項を使った回帰分析\n有権者一人あたり選挙費用 exppv が得票率 voteshare に与える影響は、有権者数 eligible によって変わるだろうか。これを確かめるために、exppv と eligible の交差項 (interaction term) を回帰分析に投入し、以下のモデルを推定する。\n\\[\n得票率_i = \\beta_0 + \\beta_1 選挙費用_i + \\beta_2 有権者数_i + \\beta_3 選挙費用_i \\times 有権者数_i + 誤差_i\n\\]\nこのモデルをlm()で推定するためには、次のコードを使う。\n\nmodel_1 &lt;- lm(voteshare ~ exppv * eligible, \n              data = HR05)\n\nつまり、変数1 * 変数2 という書き方をすると、重回帰分析に 「変数1」、「変数2」、「変数1と変数2の交差項」という3つの項が加えられる。\n結果を確認してみよう。\n\ntidy(model_1)\n\n# A tibble: 4 × 5\n  term              estimate   std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     9.64       3.79            2.54  1.12e- 2\n2 exppv           0.0192     0.114           0.168 8.67e- 1\n3 eligible       -0.00000148 0.0000107      -0.138 8.90e- 1\n4 exppv:eligible  0.00000255 0.000000350     7.29  6.44e-13\n\n\nこの結果は、どのように解釈できるだろうか。例えば、exppv の係数の推定値 0.019 はどういう意味を持っているだろうか。通常の回帰分析と同様に考えると、他の変数の値を一定に保ったとき、 exppvが1単位増えると、得票率が0.019 ポイント上がるという意味である。\nしかし、他の変数を一定に保つことは可能だろうか？このモデルでは、特殊な状況を除きそれは不可能である。exppv の値を変えれば、exppv \\(\\times\\) eligibleの値も変わってしまうからである。他の変数を一定に保つことができるのは、eligble = 0 のときだけある。しかし、有権者数がゼロの選挙区は存在しないので、0.019という数字をそのまま解釈することはできない。言い換えると、\\(\\beta_1\\) の推定値が得られただけではあまり嬉しくない。\nこの例からわかる通り、交差項を含む回帰分析の結果を、表から読み取ることは一般的に非常に難しい。これは、表を提示するだけでは分析結果の報告として不十分だということを意味する。\n先ほどのモデルでは説明変数をそのまま使っていた。次に、説明変数を中心化して、同様のモデルを推定してみよう。\n\nHR05 &lt;- HR05 |&gt; \n  mutate(exppv_c = exppv - mean(exppv, na.rm = TRUE),\n         eligible_c = eligible - mean(eligible))\nmodel_2 &lt;- lm(voteshare ~ exppv_c * eligible_c, data = HR05)\ntidy(model_2)\n\n# A tibble: 4 × 5\n  term                  estimate   std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        31.2        0.419           74.6  0        \n2 exppv_c             0.898      0.0251          35.7  1.46e-179\n3 eligible_c          0.0000613  0.00000658       9.32 7.45e- 20\n4 exppv_c:eligible_c  0.00000255 0.000000350      7.29 6.44e- 13\n\n\nこの結果は、どのように解釈できるだろうか。例えば、exppv の係数の推定値 0.898 はどういう意味を持っているだろうか。通常の回帰分析と同様に考えると、他の変数の値を一定に保ったとき、 exppv_cが1単位増えると、得票率が0.898 ポイント上がるという意味である。\nでは、他の変数を一定に保つことは可能だろうか？このモデルでも、特殊な状況を除き、それは不可能である。exppv_c の値を変えれば、exppv_c \\(\\times\\) eligible_c の値も変わってしまうからである。、他の変数を一定に保つことができるのは、eligble_c = 0 のときだけある。eligible_c は有権者数 eligible を中心化した変数なので、eligble_c = 0 というのは、「有権者数が平均値のとき」という意味である。したがって、「有権者数が平均値のとき」という特殊な場合に限り、0.898 という数字の意味を解釈することができる。\nこのように、説明変数を中心化することにより、少しだけ結果が解釈しやすくなった。（中心化できない変数以外は中心化するという方針なので、ここまではいつも辿り着くはず。）しかし、有権者数が平均値のとき以外については、解釈が不可能である。よって、もう少し工夫が必要である。そのような工夫の一つが、図を使う方法である。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>交差項の利用</span>"
    ]
  },
  {
    "objectID": "interaction.html#交差項の影響を可視化する",
    "href": "interaction.html#交差項の影響を可視化する",
    "title": "\n10  交差項の利用\n",
    "section": "\n10.5 交差項の影響を可視化する",
    "text": "10.5 交差項の影響を可視化する\n\n10.5.1 散布図に複数の回帰直線を描く\n交差項の効果を可視化する方法は色々考えられるが、最も単純な（簡単とは限らない）方法は、調整変数である「有権者数」の値をいくつかの代表的な値に設定し、それらの値ごとに異なる回帰直線（特定の有権数の下で、得票率を有権者一人当たり選挙費用に回帰した場合の回帰直線）を求め、散布図上に回帰直線を上書きするという方法である。実際にやってみよう。\nまず、有権者数の平均値と標準偏差を求める。\n\n(mean_eligible &lt;- mean(HR05$eligible))\n\n[1] 344654.3\n\n(sd_eligible &lt;- sd(HR05$eligible))\n\n[1] 63898.23\n\n\n有権者の数が「平均 \\(\\pm\\) 標準偏差」の場合について、回帰直線を求めることにする。 上で推定した model_1 の結果から、 \\[\n\\widehat{得票率} = 9.6382872 + 0.0191673 選挙費用 + -1.4832785\\times 10^{-6} 有権者数 + 2.5489967\\times 10^{-6} 選挙費用 \\times 有権者数\n\\] である。したがって、有権差数が平均 \\(-\\) 標準偏差の場合の回帰直線の切片は、\n\n(intercept1 &lt;- \n   coef(model_1)[1] +  \n   coef(model_1)[3] * (mean_eligible - sd_eligible))\n\n(Intercept) \n   9.221848 \n\n\nであり、傾きは、\n\n(slope1 &lt;- \n   coef(model_1)[2] + \n   coef(model_1)[4] * (mean_eligible - sd_eligible))\n\n    exppv \n0.7348136 \n\n\nである。\n同様に、有権差数が平均 \\(+\\) 標準偏差の場合の回帰直線の切片は、\n\n(intercept2 &lt;- \n   coef(model_1)[1] +  \n   coef(model_1)[3] * (mean_eligible + sd_eligible))\n\n(Intercept) \n    9.03229 \n\n\nであり、傾きは、\n\n(slope2 &lt;- \n   coef(model_1)[2] + \n   coef(model_1)[4] * (mean_eligible + sd_eligible))\n\n   exppv \n1.060566 \n\n\nである。\nこれらを図示してみよう。\n\nplt_int &lt;- ggplot(HR05, aes(x = exppv, y = voteshare)) + \n  geom_point(pch = 16) +\n  geom_abline(intercept = intercept1, slope = slope1,\n              linetype = \"dashed\") +\n  geom_abline(intercept = intercept2, slope = slope2) + \n  ylim(0, 100) +\n  labs(x = \"選挙費用（有権者一人当たり：円）\", y = \"得票率 (%)\") + \n  geom_text(label = \"得票率 = 9.22 + 0.73・選挙費用\\n(有権者数：平均 - 標準偏差)\", \n            x = 65, y = 8, family = my_font) +\n  geom_text(label = \"得票率 = 9.03 + 1.06・選挙費用\\n(有権者数：平均 + 標準偏差)\", \n            x = 40, y = 90, family = my_font)\n\n\nplot(plt_int)\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n10.5.2 限界効果を可視化する\n次に、有権者数の変化によって、「選挙費用が得票率に与える影響」がどのように変化するかを可視化しよう。調整変数（この例では有権者数）が特定の値のとき、説明変数1単位の変化が応答変数に与える影響のことを限界効果 (marginal effect) と呼ぶ。（交差項がない重回帰分析の場合、係数の推定値そのものが限界効果である。） 交差項がある場合の限界効果は、interplot::interplot() で図示できる。\n\nint_1 &lt;- interplot(m = model_1, \n                   var1 = \"exppv\", \n                   var2 = \"eligible\") +\n  labs(x = \"有権者数\", \n       y = \"選挙費用が得票率に与える影響\")\nplot(int_1)\n\n\n\n\n\n\n\nこの図から、選挙費用が得票率に与える影響（縦軸）は、有権者数とともに大きくなることがわかる。言い換えると、選挙費用の影響は、有権者が少ない場合には相対的に小さく、有権者が多い場合には相対的に大きくなることがわかる。\nこのように、交差項を含む回帰分析を行う場合には、限界効果を図示するなどして結果をわかりやすく示すことが求められる。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>交差項の利用</span>"
    ]
  },
  {
    "objectID": "multiple-comparison.html",
    "href": "multiple-comparison.html",
    "title": "\n11  多重比較法\n",
    "section": "",
    "text": "11.1 準備\n必要なパッケージを読み込む。\npacman::p_load(tidyverse,\n               broom)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>多重比較法</span>"
    ]
  },
  {
    "objectID": "multiple-comparison.html#多重比較の問題",
    "href": "multiple-comparison.html#多重比較の問題",
    "title": "\n11  多重比較法\n",
    "section": "\n11.2 多重比較の問題",
    "text": "11.2 多重比較の問題\n多重検定の問題を確認するために、シミュレーションを実施しよう。\nまず、標本サイズ\\(N\\)で、\\(K\\)個の互いに独立な説明変数\\(x_1, x_2, \\dots, x_{K}\\) を作る。\\(N=100\\)、\\(K=20\\)で試してみる。\n\nset.seed(2021-11-12)\nN &lt;- 100  # 標本サイズ\nK &lt;- 20   # 説明変数の数\nX &lt;- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)\ncolnames(X) &lt;- paste0(\"x\", 1:K)\nmyd &lt;- as_tibble(X)\n\nこれらの説明変数 \\(x_k\\) (\\(k = 1, 2, \\dots, K\\)) とは無関係に \\(y\\)を作り、データフレームに加える。\n\nmyd$y &lt;- rnorm(N)\n\nこのデータを使い、以下の回帰モデルを推定する。 \\[\n\\begin{aligned}\n  Y_i &\\sim \\mbox{Normal}(\\mu_i, \\sigma) \\\\\n  \\mu_i &= \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_K x_{iK}\n\\end{aligned}\n\\]\nここで、\\(\\beta_k = 0\\) という帰無仮説を、すべての\\(k\\) (\\(k = 1, 2, \\dots, K\\)) について個別に検定するとする。そうすると、検定の対象となるファミリーは、 \\[\n\\mathcal{F} = \\{\\beta_1 = 0, \\dots, \\beta_K = 0\\}\n\\] となる。\nこのシミュレーションでは、\\(y\\)をどの\\(x_k\\)とも無関係に作っているので、すべての帰無仮説が正しい。よって、このファミリーに含まれる帰無仮説は1つも棄却したくない。\n実際に回帰分析を行い、有意水準0.05で1つひとつの仮説を検定しよう。y ~ . とすると、y をそのデータに含まれるy以外のすべての変数に回帰する。\n\nfit &lt;- lm(y ~ ., data = myd)\ntidy(fit) |&gt; \n  knitr::kable()\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.0632212\n0.1064784\n0.5937468\n0.5543778\n\n\nx1\n0.0013358\n0.0477982\n0.0279475\n0.9777745\n\n\nx2\n0.0139943\n0.0660608\n0.2118397\n0.8327777\n\n\nx3\n-0.0006238\n0.0479122\n-0.0130198\n0.9896448\n\n\nx4\n-0.0730475\n0.0514828\n-1.4188723\n0.1598696\n\n\nx5\n-0.0054763\n0.0532819\n-0.1027800\n0.9183980\n\n\nx6\n0.0946855\n0.0537225\n1.7624910\n0.0818542\n\n\nx7\n0.0183856\n0.0552615\n0.3327021\n0.7402404\n\n\nx8\n-0.1972879\n0.0583854\n-3.3790612\n0.0011320\n\n\nx9\n-0.0418925\n0.0522673\n-0.8015058\n0.4252431\n\n\nx10\n-0.0051098\n0.0553812\n-0.0922659\n0.9267204\n\n\nx11\n-0.0301027\n0.0641550\n-0.4692188\n0.6402057\n\n\nx12\n0.0119326\n0.0548061\n0.2177242\n0.8282054\n\n\nx13\n0.0048011\n0.0515746\n0.0930897\n0.9260679\n\n\nx14\n-0.0089601\n0.0579230\n-0.1546894\n0.8774607\n\n\nx15\n-0.0299819\n0.0608123\n-0.4930237\n0.6233635\n\n\nx16\n0.1100211\n0.0591603\n1.8597128\n0.0666487\n\n\nx17\n0.0204935\n0.0603651\n0.3394919\n0.7351401\n\n\nx18\n-0.0383977\n0.0598645\n-0.6414093\n0.5231134\n\n\nx19\n-0.0253316\n0.0610053\n-0.4152359\n0.6790949\n\n\nx20\n0.0224067\n0.0599897\n0.3735087\n0.7097703\n\n\n\n\n\nx8の\\(p\\)値 (p.value) が 0.05未満なので、\\(\\beta_8 = 0\\)という帰無仮説が誤って棄却されてしまう。\n少なくとも1つの帰無仮説を誤って棄却するかどうかは、次のようにして調べることができる。\\(p\\)値（p.value）が有意水準を下回っていれば、帰無仮説が棄却される。\n\npv &lt;- tidy(fit) |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  pull(p.value) \nifelse(sum(pv &lt; 0.05) &gt; 0, TRUE, FALSE)\n\n[1] TRUE\n\n\nこの TRUE が、少なくとも1つの帰無仮説を誤って棄却してしまっていることを示す。FALSE ならすべての帰無仮説が「正しく」保留されているということを意味する。\nこのシミュレーションを繰り返し実施するために、関数を作ろう。 Nは標本サイズ、Kは説明変数の数（つまり、ファミリーに含まれる帰無仮説の数）、alpha は個々の帰無仮説の検証に使う有意水準である。alphaの既定値は0.05にしておく。\n\nsim_mc &lt;- function(N = 100, K = 1, alpha = 0.05) {\n  X &lt;- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)\n  y &lt;- rnorm(N)\n  fit &lt;- lm(y ~ X)\n  pv &lt;- tidy(fit) |&gt; \n    filter(term != \"(Intercept)\") |&gt; \n    pull(p.value) \n  ifelse(sum(pv &lt; alpha) &gt; 0, TRUE, FALSE)\n}\n\nこの関数を1回だけ使ってみよう。\n\nsim_mc(N = 100, K = 20)\n\n[1] TRUE\n\n\nTRUE という答えが返ってきたので、少なくとも1つの帰無仮説が誤って棄却されたことがわかる。\nこの関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。 まずは、\\(K=1\\)の場合（つまり、多重比較ではない場合）について確認する。\n\nres_k1 &lt;- replicate(10000, \n                    sim_mc(N = 100, \n                           K = 1, \n                           alpha = 0.05))\n\n少なくとも1つの帰無仮説が誤って棄却される割合を計算する。\n\nmean(res_k1)\n\n[1] 0.0478\n\n\n有意水準に設定した0.05に近い値が得られた。「帰無仮説が正しいのに誤って帰無仮説を棄却する確率（危険率）」が有意水準なので、この結果は当然である。\n次に、\\(K=20\\)の場合について確認する。\n\nres_k20 &lt;- replicate(10000, \n                     sim_mc(N = 100, \n                            K = 20, \n                            alpha = 0.05))\n\n少なくとも1つの帰無仮説が誤って棄却される割合を計算する。\n\nmean(res_k20)\n\n[1] 0.5954\n\n\nファミリーの有意水準が0.59になった。1つひとつの検定で利用するalphaの値を「めったにない」と言えそうな5%にしても、全体ではめったにないとは決して言えない59%に なってしまっており、多重比較の調整が必要であることがわかる。\nボンフェローニの方法で有意水準を補正するとどうなるだろうか。 \\(K=20\\) のときにファミリーの有意水準を0.05にするには、alpha = 0.05 / 20 にすればよいはずだ。やってみよう。\n\nbonferroni_k20 &lt;- replicate(10000, \n                            sim_mc(N = 100, \n                                   K = 20, \n                                   alpha = 0.05 / 20))\n\n少なくとも1つの帰無仮説が誤って棄却される割合を計算する。\n\nmean(bonferroni_k20)\n\n[1] 0.0484\n\n\n約5%になっており、多重比較の問題は解消されていることがわかる。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>多重比較法</span>"
    ]
  },
  {
    "objectID": "multiple-comparison.html#ボンフェローニの方法の問題",
    "href": "multiple-comparison.html#ボンフェローニの方法の問題",
    "title": "\n11  多重比較法\n",
    "section": "\n11.3 ボンフェローニの方法の問題",
    "text": "11.3 ボンフェローニの方法の問題\n上では、すべての帰無仮説が正しい場合について考えた。 では、いくつかの帰無仮説が正しくない場合にはどうなるだろうか。\n20個の説明変数のうち、3つは\\(y\\)に関係があるという状況でシミュレーションを行う。 そのための関数を作る。\n\nsim_mc2 &lt;- function(N = 100, K = 4, alpha = 0.05, type = 1) {\n  X &lt;- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)\n  y &lt;- 0.8 * X[, 1] - 0.7 * X[, 2] + 0.4 * X[, 3] + rnorm(N)\n  fit &lt;- lm(y ~ X)\n  pv &lt;- tidy(fit) |&gt; \n    filter(term != \"(Intercept)\") |&gt; \n    pull(p.value) \n  if (type == 1) ifelse(sum(pv[4:K] &lt; alpha) &gt; 0, TRUE, FALSE)\n  else if (type == 2) ifelse(sum(pv[1:3] &lt; alpha) == 3, FALSE, TRUE)\n  else stop(\"type must be either 1 or 2.\")\n}\n\nこの関数を1回だけ使ってみよう。\n\nset.seed(2021-11-12)\nsim_mc2(N = 50, K = 20)\n\n[1] FALSE\n\n\nFALSEという答えが返ってきた。正しい帰無仮説はすべて保留された。\nこの関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。\\(K=20\\)の場合について確認する。\n\nres_k20b &lt;- replicate(10000, \n                      sim_mc2(N = 50, \n                              K = 20, \n                              alpha = 0.05))\n\n正しい帰無仮説のうち少なくとも1つが誤って棄却される割合を計算する。\n\nmean(res_k20b)\n\n[1] 0.4908\n\n\nファミリーの有意水準が0.49になった。1つひとつの検定で利用するalphaの値を「めったにない」と言えそうな5%にしても、全体では「めったにない」とは決して言えない52%に なってしまっており、多重比較の調整が必要であることがわかる。\nそこで、ボンフェローニの方法で有意水準を補正する。 \\(K=20\\) なのでalpha = 0.05 / 20 にすればよいはずだ。\n\nbonferroni_k20b &lt;- replicate(10000, \n                            sim_mc2(N = 50, \n                                    K = 20, \n                                    alpha = 0.05 / 20))\n\n正しい帰無仮説のうち少なくとも1つが誤って棄却される割合を計算する。\n\nmean(bonferroni_k20b)\n\n[1] 0.0372\n\n\n約3.7%になっており、正しい帰無仮説を誤って棄却するという問題は解消されていることがわかる。\nでは、正しくない帰無仮説は棄却できているだろうか。 第2種の誤りの割合を計算したいので、type = 2 を指定する。\n\nbonferroni_k20c &lt;- replicate(10000, \n                            sim_mc2(N = 50, \n                                    K = 20, \n                                    alpha = 0.05 / 20,\n                                    type = 2))\nmean(bonferroni_k20c)\n\n[1] 0.1912\n\n\n約19%について、正しくない帰無仮説を少なくとも1つは棄却し損ねていることがわかる。\nボンフェローニの補正を行う前についても同じ割合を計算してみよう。\n\nres_k20c &lt;- replicate(10000, \n                      sim_mc2(N = 50, \n                              K = 20, \n                              alpha = 0.05,\n                              type = 2))\nmean(res_k20c)\n\n[1] 0.0244\n\n\n補正前には、この種の誤りは2%ほどしかなかったことがわかる。ボンフェローニの方法を用いると、正しい帰無仮説を誤って棄却するという間違い（第1種のエラー）が減る代わりに、正しくない帰無仮説を棄却することに失敗する（第2種のエラー）が増えるということだ。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>多重比較法</span>"
    ]
  },
  {
    "objectID": "multiple-comparison.html#ホルムの方法",
    "href": "multiple-comparison.html#ホルムの方法",
    "title": "\n11  多重比較法\n",
    "section": "\n11.4 ホルムの方法",
    "text": "11.4 ホルムの方法\nボンフェローニの方法は、帰無仮説を棄却する基準を厳しくし過ぎる結果、正しくない帰無仮説を棄却することにも失敗している。この点を改良した、ホルムの方法を試してみよう。\nボンフェローニの方法とホルムの方法比較するために、データを生成して回帰分析の結果を保存する関数を作る。\n\nsim_mc3 &lt;- function(N = 50, K = 4) {\n  X &lt;- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)\n  y &lt;- 0.8 * X[, 1] - 0.7 * X[, 2] + 0.3 * X[, 3] + rnorm(N)\n  fit &lt;- lm(y ~ X)\n  tidy(fit) |&gt; \n    filter(term != \"(Intercept)\") |&gt; \n    select(term, estimate, p.value)\n}\n\nこの関数を1回だけ使ってみよう。\n\nset.seed(2021-11-14)\nres1 &lt;- sim_mc3(N = 50, K = 20)\nres1\n\n# A tibble: 20 × 3\n   term   estimate  p.value\n   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 X1     1.05     1.47e-12\n 2 X2    -0.711    1.02e- 8\n 3 X3     0.276    5.00e- 3\n 4 X4    -0.0177   8.44e- 1\n 5 X5    -0.0987   2.79e- 1\n 6 X6    -0.0106   8.87e- 1\n 7 X7     0.0717   4.98e- 1\n 8 X8     0.00894  9.18e- 1\n 9 X9     0.101    2.49e- 1\n10 X10   -0.119    3.13e- 1\n11 X11   -0.0503   5.90e- 1\n12 X12    0.0641   5.27e- 1\n13 X13    0.0583   5.06e- 1\n14 X14   -0.0653   5.15e- 1\n15 X15    0.156    4.88e- 2\n16 X16    0.212    3.19e- 2\n17 X17   -0.102    2.03e- 1\n18 X18    0.0725   4.28e- 1\n19 X19   -0.0346   6.93e- 1\n20 X20   -0.000597 9.94e- 1\n\n\n有意水準0.05 で個々の帰無仮説が棄却されるかどうか確かめる。\n\nres1$p.value &lt; 0.05\n\n [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE\n\n\n最初の3つ（正しくない帰無仮説）は棄却されている。残りの17個の帰無仮説は正しいが、そのうち2つが誤って棄却されている（X15とX16の検定結果がTRUEすなわち棄却になっている）。\nボンフェローニの方法で補正するとどうなるだろうか。 p.adjust() 関数を使うと、多重比較の補正を行うことができる。\n\np.adjust(res1$p.value, method = \"bonferroni\")\n\n [1] 2.944308e-11 2.041376e-07 9.994142e-02 1.000000e+00 1.000000e+00\n [6] 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n[11] 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 9.754977e-01\n[16] 6.374704e-01 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n\n\nこれらの値が、ボンフェローニの方法で検定に使うべき\\(p\\)値である。これを使って検定を行う。\n\np.adjust(res1$p.value, method = \"bonferroni\") &lt; 0.05\n\n [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n補正なしだと誤って棄却してしまった正しい帰無仮説は保留されている。代わりに、補正無しでは棄却できていた正しくない帰無仮説 (\\(\\beta_3 = 0\\)) が保留されている。\np.adjust() でホルムの方法も利用できる。\n\np.adjust(res1$p.value, method = \"holm\")\n\n [1] 2.944308e-11 1.939307e-07 8.994728e-02 1.000000e+00 1.000000e+00\n [6] 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n[11] 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 7.803981e-01\n[16] 5.418499e-01 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n\n\nこれらの値が、ホルムの方法で検定に使うべき\\(p\\)値である。これを使って検定を行う。\n\np.adjust(res1$p.value, method = \"holm\") &lt; 0.05\n\n [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n補正なしだと誤って棄却してしまった正しい帰無仮説は保留されている。ボンフェローニの方法と同様に、補正無しでは棄却できていた正しくない帰無仮説 (\\(\\beta_3 = 0\\)) が保留されている。\n2つの方法の\\(p\\)値を比較してみよう。\n\ncbind(p.adjust(res1$p.value, method = \"bonferroni\"),\n      p.adjust(res1$p.value, method = \"holm\"))\n\n              [,1]         [,2]\n [1,] 2.944308e-11 2.944308e-11\n [2,] 2.041376e-07 1.939307e-07\n [3,] 9.994142e-02 8.994728e-02\n [4,] 1.000000e+00 1.000000e+00\n [5,] 1.000000e+00 1.000000e+00\n [6,] 1.000000e+00 1.000000e+00\n [7,] 1.000000e+00 1.000000e+00\n [8,] 1.000000e+00 1.000000e+00\n [9,] 1.000000e+00 1.000000e+00\n[10,] 1.000000e+00 1.000000e+00\n[11,] 1.000000e+00 1.000000e+00\n[12,] 1.000000e+00 1.000000e+00\n[13,] 1.000000e+00 1.000000e+00\n[14,] 1.000000e+00 1.000000e+00\n[15,] 9.754977e-01 7.803981e-01\n[16,] 6.374704e-01 5.418499e-01\n[17,] 1.000000e+00 1.000000e+00\n[18,] 1.000000e+00 1.000000e+00\n[19,] 1.000000e+00 1.000000e+00\n[20,] 1.000000e+00 1.000000e+00\n\n\n第1列がボンフェローニの方法による\\(p\\)値、第2列がホルムの方法による\\(p\\)値である。 2つの方法を比較すると、ホルムの方法の\\(p\\)値のほうが小さいことがわかる。 つまり、ホルムの方法のほうが、帰無仮説を棄却しやすい。 帰無仮説を棄却しにくくなるというボンフェローニの方法の欠点が改良されていることがわかる。\nこのシミュレーションを繰り返し実行するための関数を作る。 帰無仮説が3つ未満しか棄却されなかったときにTRUE を返すことにする。（厳密には、これは知りたいこととは異なる。たとえば、正しくない帰無仮説がすべて保留され、正しい帰無仮説が誤って3つ棄却されるという場合も考えられる。）\n\nsim_b_h &lt;- function(N = 50, K = 20, alpha = 0.05, method) {\n  res &lt;- sim_mc3(N = N, K = K)\n  sum(p.adjust(res$p.value, method = method) &lt; alpha) &lt; 3\n}\n\nこの関数を1回だけ使ってみよう。\n\nsim_b_h(N = 100, K = 20, method = \"holm\")\n\n[1] FALSE\n\n\nFALSE が返されたので、正しくない帰無仮説はすべて棄却されたことがわかる。\nこの関数を使い、シミュレーションを実施する。繰り返し回数は1万回とする（各自のパソコンの性能に応じて回数は調整されたい）。まず、ボンフェローニの方法を試す。\n\nres_b &lt;- replicate(10000, \n                   sim_b_h(N = 50, \n                           K = 20, \n                           method = \"bonferroni\"))\n\n正しくない帰無仮説のうち、少なくとも1つが保留されてしまう割合を計算する。\n\nmean(res_b)\n\n[1] 0.4931\n\n\n49.8%について、正しくない帰無仮説を棄却することに失敗している。\n次に、ホルムの方法を試す。\n\nres_h &lt;- replicate(10000, \n                   sim_b_h(N = 50, \n                           K = 20, \n                           method = \"holm\"))\n\n少なくとも1つの帰無仮説が誤って棄却される割合を計算する。\n\nmean(res_h)\n\n[1] 0.4822\n\n\n48.2%について、正しくない帰無仮説を棄却することに失敗している。 ボンフェローニの方法よりも少しだけマシなようだ。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>多重比較法</span>"
    ]
  },
  {
    "objectID": "multiple-comparison.html#多重比較補正の計算法",
    "href": "multiple-comparison.html#多重比較補正の計算法",
    "title": "\n11  多重比較法\n",
    "section": "\n11.5 多重比較補正の計算法",
    "text": "11.5 多重比較補正の計算法\n上で説明したとおり、分析結果に対して多重比較の補正を行う際は、p.adjust() を使う。 ランダムに生成したデータで実行してみよう。\nまず、データを作る。\n\nset.seed(2021-11-13)\nN &lt;- 50  # 標本サイズ\nK &lt;- 8   # 説明変数の数\nX &lt;- matrix(rnorm(N * K, mean = 0, sd = 2), ncol = K)\ncolnames(X) &lt;- paste0(\"x\", 1:K)\nmyd &lt;- as_tibble(X) |&gt; \n  mutate(y = 0.5 * x1 + 0.4 * x2 + rnorm(n()))\n\n回帰分析を実行する。\n\nols &lt;- lm(y ~ ., \n          data = myd)\n\n係数の推定値、補正前の\\(p\\)値、ボンフェローニの方法による\\(p\\)値、ホルムの方法による\\(p\\)値を並べて表示する。\n\nols |&gt; \n  tidy() |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  select(term, estimate, p.value) |&gt; \n  mutate(Bonferroni = p.adjust(p.value, method = \"bonferroni\"),\n         Holm = p.adjust(p.value, method = \"holm\")) |&gt; \n  rename(`説明変数` = term,\n         `推定値` = estimate,\n         `p値` = p.value)\n\n# A tibble: 8 × 5\n  説明変数  推定値         p値 Bonferroni       Holm\n  &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 x1        0.342  0.00120     0.00960    0.00840   \n2 x2        0.494  0.000000844 0.00000675 0.00000675\n3 x3        0.0113 0.906       1          1         \n4 x4        0.0728 0.415       1          1         \n5 x5       -0.0914 0.244       1          1         \n6 x6       -0.0247 0.815       1          1         \n7 x7        0.0939 0.227       1          1         \n8 x8       -0.0529 0.652       1          1         \n\n\nそれぞれの\\(p\\)値が有意水準を下回る場合について帰無仮説を棄却する。 この例では、補正の有無によって検定結果は変わらない。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>多重比較法</span>"
    ]
  }
]